<!DOCTYPE html><html lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" data-vue-meta-server-rendered><head><!-- Global site tag (gtag.js) - Google Analytics --><script type="text/javascript" src="https://ff.kis.v2.scr.kaspersky-labs.com/FD126C42-EBFA-4E12-B309-BB3FDD723AC1/main.js?attr=Zqj8zjMJEVizggvfUDcE8osIQNJOcXkT0eGANAZjoNqtmmEXSbcEimFfLIZI9RQ8cqKwUdGlkBvKBMFKMZgdOQ" charset="UTF-8"></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-20570189-2"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-20570189-2",{send_page_view:!1})</script><title data-vue-meta="true">Automatic Speech Emotion Recognition Using Machine Learning | IntechOpen</title><meta data-vue-meta="true" charset="utf-8"><meta data-vue-meta="true" http-equiv="X-UA-Compatible" content="IE=edge"><meta data-vue-meta="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-vue-meta="true" rel="canonical" href="https://www.intechopen.com/chapters/65993"><meta data-vue-meta="true" name="description" content="This chapter presents a comparative study of speech emotion recognition (SER) systems. Theoretical definition, categorization of affective state and the modalities of emotion expression are presented. To achieve this study, an SER system, based on different classifiers and different methods for features extraction, is developed. Mel-frequency cepstrum coefficients (MFCC) and modulation spectral (MS) features are extracted from the speech signals and used to train different classifiers. Feature selection (FS) was applied in order to seek for the most relevant feature subset. Several machine learning paradigms were used for the emotion classification task. A recurrent neural network (RNN) classifier is used first to classify seven emotions. Their performances are compared later to multivariate linear regression (MLR) and support vector machines (SVM) techniques, which are widely used in the field of emotion recognition for spoken audio signals. Berlin and Spanish databases are used as the experimental data set. This study shows that for Berlin database all classifiers achieve an accuracy of 83% when a speaker normalization (SN) and a feature selection are applied to the features. For Spanish database, the best accuracy (94 %) is achieved by RNN classifier without SN and with FS."><meta data-vue-meta="true" name="title" content="Automatic Speech Emotion Recognition Using Machine Learning | IntechOpen"><meta data-vue-meta="true" name="authors" content="Leila Kerkeni, Youssef Serrestou, Mohamed Mbarki, Kosai Raoof, Mohamed Ali Mahjoub and Catherine Cleder"><meta data-vue-meta="true" name="category" content="Chapter"><meta data-vue-meta="true" property="og:type" content="article"><meta data-vue-meta="true" property="og:url" content="https://www.intechopen.com/chapters/65993"><meta data-vue-meta="true" property="og:title" content="Automatic Speech Emotion Recognition Using Machine Learning"><meta data-vue-meta="true" property="og:image" content="https://cdn.intechopen.com/books/images_new/8141.jpg"><meta data-vue-meta="true" property="og:description" content="This chapter presents a comparative study of speech emotion recognition (SER) systems. Theoretical definition, categorization of affective state and the modalities of emotion expression are presented. To achieve this study, an SER system, based on different classifiers and different methods for features extraction, is developed. Mel-frequency cepstrum coefficients (MFCC) and modulation spectral (MS) features are extracted from the speech signals and used to train different classifiers. Feature selection (FS) was applied in order to seek for the most relevant feature subset. Several machine learning paradigms were used for the emotion classification task. A recurrent neural network (RNN) classifier is used first to classify seven emotions. Their performances are compared later to multivariate linear regression (MLR) and support vector machines (SVM) techniques, which are widely used in the field of emotion recognition for spoken audio signals. Berlin and Spanish databases are used as the experimental data set. This study shows that for Berlin database all classifiers achieve an accuracy of 83% when a speaker normalization (SN) and a feature selection are applied to the features. For Spanish database, the best accuracy (94 %) is achieved by RNN classifier without SN and with FS."><meta data-vue-meta="true" name="twitter:card" content="summary"><meta data-vue-meta="true" name="twitter:image" content="https://cdn.intechopen.com/books/images_new/8141.jpg"><meta data-vue-meta="true" name="DC.Format" content="text/html"><meta data-vue-meta="true" name="DC.Language" content="en"><meta data-vue-meta="true" name="DC.Title" content="Automatic Speech Emotion Recognition Using Machine Learning"><meta data-vue-meta="true" name="DC.Identifier" content="10.5772/intechopen.84856"><meta data-vue-meta="true" name="DC.Date" content="2019/03/25"><meta data-vue-meta="true" name="DC.Publisher" content="IntechOpen"><meta data-vue-meta="true" name="DC.AccessRights" content="open-access"><meta data-vue-meta="true" name="citation_fulltext_world_readable" content=""><meta data-vue-meta="true" name="citation_access" content="all"><meta data-vue-meta="true" name="citation_fulltext_html_url" content="https://www.intechopen.com/chapters/65993"><meta data-vue-meta="true" name="citation_publisher" content="IntechOpen"><meta data-vue-meta="true" name="citation_publication_date" content="2019/03/25"><meta data-vue-meta="true" name="citation_online_date" content="2019/03/25"><meta data-vue-meta="true" name="citation_title" content="Automatic Speech Emotion Recognition Using Machine Learning"><meta data-vue-meta="true" name="citation_doi" content="10.5772/intechopen.84856"><meta data-vue-meta="true" name="citation_pdf_url" content="https://www.intechopen.com/citation-pdf-url/65993"><meta data-vue-meta="true" name="citation_public_url" content="https://www.intechopen.com/chapters/65993"><meta data-vue-meta="true" name="citation_isbn" content="978-1-78984-028-5"><meta data-vue-meta="true" name="DC.relation.ispartof" content="Social Media and Machine Learning"><meta data-vue-meta="true" name="citation_inbook_title" content="Social Media and Machine Learning"><meta data-vue-meta="true" name="citation_author" content="Leila Kerkeni"><meta data-vue-meta="true" name="DC.Contributor" content="Leila Kerkeni"><meta data-vue-meta="true" name="citation_author" content="Youssef Serrestou"><meta data-vue-meta="true" name="DC.Contributor" content="Youssef Serrestou"><meta data-vue-meta="true" name="citation_author" content="Mohamed Mbarki"><meta data-vue-meta="true" name="DC.Contributor" content="Mohamed Mbarki"><meta data-vue-meta="true" name="citation_author" content="Kosai Raoof"><meta data-vue-meta="true" name="DC.Contributor" content="Kosai Raoof"><meta data-vue-meta="true" name="citation_author" content="Mohamed Ali Mahjoub"><meta data-vue-meta="true" name="DC.Contributor" content="Mohamed Ali Mahjoub"><meta data-vue-meta="true" name="citation_author" content="Catherine Cleder"><meta data-vue-meta="true" name="DC.Contributor" content="Catherine Cleder"><meta data-vue-meta="true" name="citation_reference" content="Ali H, Hariharan M, Yaacob S, Adom AH. Facial emotion recognition using empirical mode decomposition. Expert Systems with Applications. 2015;42(3):1261-1277"><meta data-vue-meta="true" name="citation_reference" content="Liu ZT, Wu M, Cao WH, Mao JW, Xu JP, Tan GZ. Speech emotion recognition based on feature selection and extreme learning machine decision tree. Neurocomputing. 2018;273:271-280"><meta data-vue-meta="true" name="citation_reference" content="Ragot M, Martin N, Em S, Pallamin N, Diverrez JM. Emotion recognition using physiological signals: Laboratory vs. wearable sensors. In: International Conference on Applied Human Factors and Ergonomics. Springer; 2017. pp. 15-22"><meta data-vue-meta="true" name="citation_reference" content="Surabhi V, Saurabh M. Speech emotion recognition: A review. International Research Journal of Engineering and Technology (IRJET). 2016;03:313-316"><meta data-vue-meta="true" name="citation_reference" content="Wu S, Falk TH, Chan WY. Automatic speech emotion recognition using modulation spectral features. Speech Communication. 2011;53:768-785"><meta data-vue-meta="true" name="citation_reference" content="Wu S. Recognition of human emotion in speech using modulation spectral features and support vector machines [PhD thesis]. 2009"><meta data-vue-meta="true" name="citation_reference" content="Tang J, Alelyani S, Liu H. Feature selection for classification: A review. Data Classification: Algorithms and Applications. 2014:37"><meta data-vue-meta="true" name="citation_reference" content="Martin V, Robert V. Recognition of emotions in German speech using Gaussian mixture models. LNAI. 2009;5398:256-263"><meta data-vue-meta="true" name="citation_reference" content="Ingale AB, Chaudhari D. Speech emotion recognition using hidden Markov model and support vector machine. International Journal of Advanced Engineering Research and Studies. 2012:316-318"><meta data-vue-meta="true" name="citation_reference" content="Milton A, Sharmy Roy S, Tamil Selvi S. SVM scheme for speech emotion recognition using MFCC feature. International Journal of Computer Applications. 2013;69"><meta data-vue-meta="true" name="citation_reference" content="Divya Sree GS, Chandrasekhar P, Venkateshulu B. SVM based speech emotion recognition compared with GMM-UBM and NN. IJESC. 2016;6"><meta data-vue-meta="true" name="citation_reference" content="Melki G, Kecman V, Ventura S, Cano A. OLLAWV: Online learning algorithm using worst-violators. Applied Soft Computing. 2018;66:384-393"><meta data-vue-meta="true" name="citation_reference" content="Pan Y, Shen P, Shen L. Speech emotion recognition using support vector machine. International Journal of Smart Home. 2012;6:101-108"><meta data-vue-meta="true" name="citation_reference" content="Peipei S, Zhou C, Xiong C. Automatic speech emotion recognition using support vector machine. IEEE. 2011;2:621-625"><meta data-vue-meta="true" name="citation_reference" content="Sathit P. Improvement of speech emotion recognition with neural network classifier by using speech spectrogram. International Conference on Systems, Signals and Image Processing (IWSSIP). 2015:73-76"><meta data-vue-meta="true" name="citation_reference" content="Alex G, Navdeep J. Towards end-to-end speech recognition with recurrent neural networks. In: International Conference on Machine Learning. Vol. 32. 2014"><meta data-vue-meta="true" name="citation_reference" content="Chen S, Jin Q. Multi-Modal Dimensional Emotion Recognition using Recurrent Neural Networks. Australia: Brisbane; 2015"><meta data-vue-meta="true" name="citation_reference" content="Lim W, Jang D, Lee T. Speech emotion recognition using convolutional and recurrent neural networks. Asia-Pacific. 2017:1-4"><meta data-vue-meta="true" name="citation_reference" content="Sara M, Saeed S, Rabiee A. Speech Emotion Recognition Based on a Modified Brain Emotional Learning Model. Biologically inspired cognitive architectures. Elsevier; 2017;19:32-38"><meta data-vue-meta="true" name="citation_reference" content="Yu G, Eric P, Hai-Xiang L, van den HJ. Speech emotion recognition using voiced segment selection algorithm. ECAI. 2016;285:1682-1683"><meta data-vue-meta="true" name="citation_reference" content="Kerkeni L, Serrestou Y, Mbarki M, Mahjoub M, Raoof K. Speech emotion recognition: Methods and cases study. In: International Conference on Agents and Artificial Intelligence (ICAART); 2018"><meta data-vue-meta="true" name="citation_reference" content="Cabanac M. What is emotion? Behavioural Processes. 2002;60(2):69-83"><meta data-vue-meta="true" name="citation_reference" content="Schacter DL, Gilbert DT, Wegner DM. Psychology (2nd Edition). New York: Worth; 2011"><meta data-vue-meta="true" name="citation_reference" content="Barrett LF, Russell JA. The Psychological Construction of Emotion. Guilford Publications; 2014"><meta data-vue-meta="true" name="citation_reference" content="James W. What is an emotion? Mind. 1884;9(34):188-205"><meta data-vue-meta="true" name="citation_reference" content="Boekaerts M. The Crucial Role of Motivation and Emotion in Classroom Learning. The Nature of Learning: Using Research to Inspire Practice 2010. Paris: OECD Publishing; pp. 91-111"><meta data-vue-meta="true" name="citation_reference" content="Kerkeni L, Serrestou Y, Mbarki M, Raoof K, Mahjoub MA. A review on speech emotion recognition: Case of pedagogical interaction in classroom. In: 2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP). IEEE; 2017. pp. 1-7"><meta data-vue-meta="true" name="citation_reference" content="Ekman P. An argument for basic emotions. Cognition &amp;amp; Emotion. 1992;6(3–4):169-200"><meta data-vue-meta="true" name="citation_reference" content="Matilda S. Emotion recognition: A survey. International Journal of Advanced Computer Research. 2015;3(1):14-19"><meta data-vue-meta="true" name="citation_reference" content="Koolagudi SG, Rao KS. Emotion recognition from speech: A review. International Journal of Speech Technology. 2012;15(2):99-117"><meta data-vue-meta="true" name="citation_reference" content="Schirmer A, Adolphs R. Emotion perception from face, voice, and touch: Comparisons and convergence. Trends in Cognitive Sciences. 2017;21(3):216-228"><meta data-vue-meta="true" name="citation_reference" content="He C, Yao Yj, Ye Xs. An emotion recognition system based on physiological signals obtained by wearable sensors. In: Wearable Sensors and Robots. Springer; 2017. pp. 15-25"><meta data-vue-meta="true" name="citation_reference" content="Srinivasan V, Ramalingam V, Arulmozhi P. Artificial Neural Network Based Pathological Voice Classification Using MFCC Features. International Journal of Science, Environment and Technology (Citeseer). 2014;3:291-302"><meta data-vue-meta="true" name="citation_reference" content="Aha DW, Bankert RL. Feature selection for case-based classification of cloud types: An empirical comparison. In: Proceedings of the AAAI-94 Workshop on Case-Based Reasoning. Vol. 106. 1994. p. 112"><meta data-vue-meta="true" name="citation_reference" content="Song P, Zheng W. Feature selection based transfer subspace learning for speech emotion recognition. IEEE Transactions on Affective Computing. 2018"><meta data-vue-meta="true" name="citation_reference" content="Duan KB, Rajapakse JC, Wang H, Azuaje F. Multiple SVM-RFE for gene selection in cancer classification with expression data. IEEE Transactions on NanoBioscience. 2005;4(3):228-234"><meta data-vue-meta="true" name="citation_reference" content="Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. SCIKIT-learn: Machine learning in Python. Journal of Machine Learning Research. 2011;12:2825-2830"><meta data-vue-meta="true" name="citation_reference" content="Guyon I, Weston J, Barnhill S, Vapnik V. Gene selection for cancer classification using support vector machines. Machine Learning. 2002;46(1–3):389-422"><meta data-vue-meta="true" name="citation_reference" content="Naseem I, Togneri R, Bennamoun M. Linear regression for face recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence. 2010;32:2106-2112"><meta data-vue-meta="true" name="citation_reference" content="Gunn SR. Support vector machines for classification and regression [PhD thesis]. 1998"><meta data-vue-meta="true" name="citation_reference" content="SVM and Kernel Methods MATLAB Toolbox. Available from: http://asi.insa-rouen.fr/enseignants/ ∼arakoto/toolbox/"><meta data-vue-meta="true" name="citation_reference" content="Parthasarathy S, Tashev I. Convolutional neural network techniques for speech emotion recognition. In: 2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC). IEEE; 2018. pp. 121-125"><meta data-vue-meta="true" name="citation_reference" content="Sepp H, Jurgen S. Long Short-term Memory. Neural Computation. 1997;9:1735-1780"><meta data-vue-meta="true" name="citation_reference" content="Vaudable C. Analyse et reconnaissance des émotions lors de conversations de centres d’appels [PhD thesis]. Université Paris Sud-Paris XI; 2012"><meta data-vue-meta="true" name="citation_reference" content="Swain M, Routray A, Kabisatpathy P. Databases, features and classifiers for speech emotion recognition: A review. International Journal of Speech Technology. 2018;21:1-28"><meta data-vue-meta="true" name="citation_reference" content="Burkhardt F, Paeschke A, Rolfes M, Sendlmeier W, Weiss B. A Database of German Emotional Speech. INTERSPEECH; 2005"><meta data-vue-meta="true" name="citation_reference" content="Berlin Database of Emotional Speech. Available from: http://emodb.bilderbar.info/start.html"><meta data-vue-meta="true" name="citation_reference" content="Berlin Database of Emotional Speech. Available from: http://www.elra.info/en/catalogues/ catalogue-language-resources/"><script src="https://www.google.com/recaptcha/api.js?onload=vueRecaptchaApiLoaded&render=explicit" async defer="defer"></script><script async src="https://badge.dimensions.ai/badge.js" charset="utf-8"></script><script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script><link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="manifest" href="/site.webmanifest"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="red"><meta name="msapplication-TileColor" content="#e10000"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css"><style>@font-face{font-family:'Relative Faux';font-style:normal;font-weight:400;src:url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.eot);src:local("Relative Faux"),local("Relative-Faux"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.eot#iefix) format("embedded-opentype"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.woff) format("woff"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.otf) format("otf"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.woff2) format("woff2"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.ttf) format("ttf")}.cc-window{font-family:'Relative Faux',Helvetica;border-top:.2em solid rgba(0,0,0,.1)}</style><script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script><script>window.addEventListener("load",function(){window.cookieconsent.initialise({palette:{popup:{background:"#e10000",text:"#fffad2"},button:{background:"transparent",text:"#fffad2",border:"#fffad2"}},content:{message:"IntechOpen uses cookies to offer you the best online experience. By continuing to use our site, you agree to our",link:"Privacy Policy",href:"https://www.intechopen.com/privacy-policy"}})})</script><script type="text/javascript">var googletag=googletag||{cmd:[]}</script><script src="//cdnjs.cloudflare.com/ajax/libs/postscribe/2.0.8/postscribe.min.js"></script><script async src="https://securepubads.g.doubleclick.net/tag/js/gpt.js"></script><script async src="//js-sec.indexww.com/ht/p/193682-67584184340778.js"></script><!-- Start VWO Async SmartCode --><script type="text/javascript">window._vwo_code=window._vwo_code||function(){var e="body",t=!1,i=document,n={use_existing_jquery:function(){return!1},library_tolerance:function(){return 2500},finish:function(){if(!t){t=!0;var e=i.getElementById("_vis_opt_path_hides");e&&e.parentNode.removeChild(e)}},finished:function(){return t},load:function(e){var t=i.createElement("script");t.src=e,t.type="text/javascript",t.innerText,t.onerror=function(){_vwo_code.finish()},i.getElementsByTagName("head")[0].appendChild(t)},init:function(){window.settings_timer=setTimeout(function(){_vwo_code.finish()},2e3);var t=i.createElement("style"),n=e+"{opacity:0 !important;filter:alpha(opacity=0) !important;background:none !important;}",o=i.getElementsByTagName("head")[0];return t.setAttribute("id","_vis_opt_path_hides"),t.setAttribute("type","text/css"),t.styleSheet?t.styleSheet.cssText=n:t.appendChild(i.createTextNode(n)),o.appendChild(t),this.load("https://dev.visualwebsiteoptimizer.com/j.php?a=531576&u="+encodeURIComponent(i.URL)+"&f=1&r="+Math.random()),settings_timer}};return window._vwo_settings_timer=n.init(),n}()</script><!-- End VWO Async SmartCode --><link rel="preload" href="//cdnintech.com/web/frontend/www/dist/manifest.738d20ca0ff2771c5ad6.js" as="script"><link rel="preload" href="//cdnintech.com/web/frontend/www/dist/vendor.df6b45c13d4920726136.js" as="script"><link rel="preload" href="//cdnintech.com/web/frontend/www/dist/app.bc4054f78c29dd68d7ff.js" as="script"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/26.1318da4498a90794091c.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/0.a0d7b02aca096ac8f8a0.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/2.6923ac2dc9b83af79025.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/3.77b2e477ff1bbacf7130.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/4.cfc2f6cabfe110a5a02a.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/5.f88474e1983978930930.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/6.e10308c67c1c235fea0e.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/7.8f07ca9f5e683a9fa180.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/8.a03fb39e43f0676cb5ee.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/9.9eefcecae186d195ded5.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/10.6807d25a7b1817f918f6.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/11.81acbd5451048308bbcd.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/12.861abda2ac9dd27183e1.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/13.d8426c849b7384b28bf8.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/14.b2660c1dd0c10953a1f3.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/15.68c7ebc6e7a3e0b6f432.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/16.8eeb7c35b6711284f644.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/17.94903346f5c97b8b3575.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/18.26133015aed60cd7fca9.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/19.efab063b641c13fd4b1e.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/20.348973b03ef6dc832576.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/21.f1b004a5da605216fb16.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/22.7baedaad6901aadfb17e.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/23.06af15fb86389e892efa.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/24.948a7b4bf43a76c73098.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/25.1a7a622c65d285f872c5.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/1.fb27b37d9fbac37a247a.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/27.658cd1d0498fafc84df8.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/28.b1d92841445951d8b97b.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/31.cc7f0751a0aacb009fc9.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/32.d6fd2cead66709d7d7b2.js"><link rel="prefetch" href="//cdnintech.com/web/frontend/www/dist/33.429c7bfca091f7b10f23.js"><style data-vue-ssr-id="3856b5b0:0 5e6db1ff:0 5acc8643:0 0283e8e9:0 2ec6c9a5:0 ff4645a2:0 c50de89a:0 5b900b40:0 7ab4c461:0 8b406100:0 4435b412:0 224785e6:0 3122ccab:0 eb28b2b2:0 259b8763:0 16927e8b:0 153e6f2c:0 7f1127f8:0 020b6d54:0 c8285a78:0 3ab19a70:0 966307c4:0 55720a8a:0 8b9fe710:0 6e27fdd0:0 d68d149a:0 989ca0c6:0 8c8edcbe:0 13729129:0 b9c5869a:0 36da7140:0 59fcc454:0 187bb7e5:0">@charset "UTF-8";@font-face{font-family:FSBrabo;font-style:normal;font-weight:400;src:url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Regular.eot);src:local("FS Brabo Regular"),local("FSBrabo-Regular"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Regular.eot#iefix) format("embedded-opentype"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Regular.woff) format("woff")}@font-face{font-family:FSBrabo;font-style:italic;font-weight:400;src:url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Italic.eot);src:local("FS Brabo Italic"),local("FSBrabo-Italic"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Italic.eot#iefix) format("embedded-opentype"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Italic.woff) format("woff")}@font-face{font-family:FSBrabo;font-style:normal;font-weight:700;src:url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Bold.eot);src:local("FS Brabo Bold"),local("FSBrabo-Bold"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Bold.eot#iefix) format("embedded-opentype"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-Bold.woff) format("woff")}@font-face{font-family:FSBrabo;font-style:italic;font-weight:700;src:url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-BoldItalic.eot);src:local("FS Brabo BoldItalic"),local("FSBrabo-BoldItalic"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-BoldItalic.eot#iefix) format("embedded-opentype"),url(//cdnintech.com/web/frontend/www/dist/fonts/FSBraboWeb-BoldItalic.woff) format("woff")}@font-face{font-family:'Relative Faux';font-style:normal;font-weight:400;src:url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.eot);src:local("Relative Faux"),local("Relative-Faux"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.eot#iefix) format("embedded-opentype"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.woff) format("woff"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.otf) format("otf"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.woff2) format("woff2"),url(//cdnintech.com/web/frontend/www/dist/fonts/relative-faux.ttf) format("ttf")}.button-type-1{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.4em;letter-spacing:1px;color:#fffad2;text-transform:uppercase;text-align:center;display:inline-block;padding:1.2rem 0;border:1px solid #e10000;border-radius:2px;box-shadow:0 1px 2px 0 rgba(0,0,0,.2);background-color:#e10000;box-sizing:border-box}.button-type-1:hover{color:#fffad2;background-color:#b40000;border-color:#b40000}.button-type-2{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.4em;letter-spacing:1px;text-transform:uppercase;text-align:center;display:inline-block;padding:1.2rem 0;border:1px solid #e10000;border-radius:2px;box-shadow:0 1px 2px 0 rgba(0,0,0,.2);color:#e10000;box-sizing:border-box}.button-type-2:hover{color:#fffad2;background-color:#b40000;border-color:#b40000}.button-type-3{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.4em;letter-spacing:1px;text-transform:uppercase;text-align:center;display:inline-block;padding:1.5rem 0;border:1px solid #fffad2;border-radius:2px;color:#fffad2;box-sizing:border-box}.button-type-3:hover{color:#e10000;background-color:#fffad2}.link-type-1{text-decoration:underline}.link-type-2{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;color:#e10000}.link-type-2:hover{text-decoration:underline}.ais-highlight em,.ais-snippet em{font-style:normal;background-color:#e10000;color:#fffad2}.clear{clear:both}@font-face{font-family:intech;src:url(//cdnintech.com/web/frontend/www/dist/fonts/InTech.eot?v1.0);src:url(//cdnintech.com/web/frontend/www/dist/fonts/InTech.eot?v1.0#iefix) format("embedded-opentype"),url(//cdnintech.com/web/frontend/www/dist/fonts/InTech.woff?v1.0) format("woff"),url(//cdnintech.com/web/frontend/www/dist/fonts/InTech.ttf?v1.0) format("truetype"),url(//cdnintech.com/web/frontend/www/dist/fonts/InTech.svg?v1.0//cdnintech.com/web/frontend/www/dist/fonts/InTech) format("svg");font-weight:400;font-style:normal}[class*=" icon"],[class^=icon]{display:inline-block;position:relative;padding-left:40px}[class*=" icon"]:before,[class^=icon]:before{font-family:intech;speak:none;font-style:normal;font-weight:400;font-variant:normal;text-transform:none;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;position:absolute;left:0;top:50%;margin:0;width:40px;height:40px;line-height:40px;margin-top:-20px;text-align:center;text-indent:0}.iconFb:before{content:"\E912"}.iconLinkedIn:before{content:"\E913"}.iconTwitter:before{content:"\E914"}.iconYt:before{content:"\E915"}.iconGoogle:before{content:"\E916"}.iconStumbleupon:before{content:"\E917"}.iconCiteulike:before{content:"\E919"}.iconReddit:before{content:"\E91A"}.iconBibsonomy:before{content:"\E918"}.iconCheck:before{content:"\E902"}.iconBook:before{content:"\E901"}.iconArrowRight:before{content:"\E903"}.iconArrowRightThin:before{content:"\E904"}.iconArrowDown:before{content:"\E900"}.iconCirclePlus:before{content:"\E905"}.iconLike:before{content:"\E906"}.iconPdf:before{content:"\E907"}.iconPlay:before{content:"\E908"}.iconPrint:before{content:"\E909"}.iconQuoteRight:before{content:"\E90A"}.iconQuoteLeft:before{content:"\E90B"}.iconSearch:before{content:"\E90C"}.iconShare:before{content:"\E90D"}.iconTimer:before{content:"\E90E"}.iconTranslate:before{content:"\E90F"}.iconUser:before{content:"\E910"}.iconClose:before{content:"\E911"}a{text-decoration:none;cursor:pointer;color:inherit}a::-moz-focus-inner,a:focus{outline:0}a,dd,dl,dt,fieldset,h1,h2,h3,h4,li,ol,p,td,ul{margin:0;padding:0;list-style:none;border:0;font-size:1em}table{border-collapse:collapse;border-spacing:0}img{vertical-align:bottom}button,input,select,textarea{font-family:inherit;font-size:100%;margin:0;outline:0;box-sizing:border-box;border-radius:0}textarea{overflow:auto;vertical-align:top;resize:vertical}button,label{cursor:pointer}html{font-size:62.5%}body{font-size:1em}figure{margin:0}.cf::after{clear:both;content:"";display:block}.icr{padding:0;display:inline-block;width:40px;height:40px;text-indent:-9999em;overflow:hidden}.icr:before{right:0;width:auto;text-indent:0}.nBtn{margin:0;padding:0;border:0;cursor:pointer;background:0 0;text-align:left}.nBtn::-moz-focus-inner{padding:0;border:0}body,html{min-height:100%;background-color:#fffad2}a{color:inherit}body{font-family:FSBrabo,serif;font-weight:400;font-style:normal;min-width:32em;position:relative;overflow-x:hidden;color:#000;margin:0}.capitalize{display:inline-block}.capitalize:first-letter{text-transform:uppercase}@media screen and (max-width:62.5em){.page-header[data-v-a6e59acc]{min-height:5.6em;background:#e10000}.page-header .search-term[data-v-a6e59acc]{display:none}.page-header.has-search .search-term[data-v-a6e59acc]{display:block}.page-header .wrap[data-v-a6e59acc]{display:none}.page-header .wrap.expanded[data-v-a6e59acc]{display:block}.search-term[data-v-a6e59acc]{background:#000;position:absolute!important;z-index:100;left:0;right:0}.search-term[data-v-a6e59acc] input{padding:1.5rem 1rem!important;border-width:0!important;width:100%}.search-term[data-v-a6e59acc] span{display:none}.toggle[data-v-a6e59acc]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.4em;line-height:1;color:#fffad2;text-transform:uppercase;display:inline-block;padding:1rem 2rem;border:1px solid #fffad2;border-radius:2px;box-shadow:0 1px 2px 0 rgba(0,0,0,.2)}.branding[data-v-a6e59acc]{position:absolute;left:50%;top:1.1em;margin-left:-1.7em}.branding img[data-v-a6e59acc]{display:block;width:3.4em}.bar[data-v-a6e59acc]{position:relative;padding:1em}.bar .aside[data-v-a6e59acc]{float:right}.bar .user-profile[data-v-a6e59acc]{font-size:2.7rem;color:#fffad2;margin-right:.5rem}.bar .search[data-v-a6e59acc]{font-size:2.8em;color:#fffad2;margin-left:.5rem}.wrap[data-v-a6e59acc]{position:fixed;top:0;left:0;right:0;bottom:0;z-index:1000;padding:1em;background:#000;overflow-y:auto;-webkit-overflow-scrolling:touch}.site-nav[data-v-a6e59acc]{margin:2em -1rem 0}.nav-item[data-v-a6e59acc]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.8em;line-height:1.33333;color:#fffad2;text-align:center;display:block;border-bottom:1px solid #333;padding:2rem 1rem}.nav-item.router-link-exact-active[data-v-a6e59acc]{color:#000;background:#fffad2}.sub-nav[data-v-a6e59acc]{padding:1em 0;border-bottom:1px solid #333}.drop-item[data-v-a6e59acc],.sub-nav-item[data-v-a6e59acc]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.4em;line-height:1.42857;color:#fffad2;text-align:center;display:block}.drop-item.router-link-exact-active[data-v-a6e59acc],.sub-nav-item.router-link-exact-active[data-v-a6e59acc]{text-decoration:underline}.sub-nav-item[data-v-a6e59acc]{padding:2rem 1rem}.drop-item[data-v-a6e59acc]{padding:1.5rem 1rem}.cta[data-v-a6e59acc]{width:100%;margin:2rem 0}.nav-dropdown[data-v-a6e59acc]{margin-bottom:2em}.nav-dropdown .nav-item[data-v-a6e59acc],.nav-dropdown p[data-v-a6e59acc]{display:none}}@media screen and (min-width:34.4375em) and (max-width:62.5em){.bar .link[data-v-a6e59acc]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.6em;line-height:2.2;color:#fffad2;float:left;position:relative;padding:0 1.2rem}.bar .link[data-v-a6e59acc]:first-child:before{content:"";position:absolute;top:50%;right:0;height:2rem;width:1px;margin-top:-1rem;background:#fffad2}.drop-item[data-v-a6e59acc],.sub-nav-item[data-v-a6e59acc]{font-size:1.6em}.sub-nav li[data-v-a6e59acc]{display:inline-block;width:50%}.cta-wrap[data-v-a6e59acc]{text-align:center}.cta[data-v-a6e59acc]{width:23rem;margin:6rem 0 4rem}.nav-dropdown[data-v-a6e59acc]{text-align:center;max-width:60em;margin:0 auto 2em}.drop-box[data-v-a6e59acc],.drop-item[data-v-a6e59acc]{display:inline-block}}@media screen and (min-width:62.5625em){.page-header[data-v-a6e59acc]{height:9em;background:#e10000}.page-header.has-subnav[data-v-a6e59acc]{height:13em}.page-header.has-double-subnav[data-v-a6e59acc]{height:17em}.page-header .wrap[data-v-a6e59acc]{transition:transform .2s ease-in .3s;position:fixed;z-index:1000;top:0;left:0;right:0;background:#e10000}.page-header .wrap[data-v-a6e59acc]::after{clear:both;content:"";display:block}.branding[data-v-a6e59acc]{position:absolute;left:50%;top:50%;margin:-2.45em 0 0 -2.45em;width:4.9em}.page-header.home .branding[data-v-a6e59acc]{margin:-1.25em 0 0 -8.5em;width:17em}.site-nav[data-v-a6e59acc]{padding:0 2em;float:left}.site-nav li[data-v-a6e59acc]{display:inline-block}.site-nav .nav-item[data-v-a6e59acc]{padding:3.5rem 1.5rem 3.5rem 2rem}.site-nav .nav-item.iconArrowDown[data-v-a6e59acc]{padding-left:2rem;padding-right:3.5rem}.site-nav .nav-item.iconArrowDown[data-v-a6e59acc]:before{font-size:.6em;left:auto;right:0;margin-top:-18px}.nav-item[data-v-a6e59acc]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.6em;line-height:1.25;color:#fffad2;display:block}.nav-item.router-link-exact-active[data-v-a6e59acc],.nav-item[data-v-a6e59acc]:hover{text-decoration:underline}.nav-item.active-drop[data-v-a6e59acc]{background:#000;text-decoration:underline}.sub-nav[data-v-a6e59acc]{position:absolute;top:9em;left:0;right:0;background:#f2edc7;text-align:center}.sub-nav-item[data-v-a6e59acc]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.5em;line-height:2rem;color:#e10000;display:inline-block;padding:1rem 2rem}.sub-nav-item.router-link-active[data-v-a6e59acc],.sub-nav-item[data-v-a6e59acc]:hover{text-decoration:underline}.p-link[data-v-a6e59acc]{color:#e10000}.p-link[data-v-a6e59acc]:hover{color:#870000}.aside[data-v-a6e59acc]{float:right;margin-right:2em}.aside ul[data-v-a6e59acc]{display:inline-block;margin-right:3em}.aside li[data-v-a6e59acc]{display:inline-block}.aside .nav-item[data-v-a6e59acc]{padding:3.5rem 0}.nav-dropdown[data-v-a6e59acc]{position:absolute;top:9em;left:0;right:0;background:#000}.nav-dropdown.collapsed[data-v-a6e59acc]{display:none}.nav-dropdown .inner[data-v-a6e59acc]{max-width:129em;margin:0 auto}.drop-box[data-v-a6e59acc]{display:inline-block;vertical-align:top;width:25%;box-sizing:border-box;padding:6em 3em}.drop-box .nav-item[data-v-a6e59acc]{margin-bottom:2rem}.drop-box p[data-v-a6e59acc]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.5em;line-height:1.6;color:#fff;margin-bottom:2rem}.drop-box p a[data-v-a6e59acc]{color:#fffad2}.drop-box p a[data-v-a6e59acc]:hover{text-decoration:underline}.drop-item[data-v-a6e59acc]{font-size:1.8em;line-height:1.33;color:#fffad2;display:block;margin-bottom:3rem}.drop-item.router-link-active[data-v-a6e59acc],.drop-item[data-v-a6e59acc]:hover{text-decoration:underline}}@media screen and (min-width:62.5625em){#app[data-scrolldir=up] .page-header .wrap{transform:translateY(0)}#app[data-scrolldir=down] .page-header .wrap{transform:translateY(-100%)}#app[data-scrolldir=down] .page-header.has-subnav .wrap{transform:translateY(-13em)}#app[data-scrolldir=down] .page-header.has-double-subnav .wrap{transform:translateY(-17em)}}.search-term[data-v-36b4823c]{position:relative;display:inline-block}.search-term input[data-v-36b4823c]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.6em;line-height:1.5;color:#fff;padding:.5rem 1rem;border:2px solid #fffad2;border-radius:2px;background:0 0}.search-term input[data-v-36b4823c]::placeholder{color:#fffad2;opacity:1}.search-term .iconSearch[data-v-36b4823c]{position:absolute;left:initial;right:0;top:50%;margin-top:-2rem;color:#fffad2;background:0 0;border:0}.search-term .iconSearch[data-v-36b4823c]:before{font-size:2em}.ad-wraper[data-v-89ab6a34]{text-align:center;margin-bottom:5rem}.left-aside[data-v-89ab6a34]{padding-left:0!important;padding-right:1em;width:auto!important;height:1000px}.main[data-v-89ab6a34]{padding-left:1em}.chapter[data-v-89ab6a34]{max-width:117em;margin:0 auto;box-sizing:border-box;padding:0 2em}@media screen and (max-width:34.375em){.chapter[data-v-89ab6a34]{padding:0 1.5em}.chapter .aside[data-v-89ab6a34]{margin-bottom:5rem}}@media screen and (min-width:34.4375em){.chapter[data-v-89ab6a34]{padding:0 2em}.chapter .aside[data-v-89ab6a34]{margin-bottom:5rem}.chapter .main .inner[data-v-89ab6a34]{max-width:60em;margin:0 auto}}@media screen and (min-width:62.5625em){.chapter .wrap[data-v-89ab6a34]{display:table;width:100%}.chapter .aside[data-v-89ab6a34]{display:table-cell;vertical-align:top;width:27em;padding-left:2em}.chapter .aside .track[data-v-89ab6a34]{transition:top .2s ease-in .3s;transform:translate3d(0,0,0);position:-webkit-sticky;position:sticky;top:2rem}.chapter .main[data-v-89ab6a34]{display:table-cell;vertical-align:top}.chapter .main .inner[data-v-89ab6a34]{max-width:68em;margin:0 auto}}.reader-body[data-v-89ab6a34] ul{line-height:1.7;margin-bottom:3rem;margin-top:3rem}.reader-body[data-v-89ab6a34] ul li{position:relative;padding-left:3rem;margin-bottom:1rem}.reader-body[data-v-89ab6a34] ul li:before{content:'';position:absolute;left:10px;top:12px;width:6px;height:6px;background:#e10000}@media screen and (max-width:34.375em){.reader-body[data-v-89ab6a34] ul li{padding-left:2rem}.reader-body[data-v-89ab6a34] ul li:before{left:0}}@media screen and (max-width:50em){.reader-body[data-v-89ab6a34] ul{line-height:1.4}.reader-body[data-v-89ab6a34] ul li:before{top:8px}}.ads-link[data-v-89ab6a34]{display:block;font-size:1.2rem;letter-spacing:1px;text-decoration:none;text-align:center;text-transform:uppercase;color:#777}.ads-link[data-v-89ab6a34]:hover{color:#777}.ads-link[data-v-89ab6a34]:after{content:none!important}.ads[data-v-89ab6a34]{margin-bottom:5rem;text-align:center}.ads a[data-v-89ab6a34]:after{content:none!important}.ads a[data-v-89ab6a34]:hover{color:#4d4d4d}@media screen and (min-width:62.5625em){#app[data-scrolldir=up] .chapter .track{top:11rem}}.intro[data-v-8cec8ff0]{background:#e10000;color:#fffad2}.wrap[data-v-8cec8ff0]{max-width:117em;margin:0 auto;text-align:center}.subtitle[data-v-8cec8ff0]{font-size:1.7rem;line-height:1.6;font-style:italic}.mb[data-v-8cec8ff0]{margin-bottom:4rem;font-size:2rem}.title[data-v-8cec8ff0]{font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.title[data-v-8cec8ff0]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.title[data-v-8cec8ff0]{font-size:3.4rem;margin-bottom:2rem}}@media screen and (min-width:50.0625em){.title[data-v-8cec8ff0]{font-size:4rem;margin-bottom:3rem}}.text[data-v-8cec8ff0]{line-height:1.5}.text a[data-v-8cec8ff0]{position:relative;color:#fffad2}.text a[data-v-8cec8ff0]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#fffad2 0,#fffad2 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.text a[data-v-8cec8ff0]:hover:after{display:none}.subtext[data-v-8cec8ff0]{font-size:1.7rem;line-height:1.6;font-size:2rem}.subtext span[data-v-8cec8ff0]{display:inline-block;margin-left:1rem}.award[data-v-8cec8ff0]{margin-top:4rem;font-weight:700;margin-bottom:-3rem;font-size:2.8rem}@media screen and (max-width:34.375em){.intro[data-v-8cec8ff0]{margin-bottom:2rem}.wrap[data-v-8cec8ff0]{padding:5em 2em}.title[data-v-8cec8ff0]{margin:1rem 0 1rem}.text[data-v-8cec8ff0]{font-size:2.2em}}@media screen and (min-width:34.4375em) and (max-width:50em){.intro[data-v-8cec8ff0]{margin-bottom:2rem}.wrap[data-v-8cec8ff0]{padding:5em 2em}.title[data-v-8cec8ff0]{margin:1.3rem 0 1rem}.text[data-v-8cec8ff0]{font-size:2.6em}}@media screen and (min-width:50.0625em){.intro[data-v-8cec8ff0]{margin-bottom:3rem}.wrap[data-v-8cec8ff0]{padding:6em 2em 9em}.title[data-v-8cec8ff0]{margin:1.5rem 0 1rem}.text[data-v-8cec8ff0]{font-size:2.8em}}.breadcrumbs[data-v-80d35b96]{max-width:117em;margin:3rem auto 0;box-sizing:border-box;padding:0 2em}.breadcrumbs p[data-v-80d35b96]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.5em}.breadcrumbs a[data-v-80d35b96]{color:#e10000}.breadcrumbs a[data-v-80d35b96]:hover{color:#870000}.breadcrumbs span[data-v-80d35b96]{color:#e10000}@media screen and (max-width:34.375em){.breadcrumbs[data-v-80d35b96]{padding:0 0 0 1.5em;position:relative}.breadcrumbs[data-v-80d35b96]:after{content:" ";position:absolute;top:0;right:0;bottom:0;width:2.5em;background-image:linear-gradient(to right,transparent,#fffad2)}.breadcrumbs .wrap[data-v-80d35b96]{overflow-x:scroll;padding-bottom:1.5rem;white-space:nowrap;-webkit-overflow-scrolling:touch}.breadcrumbs p span[data-v-80d35b96]{margin-right:3rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.breadcrumbs[data-v-80d35b96]{margin-bottom:3em}}@media screen and (min-width:50.0625em){.breadcrumbs[data-v-80d35b96]{margin-bottom:4em}}.info[data-v-b8b16c92]{border:1px solid #e10000;border-width:1px 0;padding:.8em 0}.info a[data-v-b8b16c92],.info p[data-v-b8b16c92]{font-size:1.8em;line-height:2}.info a[data-v-b8b16c92]{color:#e10000;margin-right:3rem;display:none}.info a[data-v-b8b16c92]:hover{color:#870000}@media screen and (max-width:34.375em){.info[data-v-b8b16c92]{margin-bottom:2em}.info .block p[data-v-b8b16c92]{display:block}}@media screen and (min-width:34.4375em){.info .block[data-v-b8b16c92]{float:right}.info .block[data-v-b8b16c92]:last-child{float:none}.info .block:last-child p[data-v-b8b16c92]{margin-right:3rem}.info .block p[data-v-b8b16c92]{display:inline-block}.info .block p span[data-v-b8b16c92]{display:inline-block}}@media screen and (min-width:34.4375em) and (max-width:50em){.info[data-v-b8b16c92]{margin-bottom:3em}}@media screen and (min-width:50.0625em){.info[data-v-b8b16c92]{margin-bottom:5em}}.correction-link[data-v-521ed6a8]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6;color:#e10000}.correction-link[data-v-521ed6a8]:hover{color:#870000}.correction[data-v-521ed6a8]{margin-bottom:2em}.intro .title[data-v-1e8b6f8e]{font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.intro .title[data-v-1e8b6f8e]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.intro .title[data-v-1e8b6f8e]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.intro .title[data-v-1e8b6f8e]{font-size:2.6rem;margin-bottom:4rem}}@media screen and (max-width:34.375em){.intro .body[data-v-1e8b6f8e]{font-size:1.8rem;line-height:1.6}}@media screen and (min-width:34.4375em) and (max-width:50em){.intro .body[data-v-1e8b6f8e]{font-size:1.9rem;line-height:1.6}}@media screen and (min-width:50.0625em){.intro .body[data-v-1e8b6f8e]{font-size:2rem;line-height:1.7}}.intro .body[data-v-1e8b6f8e] p{margin-bottom:3rem}.keywords[data-v-64821705]{margin-bottom:5rem}.keywords .subTitle[data-v-64821705]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;margin-bottom:2rem}@media screen and (max-width:50em){.keywords .subTitle[data-v-64821705]{font-size:2rem}}@media screen and (min-width:50.0625em){.keywords .subTitle[data-v-64821705]{font-size:2.2rem}}.keywords .item[data-v-64821705]{font-size:1.3em;line-height:1.69231em;color:#fffad2;padding:1px .76923em 0;margin:0 1rem 1rem 0;background:#e10000;border-radius:2px;display:inline-block}.title[data-v-076a6caa]{font-size:2em;margin-bottom:1rem}.position[data-v-076a6caa]{font-style:italic;font-size:1.5em}.list[data-v-076a6caa]{line-height:1.7;margin-bottom:3rem;margin-top:3rem}.list li[data-v-076a6caa]{position:relative;padding-left:3rem;margin-bottom:1rem}.list li[data-v-076a6caa]:before{content:'';position:absolute;left:10px;top:12px;width:6px;height:6px;background:#e10000}@media screen and (max-width:34.375em){.list li[data-v-076a6caa]{padding-left:2rem}.list li[data-v-076a6caa]:before{left:0}}@media screen and (max-width:50em){.list[data-v-076a6caa]{line-height:1.4}.list li[data-v-076a6caa]:before{top:8px}}.info[data-v-076a6caa]{border-bottom:1px solid #000;margin-bottom:5rem;position:relative}.info>.title[data-v-076a6caa]{font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.info>.title[data-v-076a6caa]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.info>.title[data-v-076a6caa]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.info>.title[data-v-076a6caa]{font-size:2.6rem;margin-bottom:4rem}}.info .wrap[data-v-076a6caa]{display:block}.info.collapsed .wrap[data-v-076a6caa]{display:none}.info .subTitle[data-v-076a6caa]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;margin-bottom:2rem}@media screen and (max-width:50em){.info .subTitle[data-v-076a6caa]{font-size:2rem}}@media screen and (min-width:50.0625em){.info .subTitle[data-v-076a6caa]{font-size:2.2rem}}.info .doi[data-v-076a6caa]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.5em;margin-bottom:2rem}.info .authorsItem[data-v-076a6caa]{margin-bottom:3rem}.info .authorsItem .author[data-v-076a6caa]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:2em;color:#e10000}.info .authorsItem .body[data-v-076a6caa]{font-size:1.7rem;line-height:1.6;font-style:italic}.info .authorsItem .mail[data-v-076a6caa]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;position:relative;color:#e10000;font-size:1.6em;line-height:2;display:inline-block}.info .authorsItem .mail[data-v-076a6caa]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#e10000 0,#e10000 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.info .authorsItem .mail[data-v-076a6caa]:before{content:"\E903";font-family:intech;font-size:.6em;position:absolute;right:-1.5em;top:50%;bottom:0;margin-top:-.8rem}.info .authorsItem .mail[data-v-076a6caa]:hover{color:#870000}.info .authorsItem .mail[data-v-076a6caa]:hover:after{background-image:linear-gradient(to right,#ae0000 0,#ae0000 100%)}.info .book[data-v-076a6caa]{margin-bottom:5rem}.info .book .cover[data-v-076a6caa]{float:right;margin-left:2rem;width:14.6rem}.info .book .title[data-v-076a6caa]{font-size:2em;margin-bottom:1rem}.info .book .title a[data-v-076a6caa]{color:#e10000}.info .book .title a[data-v-076a6caa]:hover{color:#870000}.info .book .bookInfo[data-v-076a6caa]{font-size:1.7em}.info .book .bookInfo a[data-v-076a6caa]{position:relative;color:#000}.info .book .bookInfo a[data-v-076a6caa]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#000 0,#000 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.info .book .bookInfo a[data-v-076a6caa]:hover:after{display:none}@media screen and (max-width:34.375em){.info .book .cover[data-v-076a6caa]{display:none}}.info .toggle[data-v-076a6caa]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;color:#e10000;font-size:1.5em;position:absolute;top:.5rem;right:0}.info .toggle[data-v-076a6caa]:hover{color:#870000}.cover-wrap[data-v-82939336]{position:relative;display:block;overflow:hidden}.cover-wrap a[data-v-82939336]{display:block}.cover-wrap[data-v-82939336]:after{content:'';position:absolute;left:-1px;top:0;bottom:0;width:1px;box-shadow:3px 0 2px rgba(0,0,0,.6);z-index:10}.cover-wrap[data-v-82939336]:before{content:'';position:absolute;left:3%;right:0;top:0;bottom:0;width:1px;background:rgba(0,0,0,.05);border-right:1px solid rgba(0,0,0,.08);box-shadow:-1px 0 2px rgba(255,255,255,.3);z-index:10}.lazy-image[data-v-82939336]{display:block;width:100%}.svg[data-v-82939336]{position:absolute;top:50%;left:0;z-index:1;width:100%;transform:translateY(-50%)}.text[data-v-82939336]{color:#fffad2;padding:0 2em;box-sizing:border-box;text-align:center;position:absolute;left:0;z-index:2;width:100%;white-space:normal}.text .title[data-v-82939336]{font-size:1.8em;display:block}.text .sub-title[data-v-82939336]{font-size:1.1em;display:block}.text .editors[data-v-82939336]{font-size:1em;font-style:italic;margin-top:1rem;display:block}.cover-wrap.top .text[data-v-82939336]{top:40%}.cover-wrap.middle .text[data-v-82939336]{top:50%;transform:translateY(-50%)}.lazy-image[data-v-d261b71c]{position:relative;display:block;overflow:hidden;width:100%;background-color:#fff9c5}.lazy-image.ar1[data-v-d261b71c]{padding-bottom:144.3%}.lazy-image.ar2[data-v-d261b71c]{padding-bottom:100%}.image[data-v-d261b71c]{position:absolute;left:0;right:0;top:0;bottom:0;margin:auto;width:100%;min-height:100%}.fade-enter-active[data-v-d261b71c],.fade-leave-active[data-v-d261b71c]{transition:opacity .5s ease-in}.fade-enter[data-v-d261b71c],.fade-leave-to[data-v-d261b71c]{transform:scale(1);opacity:0}.reader-body[data-v-0f4986cb] .main-title{font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.reader-body[data-v-0f4986cb] .main-title{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.reader-body[data-v-0f4986cb] .main-title{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.reader-body[data-v-0f4986cb] .main-title{font-size:2.6rem;margin-bottom:4rem}}.reader-body[data-v-0f4986cb] .section-title,.reader-body[data-v-0f4986cb] .subsection-title{font-family:FSBrabo,serif;font-weight:400;font-style:normal;margin-bottom:2rem}@media screen and (max-width:50em){.reader-body[data-v-0f4986cb] .section-title,.reader-body[data-v-0f4986cb] .subsection-title{font-size:2rem}}@media screen and (min-width:50.0625em){.reader-body[data-v-0f4986cb] .section-title,.reader-body[data-v-0f4986cb] .subsection-title{font-size:2.2rem}}.reader-body[data-v-0f4986cb] a{position:relative;color:#000}.reader-body[data-v-0f4986cb] a:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#000 0,#000 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.reader-body[data-v-0f4986cb] a:hover:after{display:none}.reader-body[data-v-0f4986cb] a:hover{color:#e10000}.reader-body[data-v-0f4986cb] .ads{text-align:center;margin-bottom:3rem;padding-bottom:3rem;border-bottom:gray 1px solid}.reader-body[data-v-0f4986cb] .ads a:after{content:none!important}.reader-body[data-v-0f4986cb] .ads a:hover{color:#4d4d4d}.reader-body[data-v-0f4986cb] .ads-link{display:block;font-size:1.2rem;letter-spacing:1px;text-decoration:none;text-align:center;color:#777;font-variant:small-caps;margin-bottom:.8rem}.reader-body[data-v-0f4986cb] .ads-link:hover{color:#777}.reader-body[data-v-0f4986cb] .ads-link:after{content:none!important}.reader-body[data-v-0f4986cb] p{margin-bottom:3rem}.reader-body[data-v-0f4986cb] .equ{position:relative;left:5em}.reader-body[data-v-0f4986cb] .unordered-list{margin-bottom:3rem}.reader-body[data-v-0f4986cb] .unordered-list li{position:relative;padding-left:1.5rem}.reader-body[data-v-0f4986cb] .unordered-list li:before{content:"";position:absolute;top:1.2rem;left:0;width:.75rem;height:.75rem;background:#000;border-radius:50%}.reader-body[data-v-0f4986cb] .unordered-list p{margin:0}.reader-body[data-v-0f4986cb] .table-wrap{margin-bottom:3rem}.reader-body[data-v-0f4986cb] .table-wrap .table-content{background:#fff;border:1px solid #ccc;padding:1rem;overflow-x:auto;margin-bottom:2rem}.reader-body[data-v-0f4986cb] .table-wrap .table-content table{width:100%;margin-bottom:4em;border:0;border-collapse:collapse;margin:0}.reader-body[data-v-0f4986cb] .table-wrap .table-content table th{font-size:1.2rem;vertical-align:middle;padding:1rem;border:1px solid rgba(51,51,51,.2)}.reader-body[data-v-0f4986cb] .table-wrap .table-content table td{font-size:1.2rem;vertical-align:middle;padding:.5rem;border:1px solid rgba(51,51,51,.2)}@media screen and (max-width:50em){.reader-body[data-v-0f4986cb] .table-wrap .table-content table th{font-size:1.2rem}}.reader-body[data-v-0f4986cb] .table-wrap .table-caption .heading{font-family:FSBrabo,serif;font-weight:700;font-style:normal;font-size:1.8rem;line-height:1.4;margin:0}.reader-body[data-v-0f4986cb] .table-wrap .table-caption .text{font-size:1.6rem;line-height:1.4;margin:0 0 1rem 0}.reader-body[data-v-0f4986cb] .table-wrap .table-caption .text p{margin:0}.reader-body[data-v-0f4986cb] .table-wrap .table-caption .note{font-size:1.4rem;line-height:1.4;margin:0 0 1rem 0}.reader-body[data-v-0f4986cb] .table-wrap .table-caption .note label,.reader-body[data-v-0f4986cb] .table-wrap .table-caption .note p{display:inline;margin:0}.reader-body[data-v-0f4986cb] .table-wrap .table-caption .note label{margin-right:.5rem}.reader-body[data-v-0f4986cb] .media-panel{margin:0 0 3rem}.reader-body[data-v-0f4986cb] .media-panel .media{display:block;background:#fff;border:1px solid #ccc}.reader-body[data-v-0f4986cb] .media-panel .media>img{display:block;margin:0 auto;max-width:100%}.reader-body[data-v-0f4986cb] .media-panel .caption>h4{font-family:FSBrabo,serif;font-weight:700;font-style:normal;font-size:1.8rem;line-height:1.4}.reader-body[data-v-0f4986cb] .media-panel .caption>p{font-size:1.6rem;line-height:1.4;margin:0 0 1rem 0}.reader-body[data-v-0f4986cb] .section{border-bottom:1px solid gray;margin-bottom:2.5rem;padding-bottom:0}@media screen and (max-width:34.375em){.reader-body[data-v-0f4986cb] .section{font-size:1.8rem;line-height:1.6}}@media screen and (min-width:34.4375em) and (max-width:50em){.reader-body[data-v-0f4986cb] .section{font-size:1.9rem;line-height:1.6}}@media screen and (min-width:50.0625em){.reader-body[data-v-0f4986cb] .section{font-size:2rem;line-height:1.7}}.reader-body[data-v-0f4986cb] .section:last-child{border-bottom:0;padding-bottom:0;margin-bottom:6rem}.reader-body[data-v-0f4986cb] .section .section{padding:0;margin:0;border:0}.reader-body[data-v-0f4986cb] .caption{margin-bottom:3rem}.reader-body[data-v-0f4986cb] .caption h3{font-family:FSBrabo,serif;font-weight:700;font-style:normal;font-size:1.8rem;line-height:1.5;display:inline;margin-right:1rem}.reader-body[data-v-0f4986cb] .caption p{font-size:1.8rem;line-height:1.5;display:inline}.reader-body[data-v-0f4986cb] .inline-formula .MathJax_Display{display:inline!important}@media screen and (max-width:34.375em){.reader-body[data-v-0f4986cb] .media-panel .media{padding:1rem;margin-bottom:1rem}.reader-body[data-v-0f4986cb] .formula{font-size:1.2rem;margin:4rem 0;text-align:center}.reader-body[data-v-0f4986cb] .formula>strong{font-size:.8rem;display:block;text-align:right;margin-top:1rem}}@media screen and (min-width:34.4375em){.reader-body[data-v-0f4986cb] .media-panel .media{padding:2rem;margin-bottom:2rem}.reader-body[data-v-0f4986cb] .formula{margin:5rem 0;text-align:center;position:relative}.reader-body[data-v-0f4986cb] .formula>strong{position:absolute;right:0;top:50%;margin-top:-.5rem;font-size:.6rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.reader-body[data-v-0f4986cb] .formula{font-size:1.4rem}}@media screen and (min-width:50.0625em){.reader-body[data-v-0f4986cb] .formula{font-size:1.6rem}}.share[data-v-1af021d0]{position:relative}.cta:nth-child(1)>.iconShare[data-v-1af021d0]{padding:0 3rem 0 0}.cta:nth-child(1)>.iconShare[data-v-1af021d0]:before{left:auto;right:0;font-size:2rem}.cta[data-v-1af021d0]:nth-child(2){float:right}.cta:nth-child(2)>.iconPdf[data-v-1af021d0]{padding:0 2.5rem 0 0}.cta:nth-child(2)>.iconPdf[data-v-1af021d0]:before{left:auto;right:0;font-size:2rem}@media screen and (max-width:34.375em){.share[data-v-1af021d0]{padding-top:3rem;clear:both}.share-module[data-v-1af021d0]{max-width:20rem;bottom:6.1rem!important}.share-module[data-v-1af021d0]:before{left:calc(50% - 25px)}}@media screen and (min-width:34.4375em) and (max-width:50em){.share-module[data-v-1af021d0]{max-width:20rem}}@media screen and (max-width:62.5em){.cta[data-v-1af021d0]{width:calc(50% - 1rem)}}@media screen and (min-width:34.4375em) and (max-width:62.5em){.share[data-v-1af021d0]{float:right;width:50%}.share-module[data-v-1af021d0]{bottom:6.1rem!important}.share-module[data-v-1af021d0]:before{left:calc(25% - 5px)}}@media screen and (min-width:62.5625em){.share[data-v-1af021d0]{margin-bottom:2rem}.share-module[data-v-1af021d0]{width:40rem;top:6.2rem;right:0;text-align:right}.share-module[data-v-1af021d0]:before{right:20rem!important;top:-10px;border-top:0!important;border-bottom:10px solid #000}.cta[data-v-1af021d0]{width:calc(50% - .5rem)}}.sections-toggle[data-v-515c83ac]{box-sizing:border-box;position:relative}.sections-toggle[data-v-515c83ac]:before{content:'';position:absolute;z-index:10;top:5.18em;left:0;right:2em;height:2em;background-image:linear-gradient(to top,rgba(255,255,255,0),#fffad2)}.sections-toggle[data-v-515c83ac]:after{content:'';position:absolute;z-index:10;top:100%;left:0;right:2em;margin-top:-2em;height:2em;background-image:linear-gradient(to bottom,rgba(255,255,255,0),#fffad2)}.title[data-v-515c83ac]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;line-height:1.4;font-size:2.2em;padding-top:2rem;border-top:1px solid #e10000;cursor:pointer}.clip[data-v-515c83ac]{transition:height .2s ease-in .3s;transform:translate3d(0,0,0);overflow:auto;height:calc(100vh - 85.5px - 70.8px);padding:2em 2em 0 0;-webkit-overflow-scrolling:touch}.shortcut[data-v-515c83ac]{color:#e10000;font-size:1.6em;line-height:1.5;display:block;padding-left:1.4rem}.shortcut[data-v-515c83ac]:hover{color:#870000}.list[data-v-515c83ac]{margin-bottom:3rem}.list[data-v-515c83ac] .item{font-size:1.6rem;line-height:1.4;margin-top:1rem}.list[data-v-515c83ac] .item .item-order{float:left;margin-right:.5rem}.list[data-v-515c83ac] .item .item-link{color:#e10000;overflow:hidden;display:block}.list[data-v-515c83ac] .item .item-link:hover{color:#870000}.ads-link[data-v-515c83ac]{display:block;font-size:1.2rem;letter-spacing:1px;text-decoration:none;text-align:center;text-transform:uppercase;color:#777}.ads-link[data-v-515c83ac]:hover{color:#777}.ads-link[data-v-515c83ac]:after{content:none!important}@media screen and (min-width:62.5625em){#app[data-scrolldir=up] .sections-toggle .clip{height:calc(100vh - 85.5px - 70.8px - 90px)}}.unnumbered-section[data-v-08125deb]{padding-left:1.7rem}.container[data-v-930ff012]{border-top:1px solid #e10000}.title[data-v-930ff012]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;margin-bottom:2rem;margin-bottom:3rem}@media screen and (max-width:50em){.title[data-v-930ff012]{font-size:2rem}}@media screen and (min-width:50.0625em){.title[data-v-930ff012]{font-size:2.2rem}}.text-1[data-v-930ff012]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6;margin:0 auto 4rem}.text-2[data-v-930ff012]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6}.link[data-v-930ff012]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;position:relative;color:#e10000;font-size:1.6em;line-height:2;margin-bottom:2rem;display:inline-block;padding-left:0}.link[data-v-930ff012]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#e10000 0,#e10000 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.link[data-v-930ff012]:before{content:"\E903";font-family:intech;font-size:.6em;position:absolute;right:-1.5em;top:50%;bottom:0;margin-top:-.8rem}.link[data-v-930ff012]:hover{color:#870000}.link[data-v-930ff012]:hover:after{background-image:linear-gradient(to right,#ae0000 0,#ae0000 100%)}.embedded-link[data-v-930ff012]{color:#e10000}.embedded-link[data-v-930ff012]:hover{color:#870000}.icr[data-v-930ff012]{color:#e10000;display:inline-block;font-size:2em;left:0}.icr[data-v-930ff012]:hover{color:#870000}.iconTwitter[data-v-930ff012]{margin-left:-.8rem}.cta>.iconLike[data-v-930ff012]{padding:0 3rem 0 0}.cta>.iconLike[data-v-930ff012]:before{left:auto;right:-1rem;top:.25em;font-size:2.5rem}.cta>.iconPrint[data-v-930ff012]{padding:0 3.5rem 0 0}.cta>.iconPrint[data-v-930ff012]:before{left:auto;right:-1rem;font-size:2.5rem}.last-box[data-v-930ff012]{margin-top:6rem}@media screen and (max-width:34.375em){.cta>.iconPrint[data-v-930ff012]{padding:0}.cta>.iconPrint[data-v-930ff012]:before{display:none}.icr[data-v-930ff012]{margin-right:20px}}@media screen and (max-width:50em){.container[data-v-930ff012]{padding:3rem 0 3rem}.title[data-v-930ff012]{margin-top:2rem}.cta[data-v-930ff012]{width:calc(50% - 10px);float:left}.cta[data-v-930ff012]:first-of-type{margin-right:10px}.cta[data-v-930ff012]:last-of-type{margin-left:10px}}@media screen and (min-width:50.0625em){.container[data-v-930ff012]{padding:5rem 0 5rem}.container .box[data-v-930ff012]{width:calc(100%/3);float:left}.cta[data-v-930ff012]{max-width:27rem;width:100%;margin-bottom:2rem}}.container[data-v-6b5f8e70]{border-top:1px solid #e10000}.title[data-v-6b5f8e70]{font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.title[data-v-6b5f8e70]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.title[data-v-6b5f8e70]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.title[data-v-6b5f8e70]{font-size:2.6rem;margin-bottom:4rem}}.info-box[data-v-6b5f8e70]{padding:5rem 4rem 6rem;margin-bottom:3rem;background-color:#e10000;text-align:center;color:#fffad2}.info-title[data-v-6b5f8e70]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.info-title[data-v-6b5f8e70]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.info-title[data-v-6b5f8e70]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.info-title[data-v-6b5f8e70]{font-size:2.6rem;margin-bottom:4rem}}.info-content[data-v-6b5f8e70]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6;color:#fff;margin-bottom:4rem}.cta[data-v-6b5f8e70]{width:100%}.cta[data-v-6b5f8e70]:first-of-type{margin-bottom:2rem}@media screen and (min-width:34.4375em) and (max-width:50em){.cta[data-v-6b5f8e70]{padding-right:3rem;padding-left:3rem;width:initial}}@media screen and (max-width:50em){.container[data-v-6b5f8e70]{padding:5rem 0}.info-box[data-v-6b5f8e70]{padding:5rem 3rem}}@media screen and (min-width:50.0625em){.container[data-v-6b5f8e70]{margin:0 auto;padding:5rem 0 3rem}}@media screen and (min-width:50.0625em) and (max-width:62.5em){.box-type-1[data-v-6b5f8e70],.info-box[data-v-6b5f8e70]{width:calc(50% - 10px);float:left;box-sizing:border-box}.info-box[data-v-6b5f8e70]{margin-right:10px;margin-bottom:0}}@media screen and (min-width:62.5625em){.content[data-v-6b5f8e70]{float:left;width:calc((100%/3)*2);box-sizing:border-box;padding-right:13rem}.sidebar[data-v-6b5f8e70]{float:left;width:calc(100%/3)}}.copy-item[data-v-eb50cbb4]{margin-bottom:4rem}.title[data-v-eb50cbb4]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;margin-bottom:2rem}@media screen and (max-width:50em){.title[data-v-eb50cbb4]{font-size:2rem}}@media screen and (min-width:50.0625em){.title[data-v-eb50cbb4]{font-size:2.2rem}}.title a[data-v-eb50cbb4],.title span[data-v-eb50cbb4]{color:#e10000;font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:.68182em;color:#e10000}.title a[data-v-eb50cbb4]:hover,.title span[data-v-eb50cbb4]:hover{color:#870000}.title a.copied[data-v-eb50cbb4],.title span.copied[data-v-eb50cbb4]{color:#666}.content[data-v-eb50cbb4]{font-size:1.5em;background-color:#fff;margin-bottom:1rem}.content.copied[data-v-eb50cbb4]{color:gray}.textarea[data-v-eb50cbb4]{position:absolute;left:-9999px;opacity:0}.note[data-v-eb50cbb4]{font-size:1.5em;font-style:italic}@media screen and (max-width:34.375em){.title a[data-v-eb50cbb4],.title span[data-v-eb50cbb4]{display:block}}@media screen and (min-width:34.4375em){.title a[data-v-eb50cbb4],.title span[data-v-eb50cbb4]{float:right;margin-top:4px}}@media screen and (max-width:50em){.content[data-v-eb50cbb4]{padding:1.5rem}}@media screen and (min-width:50.0625em){.content[data-v-eb50cbb4]{padding:2rem}}.book-statistics[data-v-b81d60e0]{max-width:117em;margin:0 auto;box-sizing:border-box;padding:0 2em;border-top:1px solid #e10000}@media screen and (max-width:34.375em){.book-statistics[data-v-b81d60e0]{padding:0 1.5em}.book-statistics .aside[data-v-b81d60e0]{margin-bottom:5rem}}@media screen and (min-width:34.4375em){.book-statistics[data-v-b81d60e0]{padding:0 2em}.book-statistics .aside[data-v-b81d60e0]{margin-bottom:5rem}.book-statistics .main .inner[data-v-b81d60e0]{max-width:60em;margin:0 auto}}@media screen and (min-width:62.5625em){.book-statistics .wrap[data-v-b81d60e0]{display:table;width:100%}.book-statistics .aside[data-v-b81d60e0]{display:table-cell;vertical-align:top;width:27em;padding-left:2em}.book-statistics .aside .track[data-v-b81d60e0]{transition:top .2s ease-in .3s;transform:translate3d(0,0,0);position:-webkit-sticky;position:sticky;top:2rem}.book-statistics .main[data-v-b81d60e0]{display:table-cell;vertical-align:top}.book-statistics .main .inner[data-v-b81d60e0]{max-width:68em;margin:0 auto}}.title[data-v-b81d60e0]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;text-align:center;display:block}@media screen and (max-width:34.375em){.title[data-v-b81d60e0]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.title[data-v-b81d60e0]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.title[data-v-b81d60e0]{font-size:2.6rem;margin-bottom:4rem}}.statistics[data-v-b81d60e0]{text-align:center}.stat-item[data-v-b81d60e0]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.8em;line-height:1;color:#e10000;display:inline-block;box-sizing:border-box;padding:0 2em;vertical-align:middle}.stat-item .text[data-v-b81d60e0]{line-height:1.3}.stat-item li[data-v-b81d60e0]{line-height:1.5}@media screen and (max-width:34.375em){.book-statistics[data-v-b81d60e0]{padding:5rem 1.5rem}}@media screen and (min-width:34.4375em){.book-statistics[data-v-b81d60e0]{padding:6rem 2rem}}@media screen and (max-width:43.75em){.statistics[data-v-b81d60e0]{margin:4rem 0 5rem}.stat-item[data-v-b81d60e0]{margin-bottom:4rem}.stat-item[data-v-b81d60e0]:last-child{margin-bottom:0}.data[data-v-b81d60e0]{font-size:2.22222em;margin-bottom:2rem;display:block}}@media screen and (min-width:43.8125em){.statistics[data-v-b81d60e0]{margin:5rem 0 8rem}.data[data-v-b81d60e0]{font-size:3.88889em;display:block}}@media screen and (min-width:43.8125em) and (max-width:62.5em){.statistics[data-v-b81d60e0]{margin:3rem 0 6rem}.data[data-v-b81d60e0]{font-size:2.77778em}}.box-type-1[data-v-c45c1492]{border:1px solid #000;text-align:center}.title[data-v-c45c1492]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-family:FSBrabo,serif;font-weight:400;font-style:normal;padding:0 1rem}@media screen and (max-width:34.375em){.title[data-v-c45c1492]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.title[data-v-c45c1492]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.title[data-v-c45c1492]{font-size:2.6rem;margin-bottom:4rem}}.description[data-v-c45c1492]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6;margin:0 auto 4rem}.cta[data-v-c45c1492]{padding-right:3rem;padding-left:3rem}@media screen and (max-width:34.375em){.box-type-1[data-v-c45c1492]{padding:4rem 2rem}.cta[data-v-c45c1492]{width:100%}}@media screen and (min-width:34.4375em){.box-type-1[data-v-c45c1492]{padding:5rem 3rem}.description[data-v-c45c1492]{max-width:60rem}}@media screen and (min-width:50.0625em){.box-type-1[data-v-c45c1492]{padding:5rem 4rem 6rem}.description[data-v-c45c1492]{margin-bottom:3rem}}@media screen and (min-width:50.0625em) and (max-width:62.5em){.cta[data-v-c45c1492]{width:100%;max-width:40rem}}@media screen and (min-width:62.5625em){.description[data-v-c45c1492]{max-width:77rem}}.container[data-v-6fbc1770]{background:rgba(0,0,0,.1)}.wrap[data-v-6fbc1770]{max-width:117em;margin:0 auto;box-sizing:border-box}.title[data-v-6fbc1770]{font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.title[data-v-6fbc1770]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.title[data-v-6fbc1770]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.title[data-v-6fbc1770]{font-size:2.6rem;margin-bottom:4rem}}.block-title[data-v-6fbc1770]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.6em;font-style:italic;padding-bottom:1rem;margin-bottom:4rem;border-bottom:1px solid #000}@media screen and (max-width:50em){.block.first[data-v-6fbc1770]{margin-bottom:4em}}@media screen and (max-width:62.5em){.wrap[data-v-6fbc1770]{padding:5em 2em}}@media screen and (min-width:50.0625em){.block[data-v-6fbc1770]{float:left;width:50%;box-sizing:border-box}.block.first[data-v-6fbc1770]{padding-right:1.5em}.block.second[data-v-6fbc1770]{padding-left:1.5em}}@media screen and (min-width:62.5625em){.wrap[data-v-6fbc1770]{padding:6em 2em}}.book-title[data-v-507a9a30]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6;margin-bottom:1rem}.book-text[data-v-507a9a30]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.6em;font-style:italic}.book-text>a[data-v-507a9a30]{position:relative;color:#000}.book-text>a[data-v-507a9a30]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#000 0,#000 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.book-text>a[data-v-507a9a30]:hover:after{display:none}.chapter-cta[data-v-507a9a30]{position:relative;color:#e10000;font-size:1.6em;display:inline-block;margin:2rem 0}.chapter-cta[data-v-507a9a30]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#e10000 0,#e10000 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.chapter-cta[data-v-507a9a30]:hover:after{display:none}.chapter-text[data-v-507a9a30]{font-size:1.7rem;line-height:1.6}@media screen and (max-width:62.5em){.column[data-v-507a9a30]{overflow:hidden}.column.first[data-v-507a9a30]{float:left;margin-right:2em}.cover[data-v-507a9a30]{max-width:10em}.book-info[data-v-507a9a30]{text-align:center;padding-top:2em;clear:both}.chapter-title[data-v-507a9a30]{display:none}}@media screen and (min-width:62.5625em){.column[data-v-507a9a30]{float:left;width:50%;box-sizing:border-box}.column.first[data-v-507a9a30]{text-align:center;padding:0 2em}.cover[data-v-507a9a30]{margin:0 auto 2em;max-width:20em}.chapter-title[data-v-507a9a30]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6;margin-bottom:1rem}}.about[data-v-66072837]{max-width:125em;margin:0 auto;text-align:center}.description[data-v-66072837]{font-size:1.7rem;line-height:1.6;max-width:57rem;margin:0 auto}.cta[data-v-66072837]{max-width:27rem;width:100%}@media screen and (max-width:34.375em){.about[data-v-66072837]{padding:5rem 1.5em}.description[data-v-66072837]{margin-bottom:3rem}}@media screen and (min-width:34.4375em){.about[data-v-66072837]{padding:8rem 0}.description[data-v-66072837]{margin-bottom:4rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.about[data-v-66072837]{padding:6rem 2em}}.stats-home[data-v-bfc5b0e2]{max-width:125em!important;text-align:center}.item[data-v-bfc5b0e2]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.8em;color:#e10000;float:left;box-sizing:border-box}.item>span[data-v-bfc5b0e2]{display:block;margin-bottom:2rem}@media screen and (max-width:34.375em){.stats-home[data-v-bfc5b0e2]{margin-top:5rem}.item[data-v-bfc5b0e2]{width:50%;margin-bottom:5rem}.item>span[data-v-bfc5b0e2]{font-size:1.66667em}}@media screen and (min-width:34.4375em){.stats-home[data-v-bfc5b0e2]{margin:6rem auto}.item[data-v-bfc5b0e2]{width:25%;padding:0 1em}.item>span[data-v-bfc5b0e2]{font-size:2.44444em}}@media screen and (min-width:34.4375em) and (max-width:50em){.item[data-v-bfc5b0e2]{padding:0}.item>span[data-v-bfc5b0e2]{font-size:1.77778em}}.ofs[data-v-1e9182ef]{background:rgba(0,0,0,.1);padding:4rem 0}.inner[data-v-1e9182ef]{max-width:117em;margin:0 auto;box-sizing:border-box;padding:0 2em}@media screen and (max-width:34.375em){.inner[data-v-1e9182ef]{padding:0 1.5em}}@media screen and (min-width:34.4375em){.inner[data-v-1e9182ef]{padding:0 2em}}.title[data-v-1e9182ef]{font-family:FSBrabo,serif;font-weight:400;font-style:normal}@media screen and (max-width:34.375em){.title[data-v-1e9182ef]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.title[data-v-1e9182ef]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.title[data-v-1e9182ef]{font-size:2.6rem;margin-bottom:4rem}}.calling .sub-title[data-v-1e9182ef]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;margin-bottom:2rem}@media screen and (max-width:50em){.calling .sub-title[data-v-1e9182ef]{font-size:2rem}}@media screen and (min-width:50.0625em){.calling .sub-title[data-v-1e9182ef]{font-size:2.2rem}}.calling .description[data-v-1e9182ef]{font-size:1.7rem;line-height:1.6;margin-bottom:3rem}.calling .link[data-v-1e9182ef]{position:relative;color:#e10000;font-size:1.6em;line-height:2;display:inline-block;margin-bottom:4rem}.calling .link[data-v-1e9182ef]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#e10000 0,#e10000 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.calling .link[data-v-1e9182ef]:before{content:"\E903";font-family:intech;font-size:.6em;position:absolute;right:-1.5em;top:50%;bottom:0;margin-top:-.8rem}.calling .link[data-v-1e9182ef]:hover{color:#870000}.calling .link[data-v-1e9182ef]:hover:after{background-image:linear-gradient(to right,#ae0000 0,#ae0000 100%)}.calling .cta[data-v-1e9182ef]{width:100%;max-width:37rem}.books-list[data-v-1e9182ef] .inner{padding:0}.books-list[data-v-1e9182ef] .prev{left:-1.5em}.books-list[data-v-1e9182ef] .next{right:-2em}@media screen and (max-width:34.375em){.ofs[data-v-1e9182ef]{padding:6rem 0 3rem}}@media screen and (min-width:34.4375em) and (max-width:62.5em){.ofs[data-v-1e9182ef]{padding:6rem 0 3rem}}@media screen and (max-width:62.5em){.calling[data-v-1e9182ef]{text-align:center}.books[data-v-1e9182ef]{text-align:center;margin-top:4rem}.title[data-v-1e9182ef]{margin-bottom:3rem}}@media screen and (min-width:62.5625em){.inner[data-v-1e9182ef]{position:relative}.inner[data-v-1e9182ef]:before{content:"";position:absolute;top:0;left:49rem;bottom:0;width:1px;background:#000}.calling[data-v-1e9182ef]{width:47rem;box-sizing:border-box;float:left;padding:3rem 10rem 0 0}.books[data-v-1e9182ef]{width:calc(100% - 470px);box-sizing:border-box;float:left;padding:3rem 0 0 3rem}.books .books-list[data-v-1e9182ef]{margin:0 5rem 0 -2.9rem}.books[data-v-1e9182ef] .VueCarousel-navigation-prev{left:2rem!important}.books[data-v-1e9182ef] .VueCarousel-navigation-next{right:-3rem!important}}.footer[data-v-75b1e4b2]{background:#000;color:#fffad2}.inner[data-v-75b1e4b2]{max-width:117em;margin:0 auto;box-sizing:border-box;padding:0 2em}@media screen and (max-width:34.375em){.inner[data-v-75b1e4b2]{padding:0 1.5em}.inner .aside[data-v-75b1e4b2]{margin-bottom:5rem}}@media screen and (min-width:34.4375em){.inner[data-v-75b1e4b2]{padding:0 2em}.inner .aside[data-v-75b1e4b2]{margin-bottom:5rem}.inner .main .inner[data-v-75b1e4b2]{max-width:60em;margin:0 auto}}@media screen and (min-width:62.5625em){.inner .wrap[data-v-75b1e4b2]{display:table;width:100%}.inner .aside[data-v-75b1e4b2]{display:table-cell;vertical-align:top;width:27em;padding-left:2em}.inner .aside .track[data-v-75b1e4b2]{transition:top .2s ease-in .3s;transform:translate3d(0,0,0);position:-webkit-sticky;position:sticky;top:2rem}.inner .main[data-v-75b1e4b2]{display:table-cell;vertical-align:top}.inner .main .inner[data-v-75b1e4b2]{max-width:68em;margin:0 auto}}.title[data-v-75b1e4b2]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;color:#fffad2;font-size:1.6em;line-height:1.3;display:block;margin-bottom:1.5rem}.title[data-v-75b1e4b2]:hover{text-decoration:underline}.link[data-v-75b1e4b2]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;color:#fffad2;font-size:1.4em;line-height:1.6;display:block;margin-bottom:1.5rem}.link[data-v-75b1e4b2]:hover{text-decoration:underline}.icr[data-v-75b1e4b2]{display:inline-block;font-size:2em;left:0;margin-right:.5rem;text-indent:initial}.icr[data-v-75b1e4b2]:last-child{margin-right:0}.icr img[data-v-75b1e4b2]{width:60%}.address[data-v-75b1e4b2],.meta[data-v-75b1e4b2]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.4em;line-height:1.7;color:#fff}.address[data-v-75b1e4b2]{margin:3rem 0 2rem}.meta[data-v-75b1e4b2]{margin-bottom:2rem}.search-wrap[data-v-75b1e4b2]{margin:4rem 0}.search-term[data-v-75b1e4b2] input{padding:.8rem 4rem .8rem 1.5rem}.legal-wrap[data-v-75b1e4b2]{font-family:'Relative Faux',sans-serif;font-weight:400;font-style:normal;font-size:1.3rem;line-height:1.85;padding:2rem 0;border-top:1px solid #666}.legal-nav li[data-v-75b1e4b2]{display:inline-block}.legal-nav li a[data-v-75b1e4b2]{color:#fffad2;padding:0 1rem;border-right:1px solid #666}.legal-nav li a[data-v-75b1e4b2]:hover{text-decoration:underline}.legal-nav li:last-child a[data-v-75b1e4b2]{border:none;padding-right:0}.copyright[data-v-75b1e4b2]{color:#fff}@media screen and (max-width:34.375em){.inner[data-v-75b1e4b2]{padding-top:5rem}.link[data-v-75b1e4b2]:not(.mail){display:none}.title[data-v-75b1e4b2]{font-size:1.5em}.nav-box[data-v-75b1e4b2]{width:50%;float:left;box-sizing:border-box}.nav-box[data-v-75b1e4b2]:last-child{clear:both;width:100%}.social-wrap[data-v-75b1e4b2]{margin:2rem 0 4rem;text-align:center}.icr[data-v-75b1e4b2]{margin-right:2rem}.address[data-v-75b1e4b2]{width:50%;float:left;margin:0}.meta-wrap[data-v-75b1e4b2]{width:50%;float:right;box-sizing:border-box;padding-left:2rem}.meta[data-v-75b1e4b2]{margin-bottom:1rem}.search-term[data-v-75b1e4b2]{width:100%}.search-term[data-v-75b1e4b2] input{font-size:2em;width:100%}.cta[data-v-75b1e4b2]{display:block;margin-top:3rem}.legal-wrap[data-v-75b1e4b2]{text-align:center}.legal-nav[data-v-75b1e4b2]{max-width:30rem;margin:0 auto}.legal-nav li[data-v-75b1e4b2]{margin-bottom:2rem}}@media screen and (min-width:34.4375em){.legal-nav[data-v-75b1e4b2]{float:right}.cta[data-v-75b1e4b2]{float:right;width:25%}}@media screen and (min-width:34.4375em) and (max-width:50em){.inner[data-v-75b1e4b2]{padding-top:6rem}.nav-box[data-v-75b1e4b2]{width:calc(100% / 3);float:left;box-sizing:border-box}.nav-box[data-v-75b1e4b2]:last-child{clear:both;width:100%;margin-top:5rem}.icr[data-v-75b1e4b2]{margin-right:.3rem}.social-wrap[data-v-75b1e4b2]{width:calc(100% / 3);float:right}.company-info-wrap[data-v-75b1e4b2]{width:calc((100% / 3)*2);float:left}.address[data-v-75b1e4b2]{width:50%;float:left;margin:0}.meta-wrap[data-v-75b1e4b2]{width:50%;float:right}.search-wrap[data-v-75b1e4b2]{margin:5rem 0}.cta[data-v-75b1e4b2]{width:calc(100% /3)}}@media screen and (min-width:50.0625em){.inner[data-v-75b1e4b2]{padding-top:8rem}.nav-box[data-v-75b1e4b2]{width:25%;float:left;box-sizing:border-box}.nav-box[data-v-75b1e4b2]:first-of-type{padding-left:0}.nav-box[data-v-75b1e4b2]:last-of-type{padding-right:0}}@media screen and (min-width:62.5625em){.icr[data-v-75b1e4b2]{margin-right:2rem}}.book-subject-area[data-v-687e2a4b]{background-color:#e10000;color:#fffad2}.book-subject-area .inner[data-v-687e2a4b]{max-width:117em;margin:0 auto;box-sizing:border-box;padding:0 2em}@media screen and (max-width:34.375em){.book-subject-area .inner[data-v-687e2a4b]{padding:0 1.5em}.book-subject-area .inner .aside[data-v-687e2a4b]{margin-bottom:5rem}}@media screen and (min-width:34.4375em){.book-subject-area .inner[data-v-687e2a4b]{padding:0 2em}.book-subject-area .inner .aside[data-v-687e2a4b]{margin-bottom:5rem}.book-subject-area .inner .main .inner[data-v-687e2a4b]{max-width:60em;margin:0 auto}}@media screen and (min-width:62.5625em){.book-subject-area .inner .wrap[data-v-687e2a4b]{display:table;width:100%}.book-subject-area .inner .aside[data-v-687e2a4b]{display:table-cell;vertical-align:top;width:27em;padding-left:2em}.book-subject-area .inner .aside .track[data-v-687e2a4b]{transition:top .2s ease-in .3s;transform:translate3d(0,0,0);position:-webkit-sticky;position:sticky;top:2rem}.book-subject-area .inner .main[data-v-687e2a4b]{display:table-cell;vertical-align:top}.book-subject-area .inner .main .inner[data-v-687e2a4b]{max-width:68em;margin:0 auto}}.book-subject-area .title[data-v-687e2a4b]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-family:FSBrabo,serif;font-weight:400;font-style:normal;text-align:center;margin-bottom:5rem}@media screen and (max-width:34.375em){.book-subject-area .title[data-v-687e2a4b]{font-size:2.2rem;margin-bottom:2rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.book-subject-area .title[data-v-687e2a4b]{font-size:2.4rem;margin-bottom:3rem}}@media screen and (min-width:50.0625em){.book-subject-area .title[data-v-687e2a4b]{font-size:2.6rem;margin-bottom:4rem}}.book-subject-area .sub-title[data-v-687e2a4b]{color:#fffad2;font-family:FSBrabo,serif;font-weight:700;font-style:normal;font-size:1.7rem;line-height:1.6;display:block;margin-bottom:2rem}.book-subject-area .sub-title[data-v-687e2a4b]:hover{text-decoration:underline}.book-subject-area .link[data-v-687e2a4b]{color:#fffad2;font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.7rem;line-height:1.6;display:block;margin-bottom:1.5rem}.book-subject-area .link[data-v-687e2a4b]:hover{text-decoration:underline}.book-subject-area .link-more[data-v-687e2a4b]{color:#fffad2;font-family:FSBrabo,serif;font-weight:400;font-style:normal;font-size:1.6em;line-height:1.5;padding-left:0}.book-subject-area .link-more[data-v-687e2a4b]:hover{text-decoration:underline}.book-subject-area .link-more[data-v-687e2a4b]:before{font-size:.6em;right:-3em;left:inherit}.book-subject-area .view-all[data-v-687e2a4b]{font-family:FSBrabo,serif;font-weight:400;font-style:normal;position:relative;color:#fffad2;font-size:1.6em;line-height:1.5;padding-left:0}.book-subject-area .view-all[data-v-687e2a4b]:after{content:"";position:absolute;left:0;right:0;bottom:0;top:0;background-image:linear-gradient(to right,#fffad2 0,#fffad2 100%);background-repeat:repeat-x;background-position:0 90%;background-size:100% 1px}.book-subject-area .view-all[data-v-687e2a4b]:hover:after{display:none}.book-subject-area .view-all[data-v-687e2a4b]:before{font-size:.6em;right:-3em;left:inherit}@media screen and (max-width:34.375em){.book-subject-area[data-v-687e2a4b]{padding-top:5rem;padding-bottom:5rem}.book-subject-area .title[data-v-687e2a4b]{margin-bottom:5rem}}@media screen and (min-width:34.4375em) and (max-width:50em){.book-subject-area[data-v-687e2a4b]{padding-top:6rem;padding-bottom:6rem}.book-subject-area .title[data-v-687e2a4b]{margin-bottom:5rem}}@media screen and (max-width:50em){.book-subject-area .sub-title[data-v-687e2a4b]{margin-bottom:3rem}.book-subject-area .link-more[data-v-687e2a4b],.book-subject-area .link[data-v-687e2a4b]{display:none}.book-subject-area .view-all[data-v-687e2a4b]{display:table;margin:0 auto}}@media screen and (min-width:50.0625em){.book-subject-area[data-v-687e2a4b]{padding-top:7rem;padding-bottom:8rem}.book-subject-area .inner[data-v-687e2a4b]{position:relative}.book-subject-area .title[data-v-687e2a4b]{margin-bottom:5rem}.book-subject-area .sub-title[data-v-687e2a4b]{min-height:5rem}.book-subject-area .box[data-v-687e2a4b]{width:25%;float:left;box-sizing:border-box;padding:0 1.5rem}.book-subject-area .box[data-v-687e2a4b]:first-of-type{padding-left:0}.book-subject-area .box[data-v-687e2a4b]:last-of-type{padding-right:0}.book-subject-area .box .link[data-v-687e2a4b]{display:none}.book-subject-area .box .link[data-v-687e2a4b]:nth-child(2),.book-subject-area .box .link[data-v-687e2a4b]:nth-child(3),.book-subject-area .box .link[data-v-687e2a4b]:nth-child(4){display:block}.book-subject-area .box.show-all .link[data-v-687e2a4b]{display:block}.book-subject-area .view-all[data-v-687e2a4b]{position:absolute;right:3rem;top:5px}}</style></head><body><div id="app"><div id="app" data-server-rendered="true"><div data-v-87be0136><header id="page-header" class="page-header" data-v-a6e59acc data-v-87be0136><!----><!----><div class="wrap" data-v-a6e59acc><a href="/" class="router-link-active" data-v-a6e59acc><img src="//cdnintech.com/web/frontend/www/assets/svg/logo.svg" alt="IntechOpen" class="branding" data-v-a6e59acc></a><nav class="site-nav" data-v-a6e59acc><ul data-v-a6e59acc><li data-v-a6e59acc><a href="/books" class="nav-item" data-v-a6e59acc>Books</a></li><li data-v-a6e59acc><a href="/publish" class="nav-item" data-v-a6e59acc>Publish</a><!----></li><li data-v-a6e59acc><a href="/about-intechopen" class="nav-item" data-v-a6e59acc>About</a><!----></li><li data-v-a6e59acc><a href="/news" class="nav-item" data-v-a6e59acc>News</a><!----></li><li data-v-a6e59acc><a href="/page/contact-us" class="nav-item" data-v-a6e59acc>Contact</a></li></ul></nav><aside class="aside" data-v-a6e59acc><ul data-v-a6e59acc><li data-v-a6e59acc><a href="//mts.intechopen.com/account/login" target="_blank" class="nav-item" data-v-a6e59acc>Author Panel Sign in</a></li></ul><form class="search-term" data-v-36b4823c data-v-a6e59acc><input placeholder="Search" required="required" value="" data-v-36b4823c><button type="submit" class="icr iconSearch" data-v-36b4823c>Submit</button></form></aside><div class="nav-dropdown collapsed" data-v-a6e59acc><div class="inner" data-v-a6e59acc><div class="drop-box" data-v-a6e59acc><a href="/how-open-access-publishing-with-intechopen-works" class="drop-item" data-v-a6e59acc>What is Open Access?</a><p data-v-a6e59acc>Open Access is an initiative that aims to make scientific research freely available to all. To date our community has made over 100 million downloads. It’s based on principles of collaboration, unobstructed discovery, and, most importantly, scientific progression. As PhD students, we found it difficult to access the research we needed, so we decided to create a new Open Access publisher that levels the playing field for scientists across the world. How? By making research easy to access, and puts the academic needs of the researchers before the business interests of publishers.</p></div><div class="drop-box" data-v-a6e59acc><a href="/authors-and-editors" class="drop-item" data-v-a6e59acc>Our authors and editors</a><p data-v-a6e59acc>We are a community of more than 103,000 authors and editors from 3,291 institutions spanning 160 countries, including Nobel Prize winners and some of the world’s most-cited researchers. Publishing on IntechOpen allows authors to earn citations and find new collaborators, meaning more people see your work not only from your own field of study, but from other related fields too.</p></div><div class="drop-box" data-v-a6e59acc><a href="/page/content-alerts" class="drop-item" data-v-a6e59acc>Content Alerts</a><p data-v-a6e59acc>Brief introduction to this section that descibes Open Access especially from an IntechOpen perspective</p><a href="/how-open-access-publishing-with-intechopen-works" class="nav-item" data-v-a6e59acc>How it works</a><a href="#" class="nav-item" data-v-a6e59acc>Manage preferences</a></div><div class="drop-box" data-v-a6e59acc><a href="/page/contact-us" class="drop-item" data-v-a6e59acc>Contact</a><p data-v-a6e59acc>Want to get in touch? Contact our London head office or <a href="#" data-v-a6e59acc>media team here</a></p><a href="/page/careers-at-intechopen" class="drop-item" data-v-a6e59acc>Careers</a><p data-v-a6e59acc>Our team is growing all the time, so we’re always on the lookout for smart people who want to help us reshape the world of scientific publishing.</p></div></div></div></div></header><section data-v-89ab6a34 data-v-87be0136><div class="intro" data-v-8cec8ff0 data-v-89ab6a34><div class="wrap" data-v-8cec8ff0><p class="subtitle" data-v-8cec8ff0>Open access peer-reviewed chapter</p><h1 class="title" data-v-8cec8ff0>Automatic Speech Emotion Recognition Using Machine Learning</h1><p class="text" data-v-8cec8ff0>By Leila Kerkeni, Youssef Serrestou, Mohamed Mbarki, Kosai Raoof, Mohamed Ali Mahjoub and Catherine Cleder</p><p class="subtext" data-v-8cec8ff0><span data-v-8cec8ff0>Submitted: February 21st 2018</span><span data-v-8cec8ff0>Reviewed: January 31st 2019</span><span data-v-8cec8ff0>Published: March 25th 2019</span></p><p class="subtext" data-v-8cec8ff0>DOI: 10.5772/intechopen.84856</p><!----></div></div><div class="breadcrumbs" data-v-80d35b96 data-v-89ab6a34><div class="wrap" data-v-80d35b96><p data-v-80d35b96><a href="/" class="router-link-active" data-v-89ab6a34>Home</a> &gt; <a href="/books" data-v-89ab6a34>Books</a> &gt; <a href="/books/8141" class="capitalize" data-v-89ab6a34>Social Media and Machine Learning</a></p></div></div><div class="chapter" data-v-89ab6a34><div class="ad-wraper" data-v-89ab6a34><a href="https://ehealthcaresolutions.com/contact-us/" target="_blank" class="ads-link" data-v-89ab6a34>Advertisement</a><div id="intechopen-intechopen-0" data-v-89ab6a34></div><!----><!----></div><div class="info cf" data-v-b8b16c92 data-v-89ab6a34><div class="block" data-v-b8b16c92><p data-v-b8b16c92>Downloaded: 3123</p></div><div class="block" data-v-b8b16c92><p data-v-b8b16c92><span data-doi="10.5772/intechopen.84856" data-hide-zero-citations="true" data-legend="hover-right" data-style="large_rectangle" class="__dimensions_badge_embed__" data-v-b8b16c92></span></p></div></div><!----><!----><div class="wrap" data-v-89ab6a34><aside class="aside cf left-aside" data-v-89ab6a34><div style="height:100%" data-v-89ab6a34><div class="track" data-v-89ab6a34><a href="https://ehealthcaresolutions.com/contact-us/" target="_blank" class="ads-link" style="margin-top:3px" data-v-89ab6a34>Advertisement</a><div id="intechopen-intechopen-5" style="padding-bottom:4.5rem" data-v-89ab6a34></div><!----><!----></div></div></aside><div class="main" data-v-89ab6a34><div class="inner" data-v-89ab6a34><div class="intro" data-v-1e8b6f8e data-v-89ab6a34><h2 class="title" data-v-1e8b6f8e>Abstract</h2><div class="body" data-v-1e8b6f8e><p data-v-1e8b6f8e>This chapter presents a comparative study of speech emotion recognition (SER) systems. Theoretical definition, categorization of affective state and the modalities of emotion expression are presented. To achieve this study, an SER system, based on different classifiers and different methods for features extraction, is developed. Mel-frequency cepstrum coefficients (MFCC) and modulation spectral (MS) features are extracted from the speech signals and used to train different classifiers. Feature selection (FS) was applied in order to seek for the most relevant feature subset. Several machine learning paradigms were used for the emotion classification task. A recurrent neural network (RNN) classifier is used first to classify seven emotions. Their performances are compared later to multivariate linear regression (MLR) and support vector machines (SVM) techniques, which are widely used in the field of emotion recognition for spoken audio signals. Berlin and Spanish databases are used as the experimental data set. This study shows that for Berlin database all classifiers achieve an accuracy of 83% when a speaker normalization (SN) and a feature selection are applied to the features. For Spanish database, the best accuracy (94 %) is achieved by RNN classifier without SN and with FS.</p></div></div><div class="keywords" data-v-64821705 data-v-89ab6a34><h3 class="subTitle" data-v-64821705>Keywords</h3><ul data-v-64821705><li class="item" data-v-64821705>speech emotion recognition</li><li class="item" data-v-64821705>feature extraction recurrent neural</li><li class="item" data-v-64821705>network SVM</li><li class="item" data-v-64821705>multivariate linear regression</li><li class="item" data-v-64821705>MFCC</li><li class="item" data-v-64821705>modulation spectral features</li><li class="item" data-v-64821705>machine learning</li></ul></div><div id="section-chapter-and-author" class="info collapsed" data-v-076a6caa data-v-89ab6a34><h2 class="title capitalize" data-v-076a6caa>chapter and author info</h2><div class="wrap" data-v-076a6caa><h3 class="subTitle" data-v-076a6caa>Authors</h3><ul data-v-076a6caa><li class="authorsItem" data-v-076a6caa><h4 class="author" data-v-076a6caa>Leila Kerkeni<span data-v-076a6caa>*</span></h4><span class="position" data-v-076a6caa><ul class="list"><li>LAUM UMR CNRS 6613, Le Mans Université, France</li><li>LATIS Lab, ENISo Université de Sousse, Tunisia</li></ul></span></li><li class="authorsItem" data-v-076a6caa><h4 class="author" data-v-076a6caa>Youssef Serrestou<!----></h4><span class="position" data-v-076a6caa><ul class="list"><li>LAUM UMR CNRS 6613, Le Mans Université, France</li></ul></span></li><li class="authorsItem" data-v-076a6caa><h4 class="author" data-v-076a6caa>Mohamed Mbarki<!----></h4><span class="position" data-v-076a6caa><ul class="list"><li>ISSAT, Université de Sousse, Tunisia</li></ul></span></li><li class="authorsItem" data-v-076a6caa><h4 class="author" data-v-076a6caa>Kosai Raoof<!----></h4><span class="position" data-v-076a6caa><ul class="list"><li>LAUM UMR CNRS 6613, Le Mans Université, France</li></ul></span></li><li class="authorsItem" data-v-076a6caa><h4 class="author" data-v-076a6caa>Mohamed Ali Mahjoub<!----></h4><span class="position" data-v-076a6caa><ul class="list"><li>LATIS Lab, ENISo Université de Sousse, Tunisia</li></ul></span></li><li class="authorsItem" data-v-076a6caa><h4 class="author" data-v-076a6caa>Catherine Cleder<!----></h4><span class="position" data-v-076a6caa><ul class="list"><li>CREN Lab, Université de Nantes, France</li></ul></span></li></ul><p class="title" data-v-076a6caa>*Address all correspondence to: kerkeni.leila@gmail.com</p><br data-v-076a6caa><br data-v-076a6caa><p class="doi" data-v-076a6caa>DOI: 10.5772/intechopen.84856</p><h3 class="subTitle" data-v-076a6caa>From the Edited Volume</h3><section class="book cf" data-v-076a6caa><div class="cover" data-v-076a6caa><figure class="cover-wrap middle" data-v-82939336 data-v-076a6caa><a href="/books/8141" data-v-82939336><span class="lazy-image ar1" data-v-d261b71c data-v-82939336><!----></span><svg viewBox="0 0 300 270" preserveAspectRatio="xMidYMid meet" class="svg" data-v-82939336><rect width="300" height="270" style="fill:#e10000" data-v-82939336></rect><text x="150" y="35" font-family="Arial" text-anchor="middle" fill="#fffad2" font-size="12" data-v-82939336>IntechOpen</text><g transform="translate(140, 220)" fill="#FFFAD2" data-v-82939336><g transform="scale(0.7)" data-v-82939336><path d="M18.4091275,7.09361268 L3.66754648,15.3478697 C2.61853239,15.939493 1.9668669,17.0549331 1.9668669,18.2588838 L1.9668669,33.0542958 L0.869542958,32.6455599 C0.346761268,32.4507676 -3.45070423e-05,31.9516232 -3.45070423e-05,31.3936444 L-3.45070423e-05,1.37079225 C-3.45070423e-05,0.417880282 0.94908169,-0.243792254 1.84298662,0.08575 L18.3356275,6.16347535 C18.7472965,6.3151338 18.791638,6.87932394 18.4091275,7.09361268 M38.2955359,22.6833768 C38.178212,23.1238592 37.8226169,23.4794542 37.382307,23.5967782 C36.3688352,23.8671408 35.4695817,22.9675423 35.7401169,21.9540704 C35.8576134,21.5139331 36.2132085,21.158338 36.6536908,21.0411866 C37.6666451,20.7715141 38.565381,21.6704225 38.2955359,22.6833768 M48.0927754,30.247493 C47.5629197,30.0078415 46.9350641,30.1798592 46.5494479,30.614993 L46.5221873,30.6455317 C45.2633704,32.0789542 43.7110711,33.1881831 41.9971063,33.9233556 C41.9917577,33.9255986 41.9971063,22.341757 41.9971063,22.341757 C41.9971063,13.8637218 35.1127789,6.99078169 26.6345711,6.99078169 C24.2718739,6.99078169 21.8610394,7.48388732 19.7830254,8.63297183 C17.9817577,9.62901761 7.46211338,15.5312746 4.66255704,17.1022077 C4.23846549,17.3401338 3.97845493,17.7871725 3.97845493,18.2733768 L3.97845493,47.5848662 C3.97845493,48.5941972 5.06456408,49.230507 5.9451838,48.7372289 L19.0174866,41.4119014 C19.4345042,41.1781162 19.6927894,40.7374613 19.6927894,40.2593662 L19.6927894,17.7378275 C19.6927894,17.2512782 20.0211239,16.8006162 20.5000817,16.7141761 C21.1293176,16.6008204 21.6765993,17.0811585 21.6765993,17.6893451 L21.6765993,22.2984507 L21.6821204,22.287581 C21.6821204,22.2912042 21.6817754,22.2948275 21.6817754,22.2984507 C21.6817754,30.752331 28.5590289,37.6295845 37.0127366,37.6295845 C37.7863845,37.6295845 38.5527859,37.5676444 39.3076275,37.4532535 L39.3076275,47.5686479 C39.3076275,48.3079613 39.9071873,48.9076937 40.6466732,48.9076937 C41.3859866,48.9076937 41.9853739,48.3079613 41.9853739,47.5686479 L41.9853739,36.796757 C44.484719,35.9396021 46.7488986,34.4454472 48.5267014,32.4212641 L48.5669021,32.3755423 C49.1533493,31.7199085 48.9746028,30.6460493 48.0927754,30.247493" data-v-82939336></path></g></g></svg><div class="text" style="font-size:150em" data-v-82939336><span class="title" data-v-82939336>Social Media and Machine Learning</span><!----><span class="editors" data-v-82939336>Edited by Alberto Cano</span></div></a></figure></div><p class="title" data-v-076a6caa><a href="/books/8141" data-v-076a6caa>Social Media and Machine Learning</a></p><p class="bookInfo" data-v-076a6caa>Edited by Alberto Cano</p></section></div><a class="toggle" data-v-076a6caa>Show +</a></div><div class="reader-body" data-v-0f4986cb data-v-89ab6a34><div class="section" id="sec_1" data-lvl="1"><h2 class="heading main-title">1. Introduction</h2><p id="p2">Emotion plays a significant role in daily interpersonal human interactions. This is essential to our rational as well as intelligent decisions. It helps us to match and understand the feelings of others by conveying our feelings and giving feedback to others. Research has revealed the powerful role that emotion play in shaping human social interaction. Emotional displays convey considerable information about the mental state of an individual. This has opened up a new research field called automatic emotion recognition, having basic goals to understand and retrieve desired emotions. In prior studies, several modalities have been explored to recognize the emotional states such as facial expressions [<a href="#B1" class="ref-link" data-ref-style="bibr">1</a>], speech [<a href="#B2" class="ref-link" data-ref-style="bibr">2</a>], physiological signals [<a href="#B3" class="ref-link" data-ref-style="bibr">3</a>], etc. Several inherent advantages make speech signals a good source for affective computing. For example, compared to many other biological signals (e.g., electrocardiogram), speech signals usually can be acquired more readily and economically. This is why the majority of researchers are interested in speech emotion recognition (SER). SER aims to recognize the underlying emotional state of a speaker from her voice. The area has received increasing research interest all through current years. There are many applications of detecting the emotion of the persons like in the interface with robots, audio surveillance, web-based E-learning, commercial applications, clinical studies, entertainment, banking, call centers, cardboard systems, computer games, etc. For classroom orchestration or E-learning, information about the emotional state of students can provide focus on the enhancement of teaching quality. For example, a teacher can use SER to decide what subjects can be taught and must be able to develop strategies for managing emotions within the learning environment. That is why learner&rsquo;s emotional state should be considered in the classroom.</p><p id="p3">Three key issues need to be addressed for successful SER system, namely, (1) choice of a good emotional speech database, (2) extracting effective features, and (3) designing reliable classifiers using machine learning algorithms. In fact, the emotional feature extraction is a main issue in the SER system. Many researchers [<a href="#B4" class="ref-link" data-ref-style="bibr">4</a>] have proposed important speech features which contain emotion information, such as energy, pitch, formant frequency, Linear Prediction Cepstrum Coefficients (LPCC), Mel-frequency cepstrum coefficients (MFCC), and modulation spectral features (MSFs) [<a href="#B5" class="ref-link" data-ref-style="bibr">5</a>]. Thus, most researchers prefer to use combining feature set that is composed of many kinds of features containing more emotional information [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>]. However, using a combining feature set may give rise to high dimension and redundancy of speech features; thereby, it makes the learning process complicated for most machine learning algorithms and increases the likelihood of overfitting. Therefore, feature selection is indispensable to reduce the dimensions redundancy of features. A review for feature selection models and techniques is presented in [<a href="#B7" class="ref-link" data-ref-style="bibr">7</a>]. Both feature extraction and feature selection are capable of improving learning performance, lowering computational complexity, building better generalizable models, and decreasing required storage. The last step of speech emotion recognition is classification. It involves classifying the raw data in the form of utterance or frame of the utterance into a particular class of emotion on the basis of features extracted from the data. In recent years in speech emotion recognition, researchers proposed many classification algorithms, such as Gaussian mixture model (GMM) [<a href="#B8" class="ref-link" data-ref-style="bibr">8</a>], hidden Markov model (HMM) [<a href="#B9" class="ref-link" data-ref-style="bibr">9</a>], support vector machine (SVM) [<a href="#B10" class="ref-link" data-ref-style="bibr">10</a>, <a href="#B11" class="ref-link" data-ref-style="bibr">11</a>, <a href="#B12" class="ref-link" data-ref-style="bibr">12</a>, <a href="#B13" class="ref-link" data-ref-style="bibr">13</a>, <a href="#B14" class="ref-link" data-ref-style="bibr">14</a>], neural networks (NN) [<a href="#B15" class="ref-link" data-ref-style="bibr">15</a>], and recurrent neural networks (RNN) [<a href="#B16" class="ref-link" data-ref-style="bibr">16</a>, <a href="#B17" class="ref-link" data-ref-style="bibr">17</a>, <a href="#B18" class="ref-link" data-ref-style="bibr">18</a>]. Some other types of classifiers are also proposed by some researchers such as a modified brain emotional learning model (BEL) [<a href="#B19" class="ref-link" data-ref-style="bibr">19</a>] in which the adaptive neuro-fuzzy inference system (ANFIS) and multilayer perceptron (MLP) are merged for speech emotion recognition. Another proposed strategy is a multiple kernel Gaussian process (GP) classification [<a href="#B17" class="ref-link" data-ref-style="bibr">17</a>], in which two similar notions in the learning algorithm are presented by combining the linear kernel and radial basis function (RBF) kernel. The Voiced Segment Selection (VSS) algorithm also proposed in [<a href="#B20" class="ref-link" data-ref-style="bibr">20</a>] deals with the voiced signal segment as the texture image processing feature which is different from the traditional method. It uses the Log-Gabor filters to extract the voiced and unvoiced features from spectrogram to make the classification.</p><p id="p4">In previous work [<a href="#B21" class="ref-link" data-ref-style="bibr">21</a>], we present a system for the recognition of &laquo;seven acted emotional states (anger, disgust, fear, joy, sadness, and surprise)&raquo;. To do that, we extracted the MFCC and MS features and used them to train three different machine learning paradigms (MLR, SVM, and RNN). We demonstrated that the combination of both features has a high accuracy above 94% on the Spanish database. All previously published works generally use the Berlin database. To our knowledge, the Spanish emotional database has never been used before. For this reason, we have chosen to compare them. In this chapter, we concentrate to improve accuracy; more experiments have been performed. This chapter mainly makes the following contributions:<ul><li><p id="p5">The effect of speaker normalization (SN) is also studied, which removes the mean of features and normalizes them to unit variance. Experiments are performed under a speaker-independent condition.</p></li><li><p id="p6">Additionally, a feature selection technique is assessed to obtain good features from the set of features extracted in [<a href="#B21" class="ref-link" data-ref-style="bibr">21</a>].</p></li></ul></p><p id="p7">The rest of the chapter is organized as follows. In the next section, we start by introducing the nature of speech emotions. Section 3 describes features we extracted from a speech signal. A feature selection method and machine learning algorithms used for SER are presented. Section 4 reports on the databases we used and presents the simulation results obtained using different features and different machine learning (ML) paradigms. Section 5 closes this chapter by analyses and conclusion.</p></div><div class="section" id="sec_2" data-lvl="1"><a href="https://ehealthcaresolutions.com/contact-us/" target="_blank" class="ads-link">Advertisement</a><div id="video_ad_id_20000" class="ads"></div><h2 class="heading main-title">2. Emotion and classification</h2><p id="p8">This section is concerned with defining the term emotion, presenting its different models. Also for recognizing emotions, there are several techniques and inputs that can be used. A brief description of all of the techniques is presented here.</p><div class="section" id="sec_2_2" data-lvl="2"><h3 class="heading section-title">2.1 Definition</h3><p id="p9">A definition is both important and difficult because the everyday word &ldquo;emotion&rdquo; is a notoriously fluid term in meaning. Emotion is one of the most difficult concepts to define in psychology. In fact, there are different definitions of emotions in the scientific literature. In everyday speech, emotion is any relatively brief conscious experience characterized by intense mental activity and a high degree of pleasure or displeasure [<a href="#B22" class="ref-link" data-ref-style="bibr">22</a>, <a href="#B23" class="ref-link" data-ref-style="bibr">23</a>]. Scientific discourse has drifted to other meanings and there is no consensus on a definition. Emotion is often entwined with temperament, mood, personality, motivation, and disposition. In psychology, emotion is frequently defined as a complex state of feeling that results in physical and psychological changes. These changes influence thought and behavior. According to other theories, emotions are not causal forces but simply syndromes of components such as motivation, feeling, behavior, and physiological changes [<a href="#B24" class="ref-link" data-ref-style="bibr">24</a>]. In 1884, in <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">What is an emotion?</italic></em>[<a href="#B25" class="ref-link" data-ref-style="bibr">25</a>], American psychologist and philosopher William James proposed a theory of emotion whose influence was considerable. According to his thesis, the feeling of intense emotion corresponds to the perception of specific bodily changes. This approach is found in many current theories: the bodily reaction is the cause and not the consequence of the emotion. The scope of this theory is measured by the many debates it provokes. This illustrates the difficulty of agreeing on a definition of this dynamic and complex phenomenon that we call emotion. &ldquo;Emotion&rdquo; refers to a wide range of affective processes such as moods, feelings, affects, and well-being [<a href="#B26" class="ref-link" data-ref-style="bibr">26</a>]. The term &ldquo;emotion&rdquo; in [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>] has been also referred to an extremely complex state associated with a wide variety of mental, physiological, and physical events.</p></div><div class="section" id="sec_3_2" data-lvl="2"><h3 class="heading section-title">2.2 Categorization of emotions</h3><p id="p10">The categorization of emotions has long been a hot subject of debate in different fields of psychology, affective science, and emotion research. It is mainly based on two popular approaches: categorical (termed discrete) and dimensional (termed continuous). In the first approach, emotions are described with a discrete number of classes. Many theorists have conducted studies to determine which emotions are basic [<a href="#B27" class="ref-link" data-ref-style="bibr">27</a>]. A most popular example is Ekman [<a href="#B28" class="ref-link" data-ref-style="bibr">28</a>] who proposed a list of six basic emotions, which are anger, disgust, fear, happiness, sadness, and surprise. He explains that each emotion acts as a discrete category rather than an individual emotional state. In the second approach, emotions are a combination of several psychological dimensions and identified by axes. Other researchers define emotions according to one or more dimensions. Wilhelm Max Wundt proposed in 1897 that emotions can be described by three dimensions: (1) strain versus relaxation, (2) pleasurable versus unpleasurable, and (3) arousing versus subduing [<a href="#B29" class="ref-link" data-ref-style="bibr">29</a>]. PAD emotional state model is another three-dimensional approach by Albert Mehrabian and James Russell where PAD stands for pleasure, arousal, and dominance. Another popular dimensional model was proposed by James Russell in 1977. Unlike the earlier three-dimensional models, Russell&rsquo;s model features only two dimensions which include (1) arousal (or activation) and (2) valence (or evaluation) [<a href="#B29" class="ref-link" data-ref-style="bibr">29</a>].</p><p id="p11">The categorical approach is commonly used in SER [<a href="#B30" class="ref-link" data-ref-style="bibr">30</a>]. It characterizes emotions used in everyday emotion words such as joy and anger. In this work, a set of six basic emotions (anger, disgust, fear, joy, sadness, and surprise) plus neutral, corresponding to the six emotions of Ekman&rsquo;s model, were used for the recognition of emotion from speech using the categorical approach.</p></div><div class="section" id="sec_4_2" data-lvl="2"><h3 class="heading section-title">2.3 Sensory modalities for emotion expression</h3><p id="p12">There is vigorous debate about what exactly individual can express nonverbally. Humans can express their emotions through many different types of nonverbal communication including facial expressions, quality of speech produced, and physiological signals of the human body. In this section, we discuss each of these categories.</p><div class="section" id="sec_4_3" data-lvl="3"><h4 class="heading subsection-title">2.3.1 Facial expressions</h4><p id="p13">The human face is extremely expressive, able to express countless emotions without saying a word [<a href="#B31" class="ref-link" data-ref-style="bibr">31</a>]. And unlike some forms of nonverbal communication, facial expressions are universal. The facial expressions for happiness, sadness, anger, surprise, fear, and disgust are the same across cultures.</p></div><div class="section" id="sec_5_3" data-lvl="3"><h4 class="heading subsection-title">2.3.2 Speech</h4><p id="p14">In addition to faces, voices are an important modality for emotional expression. Speech is a relevant communicational channel enriched with emotions: the voice in speech not only conveys a semantic message but also the information about the emotional state of the speaker. Some important voice feature vectors that have been chosen for research such as fundamental frequency, mel-frequency cepstral coefficient (MFCC), prediction cepstral coefficient (LPCC), etc.</p></div><div class="section" id="sec_6_3" data-lvl="3"><h4 class="heading subsection-title">2.3.3 Physiological signals</h4><p id="p15">The physiological signals related to autonomic nervous system allow to assess objectively emotions. These include electroencephalogram (EEG), heart rate (HR), electrocardiogram (ECG), respiration (RSP), blood pressure (BP), electromyogram (EMG), skin conductance (SC), blood volume pulse (BVP), and skin temperature (ST) [<a href="#B32" class="ref-link" data-ref-style="bibr">32</a>]. Using physiological signals to recognize emotions is also helpful to those people who suffer from physical or mental illness thus exhibit problems with facial expressions or tone of voice.</p></div></div></div><div class="section" id="sec_9" data-lvl="1"><div id="adx_native_ad_110818" class="ads" style="margin-top:-15px"></div><h2 class="heading main-title">3. Speech emotion recognition (SER) system</h2><div class="section" id="sec_9_2" data-lvl="2"><h3 class="heading section-title">3.1 Block diagram</h3><p id="p16">Our SER system consists of four main steps. First is the voice sample collection. The second features vector that is formed by extracting the features. As the next step, we tried to determine which features are most relevant to differentiate each emotion. These features are introduced to machine learning classifier for recognition. This process is described in <a href="#F1" class="ref-link" data-ref-style="fig">Figure 1</a>.</p><figure class="media-panel" id="F1"><div class="media"><img src="/media/chapter/65993/media/F1.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 1.</h4><p></p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p17">Block diagram of the proposed system.</p><p></p></figcaption></figure></div><div class="section" id="sec_10_2" data-lvl="2"><h3 class="heading section-title">3.2. Feature extraction</h3><p id="p18">The speech signal contains a large number of parameters that reflect the emotional characteristics. One of the sticking points in emotion recognition is what features should be used. In recent research, many common features are extracted, such as energy, pitch, formant, and some spectrum features such as linear prediction coefficients (LPC), mel-frequency cepstrum coefficients (MFCC), and modulation spectral features. In this work, we have selected modulation spectral features and MFCC, to extract the emotional features.</p><p id="p19"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Mel-frequency cepstrum coefficient (MFCC)</bold></strong>is the most used representation of the spectral property of voice signals. These are the best for speech recognition as it takes human perception sensitivity with respect to frequencies into consideration. For each frame, the Fourier transform and the energy spectrum were estimated and mapped into the Mel-frequency scale. The discrete cosine transform (DCT) of the Mel log energies was estimated, and the first 12 DCT coefficients provided the MFCC values used in the classification process. Usually, the process of calculating MFCC is shown in <a href="#F2" class="ref-link" data-ref-style="fig">Figure 2</a>.</p><figure class="media-panel" id="F2"><div class="media"><img src="/media/chapter/65993/media/F2.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 2.</h4><p></p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p20">Schema of MFCC extraction [<xref ref-type="bibr" rid="B33">33</xref>].</p><p></p></figcaption></figure><p id="p21">In our research, we extract the first 12 order of the MFCC coefficients where the speech signals are sampled at 16 KHz. For each order coefficients, we calculate the mean, variance, standard deviation, kurtosis, and skewness, and this is for the other all the frames of an utterance. Each MFCC feature vector is 60-dimensional.</p><p id="p22"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Modulation spectral features (MSFs)</bold></strong>are extracted from an auditory-inspired long-term spectro-temporal representation. These features are obtained by emulating the spectro-temporal (ST) processing performed in the human auditory system and consider regular acoustic frequency jointly with modulation frequency. The steps for computing the ST representation are illustrated in <a href="#F3" class="ref-link" data-ref-style="fig">Figure 3</a>. In order to obtain the ST representation, the speech signal is first decomposed by an auditory filterbank (19 filters in total). The Hilbert envelopes of the critical-band outputs are computed to form the modulation signals. A modulation filterbank is further applied to the Hilbert envelopes to perform frequency analysis. The spectral contents of the modulation signals are referred to as modulation spectra, and the proposed features are thereby named modulation spectral features (MSFs) [<a href="#B5" class="ref-link" data-ref-style="bibr">5</a>]. Lastly, the ST representation is formed by measuring the energy of the decomposed envelope signals, as a function of regular acoustic frequency and modulation frequency. The energy, taken over all frames in every spectral band, provides a feature. In our experiment, an auditory filterbank with <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m1"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>19</mml:mn></mml:math></span>filters and a modulation filterbank with <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m2"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math></span>filters are used. In total, 95 <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m3"><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>19</mml:mn><mml:mo>&times;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mfenced></mml:math></span>MSFs are calculated in this work from the ST representation.</p><figure class="media-panel" id="F3"><div class="media"><img src="/media/chapter/65993/media/F3.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 3.</h4><p></p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p23">Process for computing the ST representation [<xref ref-type="bibr" rid="B5">5</xref>].</p><p></p></figcaption></figure></div><div class="section" id="sec_11_2" data-lvl="2"><h3 class="heading section-title">3.3 Feature selection</h3><p id="p24">As reported by Aha and Bankert [<a href="#B34" class="ref-link" data-ref-style="bibr">34</a>], the objective of feature selection in ML is to &ldquo;reduce the number of features used to characterize a dataset so as to improve a learning algorithm&rsquo;s performance on a given task.&rdquo; The objective will be the maximization of the classification accuracy in a specific task for a certain learning algorithm; as a collateral effect, the number of features to induce the final classification model will be reduced. Feature selection (FS) aims to choose a subset of the relevant features from the original ones according to certain relevance evaluation criterion, which usually leads to higher recognition accuracy [<a href="#B35" class="ref-link" data-ref-style="bibr">35</a>]. It can drastically reduce the running time of the learning algorithms. In this section, we present an effective feature selection method used in our work, named recursive feature elimination with linear regression (LR-RFE).</p><p id="p25"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Recursive feature elimination (RFE)</bold></strong>uses a model (e.g., linear regression or SVM) to select either the best- or worst-performing feature and then excludes this feature. These estimators assign weights to features (e.g., the coefficients of a linear model), so the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features, and the predictive power of each feature is measured [<a href="#B36" class="ref-link" data-ref-style="bibr">36</a>]. Then, the least important features are removed from the current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached. In this work, we implemented the recursive feature elimination method of feature ranking via the use of basic linear regression (LR-RFE) [<a href="#B37" class="ref-link" data-ref-style="bibr">37</a>]. Other research also uses RFE with another linear model such as SVM-RFE that is an SVM-based feature selection algorithm created by [<a href="#B38" class="ref-link" data-ref-style="bibr">38</a>]. Using SVM-RFE, Guyon et al. selected key and important feature sets. In addition to improving the classification accuracy rate, it can reduce classification computational time.</p></div><div class="section" id="sec_12_2" data-lvl="2"><h3 class="heading section-title">3.4 Classification methods</h3><p id="p26">Many machine learning algorithms have been used for discrete emotion classification. The goal of these algorithms is to learn from the training samples and then use this learning to classify new observation. In fact, there is no definitive answer to the choice of the learning algorithm; every technique has its own advantages and limitations. For this reason, here we chose to compare the performance of three different classifiers.</p><p id="p27"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Multivariate linear regression classification (MLR)</bold></strong>is a simple and efficient computation of machine learning algorithms, and it can be used for both regression and classification problems. We have slightly modified the LRC algorithm described as follow Algorithm 1 [<a href="#B39" class="ref-link" data-ref-style="bibr">39</a>]. We calculated (in step 3) the absolute value of the difference between original and predicted response vectors (<span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m4"><mml:mo>&#8739;</mml:mo><mml:mi>y</mml:mi><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8739;</mml:mo></mml:math></span>), instead of the Euclidean distance between them (<span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m5"><mml:mo stretchy="true">&#8214;</mml:mo><mml:mi>y</mml:mi><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">&#8214;</mml:mo></mml:math></span>).</p><p id="p28"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Support vector machines (SVM)</bold></strong>are an optimal margin classifier in machine learning. It is also used extensively in many studies that related to audio emotion recognition which can be found in [<a href="#B10" class="ref-link" data-ref-style="bibr">10</a>, <a href="#B13" class="ref-link" data-ref-style="bibr">13</a>, <a href="#B14" class="ref-link" data-ref-style="bibr">14</a>]. It can have a very good classification performance compared to other classifiers especially for limited training data [<a href="#B11" class="ref-link" data-ref-style="bibr">11</a>]. SVM theoretical background can be found in [<a href="#B40" class="ref-link" data-ref-style="bibr">40</a>]. A MATLAB toolbox implementing SVM is freely available in [<a href="#B41" class="ref-link" data-ref-style="bibr">41</a>]. A polynomial kernel is investigated in this work.</p><p id="p29"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Algorithm 1.</bold></strong>Linear Regression Classification (LRC)</p><p id="p30">Inputs: Class models <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m6"><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&isin;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mo>&times;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&hellip;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math></span>and a test speech vector <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m7"><mml:mi>y</mml:mi><mml:mo>&isin;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mo>&times;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></span></p><p id="p31">Output: Class of <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m8"><mml:mi>y</mml:mi></mml:math></span></p><p id="p32">1. <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m9"><mml:msub><mml:mover accent="true"><mml:mi>&beta;</mml:mi><mml:mo stretchy="false">&#770;</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>&isin;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&times;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></span>is evaluated against each class model, <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m10"><mml:msub><mml:mover accent="true"><mml:mi>&beta;</mml:mi><mml:mo stretchy="false">&#770;</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mfenced open="(" close=")"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mfenced open="(" close=")"><mml:mrow><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:msup><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>y</mml:mi><mml:mo>,</mml:mo></mml:math></span><span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m11"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&hellip;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math></span></p><p id="p33">2. <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m12"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">&#770;</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></span>is computed for each <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m13"><mml:msub><mml:mover accent="true"><mml:mi>&beta;</mml:mi><mml:mo stretchy="false">&#770;</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">&#770;</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>&beta;</mml:mi><mml:mo stretchy="false">&#770;</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"></mml:mspace><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&hellip;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math></span>;</p><p id="p34">3. Distance calculation between original and predicted response variables <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m14"><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>y</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>y</mml:mi><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8739;</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"></mml:mspace><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&hellip;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math></span>;</p><p id="p35">4. Decision is made in favor of the class with the minimum distance <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m15"><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>y</mml:mi></mml:mfenced></mml:math></span></p><p id="p36"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Recurrent neural networks (RNN)</bold></strong>are suitable for learning time series data, and it has shown improved performance for classification task [<a href="#B42" class="ref-link" data-ref-style="bibr">42</a>]. While RNN models are effective at learning temporal correlations, they suffer from the vanishing gradient problem which increases with the length of the training sequences. To resolve this problem, long short-term memory (LSTM) RNNs were proposed by Hochreiter et al. [<a href="#B43" class="ref-link" data-ref-style="bibr">43</a>]; it uses memory cells to store information so that it can exploit long-range dependencies in the data [<a href="#B17" class="ref-link" data-ref-style="bibr">17</a>].</p><p id="p37"><a href="#F4" class="ref-link" data-ref-style="fig">Figure 4</a> shows a basic concept of RNN implementation. Unlike traditional neural network that uses different parameters at each layer, the RNN shares the same parameters (U, V, and W are presented in <a href="#F4" class="ref-link" data-ref-style="fig">Figure 4</a>) across all steps. The hidden state formulas and variables are as follows:</p><figure class="media-panel" id="F4"><div class="media"><img src="/media/chapter/65993/media/F4.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 4.</h4><p></p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p38">A basic concept of RNN and unfolding in time of the computation involved in its forward computation [<xref ref-type="bibr" rid="B18">18</xref>].</p><p></p></figcaption></figure><div id="df_" class="formula panel"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" specific-use="web-only"><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Ux</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="italic">Ws</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><span class="equ"></span></div><p id="p39">where <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m17"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></span>, <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m18"><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></span>, and <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m19"><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></span>are respectively the input, the hidden state, and the output at time step t and <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m20"><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>W</mml:mi></mml:math></span>are parameters matrices.</p></div></div><div class="section" id="sec_14" data-lvl="1"><div id="adx_native_ad_110743" class="ads" style="margin-top:-15px"></div><h2 class="heading main-title">4. Experimental results and analysis</h2><div class="section" id="sec_14_2" data-lvl="2"><h3 class="heading section-title">4.1 Emotional speech databases</h3><p id="p40">The performance and robustness of the recognition systems will be easily affected if it is not well trained with a suitable database. Therefore, it is essential to have sufficient and suitable phrases in the database to train the emotion recognition system and subsequently evaluate its performance. There are three main types of databases: acted emotions, natural spontaneous emotions, and elicited emotions [<a href="#B27" class="ref-link" data-ref-style="bibr">27</a>, <a href="#B44" class="ref-link" data-ref-style="bibr">44</a>]. In this work, we used an acted emotion databases because they contain strong emotional expressions. The literature on speech emotion recognition [<a href="#B45" class="ref-link" data-ref-style="bibr">45</a>] shows that the majority of studies have been conducted with emotional acted speech. In this section, we detailed the two emotional speech databases used for classifying discrete emotions in our experiments: Berlin Database and Spanish Database.</p></div><div class="section" id="sec_15_2" data-lvl="2"><h3 class="heading section-title">4.2 Berlin database</h3><p id="p41">The Berlin database [<a href="#B46" class="ref-link" data-ref-style="bibr">46</a>] is widely used in emotional speech recognition. It contains 535 utterances spoken by 10 actors (5 female, 5 male) in 7 simulated emotions (anger, boredom, disgust, fear, joy, sadness, and neutral). This database was chosen for the following reasons: (i) the quality of its recording is very good, and (ii) it is public [<a href="#B47" class="ref-link" data-ref-style="bibr">47</a>] and popular database of emotion recognition that is recommended in the literature [<a href="#B19" class="ref-link" data-ref-style="bibr">19</a>].</p></div><div class="section" id="sec_16_2" data-lvl="2"><h3 class="heading section-title">4.3 Spanish database</h3><p id="p42">The INTER1SP Spanish emotional database contains utterances from two professional actors (one female and one male speaker).The Spanish corpus that we have the right to access (free for academic and research use) [<a href="#B48" class="ref-link" data-ref-style="bibr">48</a>] was recorded twice in the &laquo;six basic emotions plus neutral (anger, sadness, joy, fear, disgust, surprise and neutral/normal)&raquo;. Four additional neutral variations (soft, loud, slow, and fast) were recorded once. This is preferred to other created database because it is available for researchers use and it contains more data (6041 utterances in total). This paper has focused on only seven main emotions from the Spanish database in order to achieve a higher and more accurate rate of recognition and to make the comparison with the Berlin database detailed above.</p></div><div class="section" id="sec_17_2" data-lvl="2"><h3 class="heading section-title">4.4 Results and analysis</h3><p id="p43">In this section, experimentation results are presented and discussed. We report the recognition accuracy of using MLR, SVM, and RNN classifiers. Experimental evaluation is performed on the Berlin and Spanish databases. All classification results are obtained under tenfold cross-validation. Cross-validation is a common practice used in performance analysis that randomly partitions the data into N complementary subsets, with <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m21"><mml:mi>N</mml:mi><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:math></span>of them used for training in each validation and the remaining one used for testing. The neural network structure used is a simple LSTM. It consists of two consecutive LSTM layers with hyperbolic tangent activation followed by two classification dense layers. Features from data are scaled to <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m22"><mml:mfenced open="[" close="]" separators=","><mml:mrow><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:mfenced></mml:math></span>before applying classifiers. Scaling features before recognition is important, because when a learning phase is fit on unscaled data, it is possible for large inputs to slow down the learning and convergence and in some cases prevent the used classifier from effectively learning for the classification problem. The effect of speaker normalization (SN) step prior to recognition is investigated, and there are three different SN schemes that are defined in [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>]. SN is useful to compensate for the variations due to speaker diversity rather than the change of emotional state. We used in this section the SN scheme that has given the best results in [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>]. The features of each speaker are normalized with a mean of <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m23"><mml:mn>0</mml:mn></mml:math></span>and a standard deviation of <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m24"><mml:mn>1</mml:mn></mml:math></span>. <a href="#tab1" class="ref-link" data-ref-style="table">Tables 1</a>, <a href="#tab2" class="ref-link" data-ref-style="table">2</a>, <a href="#tab3" class="ref-link" data-ref-style="table">3</a> show the recognition rate for each combination of various features and classifiers based on Berlin and Spanish databases. These experiments use feature set without feature selection. As shown in <a href="#tab1" class="ref-link" data-ref-style="table">Table 1</a>, SVM classifier yields better results above 81%, with feature combination of MFCC and MS for Berlin database. Our results have improved compared to previous results in [<a href="#B21" class="ref-link" data-ref-style="bibr">21</a>] because we changed the SVM parameters for each type of features to develop a good model.</p><div class="table-wrap" id="tab1"><div class="table-content"><table frame="hsides" rules="groups"><col><col><col><col><col><col><col><col><col><col><col><col><col><thead><tr><th></th><th></th><th></th><th></th><th colspan="7" align="left">Recognition rate (%)</th><th colspan="2"></th></tr><tr><th>Test</th><th align="left">Feature</th><th align="left">Method</th><th align="left">SN</th><th align="left">A</th><th align="left">E</th><th align="left">F</th><th align="left">L</th><th align="left">N</th><th align="left">T</th><th align="left">W</th><th align="left">AVG.</th><th align="left">(<span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m25"><mml:mi>&sigma;</mml:mi></mml:math></span>)</th></tr></thead><tbody><tr><td rowspan="3">#1</td><td align="left">MS</td><td rowspan="3" align="left">MLR</td><td rowspan="3" align="left">No</td><td align="left">45.90</td><td align="left">45.72</td><td align="left">48.78</td><td align="left">77.08</td><td align="left">59.43</td><td align="left">79.91</td><td align="left">75.94</td><td align="left">66.23</td><td align="left">(5.85)</td></tr><tr><td align="left">MFCC</td><td align="left">56.55</td><td align="left">62.28</td><td align="left">45.60</td><td align="left">54.97</td><td align="left">57.35</td><td align="left">74.36</td><td align="left">91.37</td><td align="left">64.70</td><td align="left">(3.20)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">70.26</td><td align="left">73.04</td><td align="left">51.95</td><td align="left">82.44</td><td align="left">69.55</td><td align="left">82.49</td><td align="left">76.55</td><td align="left">73.00</td><td align="left">(3.23)</td></tr><tr><td rowspan="3" align="left">#2</td><td align="left">MS</td><td rowspan="3" align="left">SVM</td><td rowspan="3" align="left">No</td><td align="left">56.61</td><td align="left">54.78</td><td align="left">51.17</td><td align="left">70.98</td><td align="left">67.32</td><td align="left">67.50</td><td align="left">73.13</td><td align="left">70.63</td><td align="left">(6.45)</td></tr><tr><td align="left">MFCC</td><td align="left">73.99</td><td align="left">64.14</td><td align="left">64.76</td><td align="left">55.30</td><td align="left">62.28</td><td align="left">84.13</td><td align="left">83.13</td><td align="left">71.70</td><td align="left">(4.24)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">82.03</td><td align="left">68.70</td><td align="left">69.09</td><td align="left">79.16</td><td align="left">76.99</td><td align="left">80.89</td><td align="left">80.63</td><td align="left">81.10</td><td align="left">(2.73)</td></tr><tr><td rowspan="3" align="left">#3</td><td align="left">MS</td><td rowspan="3" align="left">MLR</td><td rowspan="3" align="left">Yes</td><td align="left">48.98</td><td align="left">35.54</td><td align="left">32.66</td><td align="left">80.35</td><td align="left">55.54</td><td align="left">88.79</td><td align="left">85.77</td><td align="left">64.20</td><td align="left">(5.27)</td></tr><tr><td align="left">MFCC</td><td align="left">59.71</td><td align="left">59.72</td><td align="left">48.65</td><td align="left">67.10</td><td align="left">67.98</td><td align="left">91.73</td><td align="left">87.51</td><td align="left">71.00</td><td align="left">(4.19)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">72.32</td><td align="left">68.82</td><td align="left">51.98</td><td align="left">82.60</td><td align="left">81.72</td><td align="left">91.96</td><td align="left">80.71</td><td align="left">75.25</td><td align="left">(2.49)</td></tr><tr><td rowspan="3" align="left">#4</td><td align="left">MS</td><td rowspan="3" align="left">SVM</td><td rowspan="3" align="left">Yes</td><td align="left">62.72</td><td align="left">49.44</td><td align="left">37.29</td><td align="left">76.14</td><td align="left">71.30</td><td align="left">88.44</td><td align="left">80.15</td><td align="left">71.90</td><td align="left">(2.38)</td></tr><tr><td align="left">MFCC</td><td align="left">70.68</td><td align="left">56.55</td><td align="left">56.99</td><td align="left">59.88</td><td align="left">68.14</td><td align="left">91.88</td><td align="left">85.44</td><td align="left">77.60</td><td align="left">(4.35)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">77.37</td><td align="left">69.67</td><td align="left">58.16</td><td align="left">79.87</td><td align="left">88.57</td><td align="left">98.75</td><td align="left">86.64</td><td align="left">81.00</td><td align="left">(2.45)</td></tr></tbody></table></div><div class="table-caption"><h3 class="heading">Table 1.</h3><div class="text"><p id="p45">Recognition results with MS, MFCC features, and their combination on Berlin database; AVG. denotes average recognition rate; <span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m26"><mml:mi>&sigma;</mml:mi></mml:math></span>denotes standard deviation of the 10-cross-validation accuracies.</p></div><div class="text"><p id="p44">Berlin (a, fear; e, disgust; f, happiness; l, boredom; n, neutral; t, sadness; w, anger).</p></div></div></div><div class="table-wrap" id="tab2"><div class="table-content"><table frame="hsides" rules="groups"><col><col><col><col><col><col><col><col><col><col><col><col><col><thead><tr><th></th><th></th><th></th><th></th><th colspan="7" align="left">Recognition rate (%)</th><th></th><th></th></tr><tr><th>Test</th><th align="left">Feature</th><th align="left">Method</th><th align="left">SN</th><th align="left">A</th><th align="left">D</th><th align="left">F</th><th align="left">J</th><th align="left">N</th><th align="left">S</th><th align="left">T</th><th align="left">AVG.</th><th align="left">(<span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m27"><mml:mi>&sigma;</mml:mi></mml:math></span>)</th></tr></thead><tbody><tr><td rowspan="3">#1</td><td align="left">MS</td><td rowspan="3" align="left">MLR</td><td rowspan="3" align="left">No</td><td align="left">67.72</td><td align="left">44.04</td><td align="left">68.78</td><td align="left">46.95</td><td align="left">89.58</td><td align="left">63.10</td><td align="left">78.49</td><td align="left">69.22</td><td align="left">(1.37)</td></tr><tr><td align="left">MFCC</td><td align="left">67.85</td><td align="left">61.41</td><td align="left">75.97</td><td align="left">60.17</td><td align="left">95.79</td><td align="left">71.89</td><td align="left">84.94</td><td align="left">77.21</td><td align="left">(0.76)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">78.75</td><td align="left">78.18</td><td align="left">80.68</td><td align="left">63.84</td><td align="left">96.80</td><td align="left">82.44</td><td align="left">89.01</td><td align="left">83.55</td><td align="left">(0.55)</td></tr><tr><td rowspan="3">#2</td><td align="left">MS</td><td rowspan="3" align="left">SVM</td><td rowspan="3" align="left">No</td><td align="left">70.33</td><td align="left">69.38</td><td align="left">78.09</td><td align="left">60.97</td><td align="left">89.25</td><td align="left">69.38</td><td align="left">85.95</td><td align="left">80.98</td><td align="left">(1.09)</td></tr><tr><td align="left">MFCC</td><td align="left">79.93</td><td align="left">79.02</td><td align="left">81.81</td><td align="left">75.71</td><td align="left">93.77</td><td align="left">80.15</td><td align="left">92.01</td><td align="left">90.94</td><td align="left">(0.93)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">84.90</td><td align="left">88.26</td><td align="left">89.44</td><td align="left">80.90</td><td align="left">96.58</td><td align="left">83.89</td><td align="left">95.63</td><td align="left">89.69</td><td align="left">(0.62)</td></tr><tr><td rowspan="3">#3</td><td align="left">MS</td><td rowspan="3" align="left">MLR</td><td rowspan="3" align="left">Yes</td><td align="left">64.76</td><td align="left">49.02</td><td align="left">66.87</td><td align="left">44.52</td><td align="left">87.50</td><td align="left">58.26</td><td align="left">78.70</td><td align="left">67.84</td><td align="left">(1.27)</td></tr><tr><td align="left">MFCC</td><td align="left">66.54</td><td align="left">57.83</td><td align="left">74.56</td><td align="left">56.98</td><td align="left">94.02</td><td align="left">72.32</td><td align="left">89.63</td><td align="left">76.47</td><td align="left">(1.51)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">77.01</td><td align="left">78.45</td><td align="left">80.50</td><td align="left">64.18</td><td align="left">94.42</td><td align="left">80.14</td><td align="left">91.29</td><td align="left">83.03</td><td align="left">(0.97)</td></tr><tr><td rowspan="3">#4</td><td align="left">MS</td><td rowspan="3" align="left">SVM</td><td rowspan="3" align="left">Yes</td><td align="left">69.81</td><td align="left">70.35</td><td align="left">75.44</td><td align="left">52.60</td><td align="left">86.77</td><td align="left">66.94</td><td align="left">82.57</td><td align="left">78.40</td><td align="left">(1.64)</td></tr><tr><td align="left">MFCC</td><td align="left">77.45</td><td align="left">77.41</td><td align="left">80.99</td><td align="left">69.47</td><td align="left">91.89</td><td align="left">75.17</td><td align="left">93.50</td><td align="left">87.47</td><td align="left">(0.95)</td></tr><tr><td align="left">MFCC+SM</td><td align="left">85.28</td><td align="left">84.54</td><td align="left">84.49</td><td align="left">73.47</td><td align="left">93.43</td><td align="left">81.79</td><td align="left">94.04</td><td align="left">86.57</td><td align="left">(0.72)</td></tr></tbody></table></div><div class="table-caption"><h3 class="heading">Table 2.</h3><div class="text"><p id="p47">Recognition results with MS, MFCC features, and their combination on Spanish database.</p></div><div class="text"><p id="p46">Spanish (a, anger; d, disgust; f, fear; j, joy; n, neutral; s, surprise; t, sadness).</p></div></div></div><div class="table-wrap" id="tab3"><div class="table-content"><table frame="hsides" rules="groups"><col><col><col><col><col><thead><tr><th>Dataset</th><th align="left">Feature</th><th align="left">SN</th><th align="left">Average (avg)</th><th align="left">Standard deviation (<span class="inline-formula"><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m28"><mml:mi>&sigma;</mml:mi></mml:math></span>)</th></tr></thead><tbody><tr><td rowspan="6">Berlin</td><td align="left">MS</td><td rowspan="2" align="left">No</td><td align="left">66.32</td><td align="left">5.93</td></tr><tr><td align="left">MFCC</td><td align="left">69.55</td><td align="left">3.91</td></tr><tr><td align="left">MFCC+MS</td><td rowspan="3" align="left">Yes</td><td align="left">63.67</td><td align="left">7.74</td></tr><tr><td align="left">MS</td><td align="left">68.94</td><td align="left">5.65</td></tr><tr><td align="left">MFCC</td><td align="left">73.08</td><td align="left">5.17</td></tr><tr><td align="left">MFCC+MS</td><td></td><td align="left">76.98</td><td align="left">4.79</td></tr><tr><td rowspan="6">Spanish</td><td align="left">MS</td><td rowspan="3" align="left">No</td><td align="left">82.30</td><td align="left">2.88</td></tr><tr><td align="left">MFCC</td><td align="left">86.56</td><td align="left">2.80</td></tr><tr><td align="left">MFCC+MS</td><td align="left">90.05</td><td align="left">1.64</td></tr><tr><td align="left">MS</td><td rowspan="3" align="left">Yes</td><td align="left">82.14</td><td align="left">1.67</td></tr><tr><td align="left">MFCC</td><td align="left">86.21</td><td align="left">1.22</td></tr><tr><td align="left">MFCC+MS</td><td align="left">87.02</td><td align="left">0.36</td></tr></tbody></table></div><div class="table-caption"><h3 class="heading">Table 3.</h3><div class="text"><p id="p48">Recognition results using RNN classifier based on Berlin and Spanish databases.</p></div><div class="text"></div></div></div><p id="p49">From <a href="#tab1" class="ref-link" data-ref-style="table">Table 1</a>, it can be concluded that applying SN improves recognition results for Berlin database. But this is not the case for the Spanish database, as demonstrated in <a href="#tab2" class="ref-link" data-ref-style="table">Tables 2</a> and <a href="#tab3" class="ref-link" data-ref-style="table">3</a>. Results are the same with the three different classifiers. This can be explained by the number of speakers in each database. The Berlin database contains 10 different speakers, compared to the Spanish database that contains only two speakers and probably the language impact. As regarding the RNN method, we found that combining both types of features has the worst recognition rate for the Berlin database, as shown in <a href="#tab3" class="ref-link" data-ref-style="table">Table 3</a>. That is because the RNN model has too many parameters (155 coefficients in total) and a poor training data. This is the phenomena of overfitting. This is confirmed by the fact that when we reduced the number of features from 155 to 59 features, the results show an increase of above 13%, as shown in <a href="#tab4" class="ref-link" data-ref-style="table">Table 4</a>. To investigate whether a smaller feature space leads to better recognition performance, we repeated all evaluations on the development set by applying a recursive feature elimination (LR-RFE) for each modality combination. The stability of RFE depends heavily on the type of model that is used for feature ranking at each iteration. In our case, we tested the RFE based on an SVM and regression models; we found that using linear regression provides more stable results. We observed from the previous results that the combination of the features gives the best results. So we applied LR-RFE feature selection only for this combination to improve accuracy. In this work, a total of 155 features were used; best features were chosen from feature selection. Fifty-nine features were selected by RFE feature selection method based on LR from the Berlin database and 110 features from the Spanish database. The corresponding results of LR-RFE can be seen in <a href="#tab4" class="ref-link" data-ref-style="table">Table 4</a>. For most setting using the Spanish database, LR-RFE does not significantly improve the average accuracy. However, for recognition based on Berlin database using the three classifiers, LR-RFE leads to a remarkable performance gain, as shown in <a href="#F5" class="ref-link" data-ref-style="fig">Figure 5</a>. This increases the average of MFCC combined with MS features from 63.67 to 78.11% for RNN classifier. These results are illustrated in <a href="#tab4" class="ref-link" data-ref-style="table">Table 4</a>. For the Spanish database, the feature combination of MFCC and MS after applying LR-RFE selection using RNN has the best recognition rate which is above 94.01%.</p><div class="table-wrap" id="tab4"><div class="table-content"><table frame="hsides" rules="groups"><col><col><col><col><col><thead><tr><th>SN</th><th align="left">Classifier</th><th align="left">LR-RFE</th><th align="left">Berlin</th><th align="left">Spanish</th></tr></thead><tbody><tr><td rowspan="6">No</td><td rowspan="2" align="left">MLR</td><td align="left">No</td><td align="left">73.00 (3.23)</td><td align="left">83.55 (0.55)</td></tr><tr><td align="left">Yes</td><td align="left">79.40 (3.09)</td><td align="left">84.19 (0.96)</td></tr><tr><td rowspan="2" align="left">SVM</td><td align="left">No</td><td align="left">81.10 (2.73)</td><td align="left">89.69 (0.62)</td></tr><tr><td align="left">Yes</td><td align="left">80.90 (3.17)</td><td align="left">90.05 (0.80)</td></tr><tr><td rowspan="2" align="left">RNN</td><td align="left">No</td><td align="left">63.67 (7.74)</td><td align="left">90.05 (1.64)</td></tr><tr><td align="left">Yes</td><td align="left">78.11 (3.53)</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">94.01</bold></strong>(0.76)</td></tr><tr><td rowspan="6">Yes</td><td rowspan="2" align="left">MLR</td><td align="left">No</td><td align="left">75.25 (2.49)</td><td align="left">83.03 (0.97)</td></tr><tr><td align="left">Yes</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">83.20</bold></strong>(3.25)</td><td align="left">82.27 (1.12)</td></tr><tr><td rowspan="2" align="left">SVM</td><td align="left">No</td><td align="left">81.00 (2.45)</td><td align="left">86.57 (0.72)</td></tr><tr><td align="left">Yes</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">83.90</bold></strong>(2.46)</td><td align="left">86.47 (1.34)</td></tr><tr><td rowspan="2">RNN</td><td align="left">No</td><td align="left">76.98 (4.79)</td><td align="left">87.02 (0.36)</td></tr><tr><td align="left">Yes</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">83.42</bold></strong>(0.70)</td><td align="left">85.00 (0.93)</td></tr></tbody></table></div><div class="table-caption"><h3 class="heading">Table 4.</h3><div class="text"><p id="p50">Recognition results with combination of MFCC and MS features using ML paradigm before and after applying LR-RFE feature selection method (Berlin and Spanish databases).</p></div><div class="text"></div></div></div><figure class="media-panel" id="F5"><div class="media"><img src="/media/chapter/65993/media/F5.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 5.</h4><p></p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p51">Performance comparison of three machine learning paradigms (MLR, SVM, RNN) using speaker normalization (SN) and RFE feature selection (FS), for the Berlin database, is shown.</p><p></p></figcaption></figure><p id="p52">The confusion matrix for the best recognition of emotions using MFCC and MS features with RNN based on Spanish database is shown in <a href="#tab5" class="ref-link" data-ref-style="table">Table 5</a>. The rate column lists per class recognition rates and precision for a class are the number of samples correctly classified divided by the total number of samples classified to the class. It can be seen that <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Neutral</italic></em>was the emotion that was least difficult to recognize from speech as opposed to <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Disgust</italic></em>which was the most difficult and it forms the most notable confusion pair with <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Fear</italic></em>.</p><div class="table-wrap" id="tab5"><div class="table-content"><table frame="hsides" rules="groups"><col><col><col><col><col><col><col><col><col><thead><tr><th>Emotion</th><th align="left">Anger</th><th align="left">Disgust</th><th align="left">Fear</th><th align="left">Joy</th><th align="left">Neutral</th><th align="left">Surprise</th><th align="left">Sadness</th><th align="left">Rate (%)</th></tr></thead><tbody><tr><td align="left">Anger</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">79</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">2</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">3</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">91.86</bold></strong></td></tr><tr><td align="left">Disgust</td><td align="left">0</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">67</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">3</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">93.05</bold></strong></td></tr><tr><td align="left">Fear</td><td align="left">0</td><td align="left">3</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">70</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">2</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">93.33</bold></strong></td></tr><tr><td align="left">Joy</td><td align="left">3</td><td align="left">1</td><td align="left">1</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">71</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">93.42</bold></strong></td></tr><tr><td align="left">Neutral</td><td align="left">2</td><td align="left">0</td><td align="left">1</td><td align="left">0</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">156</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">97.50</bold></strong></td></tr><tr><td align="left">surprise</td><td align="left">2</td><td align="left">1</td><td align="left">0</td><td align="left">3</td><td align="left">0</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">60</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">92.30</bold></strong></td></tr><tr><td align="left">Sadness</td><td align="left">0</td><td align="left">0</td><td align="left">1</td><td align="left">0</td><td align="left">2</td><td align="left">0</td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">66</bold></strong></td><td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">95.65</bold></strong></td></tr><tr><td align="left">Precision (%)</td><td align="left">91.86</td><td align="left">91.78</td><td align="left">92.10</td><td align="left">94.66</td><td align="left">96.29</td><td align="left">95.23</td><td align="left">94.28</td><td></td></tr></tbody></table></div><div class="table-caption"><h3 class="heading">Table 5.</h3><div class="text"><p id="p53">Confusion matrix for feature combination after LR-RFE selection based on Spanish database.</p></div><div class="text"></div></div></div></div></div><div class="section" id="sec_19" data-lvl="1"><h2 class="heading main-title">5. Conclusion</h2><p id="p54">In this current study, we presented an automatic speech emotion recognition (SER) system using three machine learning algorithms (MLR, SVM, and RNN) to classify seven emotions. Thus, two types of features (MFCC and MS) were extracted from two different acted databases (Berlin and Spanish databases), and a combination of these features was presented. In fact, we study how classifiers and features impact recognition accuracy of emotions in speech. A subset of highly discriminant features is selected. Feature selection techniques show that more information is not always good in machine learning applications. The machine learning models were trained and evaluated to recognize emotional states from these features. SER reported the best recognition rate of 94% on the Spanish database using RNN classifier without speaker normalization (SN) and with feature selection (FS). For Berlin database, all of the classifiers achieve an accuracy of 83% when a speaker normalization (SN) and a feature selection (FS) are applied to the features. From this result, we can see that RNN often perform better with more data and it suffers from the problem of very long training times. Therefore, we concluded that the SVM and MLR models have a good potential for practical usage for limited data in comparison with RNN .</p><p id="p55">Enhancement of the robustness of emotion recognition system is still possible by combining databases and by fusion of classifiers. The effect of training multiple emotion detectors can be investigated by fusing these into a single detection system. We aim also to use other feature selection methods because the quality of the feature selection affects the emotion recognition rate: a good emotion feature selection method can select features reflecting emotion state quickly. The overall aim of our work is to develop a system that will be used in a pedagogical interaction in classrooms, in order to help the teacher to orchestrate his class. For achieving this goal, we aim to test the system proposed in this work.</p></div></div><div id="adx_native_ad_110741" class="ads" style="margin-top:-15px;margin-bottom:7rem" data-v-89ab6a34></div><!----></div></div><aside class="aside cf" style="position:relative" data-v-89ab6a34><div style="position:absolute;top:0;bottom:0;display:block" data-v-89ab6a34><div class="track" data-v-89ab6a34><div class="share cf" data-v-1af021d0 data-v-89ab6a34><a class="cta button-type-2" data-v-1af021d0><span class="iconShare" data-v-1af021d0>Share<br data-v-1af021d0>this chapter</span></a><a rel="" href="/chapter/pdf-download/65993" class="cta button-type-1" style="display:flex;align-items:center;height:80px!important" data-v-1af021d0><span class="iconPdf" data-v-1af021d0>DOWNLOAD FOR FREE</span></a><!----></div><section class="sections-toggle" data-v-515c83ac data-v-89ab6a34><h3 class="title" data-v-515c83ac>Sections</h3><div class="clip" data-v-515c83ac><a class="shortcut capitalize" data-v-515c83ac>chapter and author info</a><ul class="list" data-v-515c83ac><li class="item" data-v-08125deb data-v-515c83ac><span class="item-order" data-v-08125deb>1.</span><a class="item-link" data-v-08125deb>Introduction</a></li><li class="item" data-v-08125deb data-v-515c83ac><span class="item-order" data-v-08125deb>2.</span><a class="item-link" data-v-08125deb>Emotion and classification</a></li><li class="item" data-v-08125deb data-v-515c83ac><span class="item-order" data-v-08125deb>3.</span><a class="item-link" data-v-08125deb>Speech emotion recognition (SER) system</a></li><li class="item" data-v-08125deb data-v-515c83ac><span class="item-order" data-v-08125deb>4.</span><a class="item-link" data-v-08125deb>Experimental results and analysis</a></li><li class="item" data-v-08125deb data-v-515c83ac><span class="item-order" data-v-08125deb>5.</span><a class="item-link" data-v-08125deb>Conclusion</a></li></ul><!----><a href="https://ehealthcaresolutions.com/contact-us/" target="_blank" class="ads-link" data-v-515c83ac>Advertisement</a><div id="intechopen-intechopen-2" data-v-515c83ac></div><!----><!----></div></section></div></div></aside></div><div class="container cf" data-v-930ff012 data-v-89ab6a34><div class="box" data-v-930ff012><h2 class="title" data-v-930ff012>DOWNLOAD FOR FREE</h2><a rel="" href="/chapter/pdf-download/65993" class="link" data-v-930ff012><span class="capitalize" data-v-930ff012>chapter PDF</span></a><br data-v-930ff012><a href="/chapter/ris/65993" class="link" data-v-930ff012>Citations in RIS format</a><br data-v-930ff012><a href="/chapter/bibtex/65993" class="link" data-v-930ff012>Citations in bibtex format</a></div><div class="box" data-v-930ff012><h2 class="title" data-v-930ff012>Share</h2><a href="mailto:?subject=IntechOpen, Automatic Speech Emotion Recognition Using Machine Learning&amp;body=Hi, check this out! https://www.intechopen.com/chapters/65993" class="link" data-v-930ff012>Email chapter link</a><br data-v-930ff012><a class="link" data-v-930ff012>Share on my website</a><br data-v-930ff012><a href="https://www.mendeley.com/?interaction_required=true" target="_blank" class="link" data-v-930ff012>Save to Mendeley</a><br data-v-930ff012><a href="https://www.readcube.com/home" target="_blank" class="link" data-v-930ff012>Read in ReadCube</a><br data-v-930ff012><a href="https://twitter.com/intent/tweet?url=https://www.intechopen.com/chapters/65993&amp;text=@IntechOpen Automatic Speech Emotion Recognition Using Machine Learning" data-type="facebook" target="_blank" class="icr iconTwitter" data-v-930ff012>Share on Twitter</a><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.intechopen.com/chapters/65993" data-type="facebook" target="_blank" class="icr iconFb" data-v-930ff012>Share on Facebook</a><a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.intechopen.com/chapters/65993&amp;title=Automatic Speech Emotion Recognition Using Machine Learning" data-type="facebook" target="_blank" class="icr iconLinkedIn" data-v-930ff012>Share on LinkedIn</a></div><div class="box" data-v-930ff012><h2 class="title" data-v-930ff012>More</h2><a href="/chapter/pdf-preview/65993" target="_blank" class="cta button-type-2" data-v-930ff012><span class="iconPrint" data-v-930ff012>Print chapter</span></a></div><div class="clear" data-v-930ff012></div><div class="last-box" data-v-930ff012><!----><p class="text-2" data-v-930ff012>© 2019 The Author(s). Licensee IntechOpen. This chapter is distributed under the terms of the <a href="http://creativecommons.org/licenses/by/3.0" target="_blank" class="embedded-link" data-v-930ff012>Creative Commons Attribution 3.0 License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!----></div></div><div class="ad-wraper" data-v-89ab6a34><!----><!----></div><div class="container cf" data-v-6b5f8e70 data-v-89ab6a34><h2 class="title" data-v-6b5f8e70>How to cite and reference</h2><div id="shareAndCite" class="content" data-v-6b5f8e70><div class="copy-item" data-v-eb50cbb4 data-v-6b5f8e70><h3 class="title" data-v-eb50cbb4>Link to this chapter <a data-v-eb50cbb4>Copy to clipboard</a></h3><div class="content" data-v-eb50cbb4></div><textarea class="textarea" data-v-eb50cbb4></textarea><!----></div><div class="copy-item" data-v-eb50cbb4 data-v-6b5f8e70><h3 class="title" data-v-eb50cbb4>Cite this chapter <a data-v-eb50cbb4>Copy to clipboard</a></h3><div class="content" data-v-eb50cbb4>Leila Kerkeni, Youssef Serrestou, Mohamed Mbarki, Kosai Raoof, Mohamed Ali Mahjoub and Catherine Cleder (March 25th 2019). Automatic Speech Emotion Recognition Using Machine Learning, Social Media and Machine Learning, Alberto Cano, IntechOpen, DOI: 10.5772/intechopen.84856. Available from:</div><textarea class="textarea" data-v-eb50cbb4>Leila Kerkeni, Youssef Serrestou, Mohamed Mbarki, Kosai Raoof, Mohamed Ali Mahjoub and Catherine Cleder (March 25th 2019). Automatic Speech Emotion Recognition Using Machine Learning, Social Media and Machine Learning, Alberto Cano, IntechOpen, DOI: 10.5772/intechopen.84856. Available from: </textarea><!----></div></div><div class="sidebar cf" data-v-6b5f8e70><div class="info-box" data-v-6b5f8e70><h3 class="info-title" data-v-6b5f8e70>Over 21,000 IntechOpen readers like this topic</h3><p class="info-content" data-v-6b5f8e70>Help us write another book on this subject and reach those readers</p><a href="/publishing-proposal" class="cta button-type-3" data-v-6b5f8e70>Suggest a book topic</a><a href="/open-for-submissions" class="cta button-type-3" data-v-6b5f8e70>Books open for submissions</a></div></div></div><div id="statistics" class="book-statistics" data-v-b81d60e0 data-v-89ab6a34><h3 class="title capitalize" data-v-b81d60e0>chapter statistics</h3><div class="statistics cf" data-v-b81d60e0><p class="stat-item" data-v-b81d60e0><span class="data" data-v-b81d60e0>3123</span><span class="text" data-v-b81d60e0>total chapter downloads</span></p><p class="stat-item" data-v-b81d60e0><span class="data" data-v-b81d60e0>13</span><span class="text" data-v-b81d60e0>Crossref citations</span></p><p class="stat-item" data-v-b81d60e0><span data-doi="10.5772/intechopen.84856" data-hide-zero-citations="true" data-legend="hover-top" class="__dimensions_badge_embed__" data-v-b81d60e0></span></p><p class="stat-item" data-v-b81d60e0><span data-badge-popover="top" data-badge-type="medium-donut" data-doi="10.5772/intechopen.84856" data-hide-no-mentions="true" class="altmetric-embed" data-v-b81d60e0></span></p></div><div class="box-type-1" data-v-c45c1492 data-v-b81d60e0><h3 class="title" data-v-c45c1492>More statistics for editors and authors</h3><p class="description" data-v-c45c1492>Login to your personal dashboard for more detailed statistics on your publications.</p><a href="https://mts.intechopen.com/myprofile/index/dashboard" target="_blank" class="cta button-type-2" data-v-c45c1492>Access personal reporting</a></div></div></div><div class="container" data-v-6fbc1770 data-v-89ab6a34><div class="wrap cf" data-v-6fbc1770><h3 class="title" data-v-6fbc1770>Related Content</h3><section class="block first" data-v-6fbc1770><h4 class="block-title" data-v-6fbc1770>This Book</h4><section class="cf" data-v-507a9a30 data-v-6fbc1770><div class="column first" data-v-507a9a30><div class="cover" data-v-507a9a30><figure class="cover-wrap middle" data-v-82939336 data-v-507a9a30><a href="/books/8141" data-v-82939336><span class="lazy-image ar1" data-v-d261b71c data-v-82939336><!----></span><svg viewBox="0 0 300 270" preserveAspectRatio="xMidYMid meet" class="svg" data-v-82939336><rect width="300" height="270" style="fill:#e10000" data-v-82939336></rect><text x="150" y="35" font-family="Arial" text-anchor="middle" fill="#fffad2" font-size="12" data-v-82939336>IntechOpen</text><g transform="translate(140, 220)" fill="#FFFAD2" data-v-82939336><g transform="scale(0.7)" data-v-82939336><path d="M18.4091275,7.09361268 L3.66754648,15.3478697 C2.61853239,15.939493 1.9668669,17.0549331 1.9668669,18.2588838 L1.9668669,33.0542958 L0.869542958,32.6455599 C0.346761268,32.4507676 -3.45070423e-05,31.9516232 -3.45070423e-05,31.3936444 L-3.45070423e-05,1.37079225 C-3.45070423e-05,0.417880282 0.94908169,-0.243792254 1.84298662,0.08575 L18.3356275,6.16347535 C18.7472965,6.3151338 18.791638,6.87932394 18.4091275,7.09361268 M38.2955359,22.6833768 C38.178212,23.1238592 37.8226169,23.4794542 37.382307,23.5967782 C36.3688352,23.8671408 35.4695817,22.9675423 35.7401169,21.9540704 C35.8576134,21.5139331 36.2132085,21.158338 36.6536908,21.0411866 C37.6666451,20.7715141 38.565381,21.6704225 38.2955359,22.6833768 M48.0927754,30.247493 C47.5629197,30.0078415 46.9350641,30.1798592 46.5494479,30.614993 L46.5221873,30.6455317 C45.2633704,32.0789542 43.7110711,33.1881831 41.9971063,33.9233556 C41.9917577,33.9255986 41.9971063,22.341757 41.9971063,22.341757 C41.9971063,13.8637218 35.1127789,6.99078169 26.6345711,6.99078169 C24.2718739,6.99078169 21.8610394,7.48388732 19.7830254,8.63297183 C17.9817577,9.62901761 7.46211338,15.5312746 4.66255704,17.1022077 C4.23846549,17.3401338 3.97845493,17.7871725 3.97845493,18.2733768 L3.97845493,47.5848662 C3.97845493,48.5941972 5.06456408,49.230507 5.9451838,48.7372289 L19.0174866,41.4119014 C19.4345042,41.1781162 19.6927894,40.7374613 19.6927894,40.2593662 L19.6927894,17.7378275 C19.6927894,17.2512782 20.0211239,16.8006162 20.5000817,16.7141761 C21.1293176,16.6008204 21.6765993,17.0811585 21.6765993,17.6893451 L21.6765993,22.2984507 L21.6821204,22.287581 C21.6821204,22.2912042 21.6817754,22.2948275 21.6817754,22.2984507 C21.6817754,30.752331 28.5590289,37.6295845 37.0127366,37.6295845 C37.7863845,37.6295845 38.5527859,37.5676444 39.3076275,37.4532535 L39.3076275,47.5686479 C39.3076275,48.3079613 39.9071873,48.9076937 40.6466732,48.9076937 C41.3859866,48.9076937 41.9853739,48.3079613 41.9853739,47.5686479 L41.9853739,36.796757 C44.484719,35.9396021 46.7488986,34.4454472 48.5267014,32.4212641 L48.5669021,32.3755423 C49.1533493,31.7199085 48.9746028,30.6460493 48.0927754,30.247493" data-v-82939336></path></g></g></svg><div class="text" style="font-size:150em" data-v-82939336><span class="title" data-v-82939336>Social Media and Machine Learning</span><!----><span class="editors" data-v-82939336>Edited by Alberto Cano</span></div></a></figure></div><h4 class="book-title" data-v-507a9a30>Social Media and Machine Learning</h4><p class="book-text" data-v-507a9a30>Edited by <a href="/profiles/200724" class="edited-by" data-v-507a9a30>Alberto Cano</a></p></div><div class="column" data-v-507a9a30><a href="/chapters/67538" class="chapter-cta" data-v-507a9a30>Next chapter</a><h4 class="chapter-title" data-v-507a9a30>A Case Study of Using Big Data Processing in Education: Method of Matching Members by Optimizing Collaborative Learning Environment</h4><p class="chapter-text" data-v-507a9a30>By Keiko Tsujioka</p></div><!----></section></section><section class="block second" data-v-6fbc1770><h4 class="block-title" data-v-6fbc1770>Related Book</h4><section class="cf" data-v-507a9a30 data-v-6fbc1770><div class="column first" data-v-507a9a30><div class="cover" data-v-507a9a30><figure class="cover-wrap middle" data-v-82939336 data-v-507a9a30><a href="/books/1358" data-v-82939336><span class="lazy-image ar1" data-v-d261b71c data-v-82939336><!----></span><svg viewBox="0 0 300 270" preserveAspectRatio="xMidYMid meet" class="svg" data-v-82939336><rect width="300" height="270" style="fill:#e10000" data-v-82939336></rect><text x="150" y="35" font-family="Arial" text-anchor="middle" fill="#fffad2" font-size="12" data-v-82939336>IntechOpen</text><g transform="translate(140, 220)" fill="#FFFAD2" data-v-82939336><g transform="scale(0.7)" data-v-82939336><path d="M18.4091275,7.09361268 L3.66754648,15.3478697 C2.61853239,15.939493 1.9668669,17.0549331 1.9668669,18.2588838 L1.9668669,33.0542958 L0.869542958,32.6455599 C0.346761268,32.4507676 -3.45070423e-05,31.9516232 -3.45070423e-05,31.3936444 L-3.45070423e-05,1.37079225 C-3.45070423e-05,0.417880282 0.94908169,-0.243792254 1.84298662,0.08575 L18.3356275,6.16347535 C18.7472965,6.3151338 18.791638,6.87932394 18.4091275,7.09361268 M38.2955359,22.6833768 C38.178212,23.1238592 37.8226169,23.4794542 37.382307,23.5967782 C36.3688352,23.8671408 35.4695817,22.9675423 35.7401169,21.9540704 C35.8576134,21.5139331 36.2132085,21.158338 36.6536908,21.0411866 C37.6666451,20.7715141 38.565381,21.6704225 38.2955359,22.6833768 M48.0927754,30.247493 C47.5629197,30.0078415 46.9350641,30.1798592 46.5494479,30.614993 L46.5221873,30.6455317 C45.2633704,32.0789542 43.7110711,33.1881831 41.9971063,33.9233556 C41.9917577,33.9255986 41.9971063,22.341757 41.9971063,22.341757 C41.9971063,13.8637218 35.1127789,6.99078169 26.6345711,6.99078169 C24.2718739,6.99078169 21.8610394,7.48388732 19.7830254,8.63297183 C17.9817577,9.62901761 7.46211338,15.5312746 4.66255704,17.1022077 C4.23846549,17.3401338 3.97845493,17.7871725 3.97845493,18.2733768 L3.97845493,47.5848662 C3.97845493,48.5941972 5.06456408,49.230507 5.9451838,48.7372289 L19.0174866,41.4119014 C19.4345042,41.1781162 19.6927894,40.7374613 19.6927894,40.2593662 L19.6927894,17.7378275 C19.6927894,17.2512782 20.0211239,16.8006162 20.5000817,16.7141761 C21.1293176,16.6008204 21.6765993,17.0811585 21.6765993,17.6893451 L21.6765993,22.2984507 L21.6821204,22.287581 C21.6821204,22.2912042 21.6817754,22.2948275 21.6817754,22.2984507 C21.6817754,30.752331 28.5590289,37.6295845 37.0127366,37.6295845 C37.7863845,37.6295845 38.5527859,37.5676444 39.3076275,37.4532535 L39.3076275,47.5686479 C39.3076275,48.3079613 39.9071873,48.9076937 40.6466732,48.9076937 C41.3859866,48.9076937 41.9853739,48.3079613 41.9853739,47.5686479 L41.9853739,36.796757 C44.484719,35.9396021 46.7488986,34.4454472 48.5267014,32.4212641 L48.5669021,32.3755423 C49.1533493,31.7199085 48.9746028,30.6460493 48.0927754,30.247493" data-v-82939336></path></g></g></svg><div class="text" style="font-size:150em" data-v-82939336><span class="title" data-v-82939336>Knowledge-Oriented Applications in Data Mining</span><!----><span class="editors" data-v-82939336>Edited by Kimito Funatsu</span></div></a></figure></div><h4 class="book-title" data-v-507a9a30>Knowledge-Oriented Applications in Data Mining</h4><p class="book-text" data-v-507a9a30>Edited by <a href="/profiles/16715" class="edited-by" data-v-507a9a30>Kimito Funatsu</a></p></div><div class="column" data-v-507a9a30><a href="/chapters/13157" class="chapter-cta" data-v-507a9a30>First chapter</a><h4 class="chapter-title" data-v-507a9a30>Data Mining Classification Techniques for Human Talent Forecasting</h4><p class="chapter-text" data-v-507a9a30>By Hamidah Jantan, Abdul Razak Hamdan and Zulaiha Ali Othman</p></div><!----></section></section></div></div><div class="about" data-v-66072837 data-v-89ab6a34><p class="description" data-v-66072837>We are IntechOpen, the world's leading publisher of Open Access books. Built by scientists, for scientists. Our readership spans scientists, professors, researchers, librarians, and students, as well as business professionals. We share our knowledge and peer-reveiwed research papers with libraries, scientific and engineering societies, and also work with corporate R&amp;D departments and government entities.</p><!----><a href="/about-intechopen" class="cta button-type-2" data-v-66072837>More About Us</a></div><!----><!----><!----></section><footer data-v-75b1e4b2 data-v-87be0136><div class="book-subject-area" data-v-687e2a4b data-v-75b1e4b2><div class="inner cf" data-v-687e2a4b><h2 class="title" data-v-687e2a4b>Book Subject Areas</h2><div class="box" data-v-687e2a4b><a href="/subjects/1" class="sub-title" data-v-687e2a4b>Physical Sciences, Engineering and Technology</a><a href="/subjects/8" class="link" data-v-687e2a4b>Chemistry</a><a href="/subjects/9" class="link" data-v-687e2a4b>Computer and Information Science</a><a href="/subjects/10" class="link" data-v-687e2a4b>Earth and Planetary Sciences</a><a href="/subjects/11" class="link" data-v-687e2a4b>Engineering</a><a href="/subjects/14" class="link" data-v-687e2a4b>Materials Science</a><a href="/subjects/15" class="link" data-v-687e2a4b>Mathematics</a><a href="/subjects/17" class="link" data-v-687e2a4b>Nanotechnology and Nanomaterials</a><a href="/subjects/20" class="link" data-v-687e2a4b>Physics</a><a href="/subjects/22" class="link" data-v-687e2a4b>Robotics</a><a href="/subjects/24" class="link" data-v-687e2a4b>Technology</a><a class="link-more iconArrowRight" data-v-687e2a4b>More</a></div><div class="box" data-v-687e2a4b><a href="/subjects/2" class="sub-title" data-v-687e2a4b>Life Sciences</a><a href="/subjects/5" class="link" data-v-687e2a4b>Agricultural and Biological Sciences</a><a href="/subjects/6" class="link" data-v-687e2a4b>Biochemistry, Genetics and Molecular Biology</a><a href="/subjects/12" class="link" data-v-687e2a4b>Environmental Sciences</a><a href="/subjects/13" class="link" data-v-687e2a4b>Immunology and Microbiology</a><a href="/subjects/18" class="link" data-v-687e2a4b>Neuroscience</a><a class="link-more iconArrowRight" data-v-687e2a4b>More</a></div><div class="box" data-v-687e2a4b><a href="/subjects/3" class="sub-title" data-v-687e2a4b>Health Sciences</a><a href="/subjects/16" class="link" data-v-687e2a4b>Medicine</a><a href="/subjects/19" class="link" data-v-687e2a4b>Pharmacology, Toxicology and Pharmaceutical Science</a><a href="/subjects/25" class="link" data-v-687e2a4b>Veterinary Medicine and Science</a><!----></div><div class="box" data-v-687e2a4b><a href="/subjects/4" class="sub-title" data-v-687e2a4b>Social Sciences and Humanities</a><a href="/subjects/7" class="link" data-v-687e2a4b>Business, Management and Economics</a><a href="/subjects/21" class="link" data-v-687e2a4b>Psychology</a><a href="/subjects/23" class="link" data-v-687e2a4b>Social Sciences</a><!----></div><a href="/books" class="view-all iconArrowRight" data-v-687e2a4b>View all Books</a></div></div><div class="footer" data-v-75b1e4b2><div class="inner" data-v-75b1e4b2><div class="footer-nav cf" data-v-75b1e4b2><div class="nav-box" data-v-75b1e4b2><a href="/" class="title router-link-active" data-v-75b1e4b2>Home</a><a href="/news" class="title" data-v-75b1e4b2>News</a><a href="/page/contact-us" class="title" data-v-75b1e4b2>Contact</a><a href="/page/careers-at-intechopen" class="title" data-v-75b1e4b2>Careers</a></div><div class="nav-box" data-v-75b1e4b2><!----><a href="/about-intechopen" class="title" data-v-75b1e4b2>About</a><a href="/authors-and-editors" class="link" data-v-75b1e4b2>Our Authors and Editors</a><a href="/page/scientific-advisors" class="link" data-v-75b1e4b2>Scientific Advisors</a><a href="/page/team" class="link" data-v-75b1e4b2>Team</a><a href="/page/events" class="link" data-v-75b1e4b2>Events</a><a href="/advertising" class="link" data-v-75b1e4b2>Advertising</a><a href="/page/partnerships" class="link" data-v-75b1e4b2>Partnerships</a></div><div class="nav-box" data-v-75b1e4b2><a href="/publish" class="title" data-v-75b1e4b2>Publish</a><a href="/page/about-open-access" class="link" data-v-75b1e4b2>About Open Access</a><a href="/how-open-access-publishing-with-intechopen-works" class="link" data-v-75b1e4b2>How it works</a><a href="/page/OA-publishing-fees" class="link" data-v-75b1e4b2>OA Publishing Fees</a><a href="/page/open-access-funding" class="link" data-v-75b1e4b2>Open Access funding</a><a href="/peer-reviewing" class="link" data-v-75b1e4b2>Peer Reviewing</a><a href="/page/editorial-policies" class="link" data-v-75b1e4b2>Editorial Policies</a></div><div class="nav-box" data-v-75b1e4b2><div class="social-wrap" data-v-75b1e4b2><a href="https://twitter.com/intechopen" target="_blank" class="icr" data-v-75b1e4b2><img src="//cdnintech.com/web/frontend/www/assets/svg/twitter.svg" alt="Twitter" data-v-75b1e4b2></a><a href="https://www.facebook.com/IntechOpen" target="_blank" class="icr" data-v-75b1e4b2><img src="//cdnintech.com/web/frontend/www/assets/svg/facebook.svg" alt="Facebook" data-v-75b1e4b2></a><a href="https://www.linkedin.com/company/intechopen" target="_blank" class="icr" data-v-75b1e4b2><img src="//cdnintech.com/web/frontend/www/assets/svg/linkedin.svg" alt="LinkedIn" data-v-75b1e4b2></a><a href="https://www.instagram.com/intechopen/" target="_blank" class="icr" data-v-75b1e4b2><img src="//cdnintech.com/web/frontend/www/assets/svg/instagram.svg" alt="Instagram" data-v-75b1e4b2></a></div><div class="company-info-wrap cf" data-v-75b1e4b2><p class="address" data-v-75b1e4b2>Headquarters<br data-v-75b1e4b2>IntechOpen Limited<br data-v-75b1e4b2>5 Princes Gate Court,<br data-v-75b1e4b2>London, SW7 2QJ,<br data-v-75b1e4b2>UNITED KINGDOM</p><div class="meta-wrap" data-v-75b1e4b2><p class="meta" data-v-75b1e4b2>Phone: +44 20 8089 5702</p></div></div></div></div><div class="search-wrap cf" data-v-75b1e4b2><form class="search-term" data-v-36b4823c data-v-75b1e4b2><input placeholder="Search" required="required" value="" data-v-36b4823c><button type="submit" class="icr iconSearch" data-v-36b4823c>Submit</button></form><a href="//mts.intechopen.com/account/login" target="_blank" class="cta button-type-1" data-v-75b1e4b2>Author Panel Sign in</a></div><div class="legal-wrap" data-v-75b1e4b2><ul class="legal-nav" data-v-75b1e4b2><li data-v-75b1e4b2><a href="/page/terms-and-conditions" data-v-75b1e4b2>Terms and Conditions</a></li><li data-v-75b1e4b2><a href="/privacy-policy" data-v-75b1e4b2>Privacy Policy</a></li><li data-v-75b1e4b2><a href="/page/customer-complaints" data-v-75b1e4b2>Customer Complaints</a></li></ul><p class="copyright" data-v-75b1e4b2>© 2021 IntechOpen. All rights reserved.</p></div></div></div></footer></div><!----></div><script>window.__INITIAL_STATE__={errorStatus:null,topics:null,windowContext:"large",lastViewed:[],ofsBooksList:[],statistics:null,globalStatistics:null,featuredNews:null,testimonials:null,loader:!1,home:{featuredBooks:[{type:"book",id:"10363",title:"Abiotic Stress in Plants",subtitle:null,isOpenForSubmission:!1,hash:"e4d0b0a5b0d55843e704d38d55206b91",slug:"abiotic-stress-in-plants",bookSignature:"Shah Fahad, Shah Saud, Yajun Chen, Chao Wu and Depeng Wang",coverURL:"https://cdn.intechopen.com/books/images_new/10363.jpg",editors:[{id:"194771",title:"Dr.",name:"Shah",middleName:null,surname:"Fahad",slug:"shah-fahad",fullName:"Shah Fahad"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10321",title:"Advances in Precision Medicine Oncology",subtitle:null,isOpenForSubmission:!1,hash:"043ad1c1a6bbdcd5604917ccbff003d8",slug:"advances-in-precision-medicine-oncology",bookSignature:"Hilal Arnouk and Bassam Abdul Rasool Hassan",coverURL:"https://cdn.intechopen.com/books/images_new/10321.jpg",editors:[{id:"76431",title:"Dr.",name:"Hilal",middleName:null,surname:"Arnouk",slug:"hilal-arnouk",fullName:"Hilal Arnouk"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9927",title:"Real Perspective of Fourier Transforms and Current Developments in Superconductivity",subtitle:null,isOpenForSubmission:!1,hash:"89f437eae592f8f3730b6c9ec8426e43",slug:"real-perspective-of-fourier-transforms-and-current-developments-in-superconductivity",bookSignature:"Juan Manuel Velazquez Arcos",coverURL:"https://cdn.intechopen.com/books/images_new/9927.jpg",editors:[{id:"114776",title:"Dr.",name:"Juan Manuel",middleName:null,surname:"Velazquez Arcos",slug:"juan-manuel-velazquez-arcos",fullName:"Juan Manuel Velazquez Arcos"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"8950",title:"Birds",subtitle:"Challenges and Opportunities for Business, Conservation and Research",isOpenForSubmission:!1,hash:"404a05af45e47e43871f4a0b1bedc6fd",slug:"birds-challenges-and-opportunities-for-business-conservation-and-research",bookSignature:"Heimo Mikkola",coverURL:"https://cdn.intechopen.com/books/images_new/8950.jpg",editors:[{id:"144330",title:"Dr.",name:"Heimo",middleName:"Juhani",surname:"Mikkola",slug:"heimo-mikkola",fullName:"Heimo Mikkola"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9496",title:"Management of Dyslipidemia",subtitle:null,isOpenForSubmission:!1,hash:"1d1174ff4ed8ad553c944e99add28154",slug:"management-of-dyslipidemia",bookSignature:"Wilbert S. Aronow",coverURL:"https://cdn.intechopen.com/books/images_new/9496.jpg",editors:[{id:"164597",title:"Dr.",name:"Wilbert S.",middleName:null,surname:"Aronow",slug:"wilbert-s.-aronow",fullName:"Wilbert S. Aronow"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10214",title:"Saccharomyces",subtitle:null,isOpenForSubmission:!1,hash:"e313134fdc982e3fdc0cc0bd1b48ef59",slug:"saccharomyces",bookSignature:"Thalita Peixoto Basso and Luiz Carlos Basso",coverURL:"https://cdn.intechopen.com/books/images_new/10214.jpg",editors:[{id:"139174",title:"Ph.D.",name:"Thalita",middleName:null,surname:"Peixoto Basso",slug:"thalita-peixoto-basso",fullName:"Thalita Peixoto Basso"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10071",title:"Nanowires",subtitle:"Recent Progress",isOpenForSubmission:!1,hash:"3baef9684ce58f9f65a1f1788509220d",slug:"nanowires-recent-progress",bookSignature:"Xihong Peng",coverURL:"https://cdn.intechopen.com/books/images_new/10071.jpg",editors:[{id:"24647",title:"Prof.",name:"Xihong",middleName:null,surname:"Peng",slug:"xihong-peng",fullName:"Xihong Peng"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9788",title:"Colorectal Cancer",subtitle:null,isOpenForSubmission:!1,hash:"6faf06dfe50a3febba931e41b794f4e5",slug:"colorectal-cancer",bookSignature:"Alberto Vannelli",coverURL:"https://cdn.intechopen.com/books/images_new/9788.jpg",editors:[{id:"34524",title:"Dr.",name:"Alberto",middleName:null,surname:"Vannelli",slug:"alberto-vannelli",fullName:"Alberto Vannelli"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10237",title:"Innovation in the Food Sector Through the Valorization of Food and Agro-Food By-Products",subtitle:null,isOpenForSubmission:!1,hash:"c3a5a3c7f7999d68f04ae49ff0553f3d",slug:"innovation-in-the-food-sector-through-the-valorization-of-food-and-agro-food-by-products",bookSignature:"Ana Novo de Barros and Irene Gouvinhas",coverURL:"https://cdn.intechopen.com/books/images_new/10237.jpg",editors:[{id:"260510",title:"Prof.",name:"Ana",middleName:null,surname:"Novo de Barros",slug:"ana-novo-de-barros",fullName:"Ana Novo de Barros"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10481",title:"Practical Applications of Laser Ablation",subtitle:null,isOpenForSubmission:!1,hash:"e9f235e98a88813c08a9dba80525b195",slug:"practical-applications-of-laser-ablation",bookSignature:"Dongfang Yang",coverURL:"https://cdn.intechopen.com/books/images_new/10481.jpg",editors:[{id:"177814",title:"Dr.",name:"Dongfang",middleName:null,surname:"Yang",slug:"dongfang-yang",fullName:"Dongfang Yang"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}}],featuredProfiles:[{id:"164277",title:"Dr.",name:"Sebastien",middleName:null,surname:"Boisseau",slug:"sebastien-boisseau",fullName:"Sebastien Boisseau",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:{name:"CEA LETI",country:{name:"France"}}},{id:"33351",title:null,name:"Hendra",middleName:null,surname:"Hermawan",slug:"hendra-hermawan",fullName:"Hendra Hermawan",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/33351/images/168_n.jpg",biography:null,institutionString:null,institution:{name:"Institut Teknologi Bandung",country:{name:"Indonesia"}}},{id:"41989",title:"Prof.",name:"He",middleName:null,surname:"Tian",slug:"he-tian",fullName:"He Tian",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:{name:"East China University of Science and Technology",country:{name:"China"}}}]},newsLanding:{offset:4,limit:4,total:183,newsList:[{slug:"intechopen-partners-with-ehs-for-digital-advertising-representation-20210514",title:"IntechOpen Partners with EHS for Digital Advertising Representation",intro:"<p>IntechOpen is proud to announce a new partnership with eHealthcare Solutions (EHS), where EHS will represent our Health Science and Life Science portfolio. By offering EHS a better way to target and communicate with our audience, we aim to provide our readers with a better experience overall.&nbsp;</p>",publishedDatetime:"14th May 2021",endDate:null,newsType:"1",mainMedia:null},{slug:"intechopen-is-the-open-access-publisher-with-the-most-titles-available-in-doab-20210427",title:"IntechOpen is the Open Access Publisher with the Most Titles Available in DOAB",intro:"<p>IntechOpen is excited to announce that now our complete catalog of over 5,200 books has successfully been added to the Directory of Open Access Books (DOAB) - making IntechOpen the Open Access publisher with the most titles indexed in DOAB.</p>",publishedDatetime:"27th April 2021",endDate:null,newsType:"1",mainMedia:null},{slug:"intechopen-signs-new-contract-with-cepiec-china-for-distribution-of-open-access-books-20210319",title:"IntechOpen Signs New Contract with CEPIEC, China for Distribution of Open Access Books",intro:"<p>IntechOpen has signed a new contract with China Educational Publications Import &amp; Export Co. Ltd. (CEPIEC) regarding the distribution of Open Access books through their iResearch platform.&nbsp;</p>",publishedDatetime:"19th March 2021",endDate:null,newsType:"1",mainMedia:null},{slug:"150-million-downloads-and-counting-20210316",title:"150 Million Downloads and Counting",intro:"<p>Barely three months into the new year and we are happy to announce a monumental milestone reached - 150 million downloads.&nbsp;</p>",publishedDatetime:"16th March 2021",endDate:null,newsType:"1",mainMedia:null}]},news:{item:{slug:"intechopen-becomes-a-member-of-the-stm-association-20180502",title:"IntechOpen Becomes a Member of the STM Association",subtitle:"Contributing to Evolving Industry as It Expeditiously Spreads Open Science",metaTitle:"IntechOpen Becomes a Member of the STM Association",metaDescription:"IntechOpen, the first native scientific publisher of Open Access books, announced today it joined the International Association of Scientific, Technical and Medical Publishers (STM), the leading global trade association for academic and professional publishers.&nbsp;",metaKeywords:null,publishedDatetime:"2nd May 2018",endDate:null,newsType:"1",contentRaw:'[{"type":"htmlEditorComponent","content":"<p>IntechOpen, the first native scientific publisher of Open Access books, announced today it joined the International Association of Scientific, Technical and Medical Publishers (STM), the leading global trade association for academic and professional publishers.&nbsp;</p>\\n\\n<p><em>&ldquo;As Open Access publishing changes, it is important for us to engage in conversations with peers in this trade association that convenes and educates about trends in the industry, and this enables us to participate in defining answers to the scientific community&rsquo;s publishing needs in Open Access books&rdquo;, said Alex Lazinica, IntechOpen&rsquo;s co-founder and CEO. &ldquo;IntechOpen as a company is only as good as our editors and authors who follow STM&rsquo;s Ethical Principles for Scholarly Publishing. I am also confident that with Dr. Anke Beck, our incoming CEO, IntechOpen will become a significant contributor to defining the future of STM&rsquo;s publishing.&rdquo;</em></p>\\n\\n<p>STM is the leading global trade association for academic and professional publishers. It has 145 members in 21 countries who each year collectively publish nearly 66% of all journal articles and tens of thousands of monographs and reference works. STM members include learned societies, university presses, both subscription and open access publishers, new starts and established players.</p>\\n\\n<p><em>&ldquo;As a trade association we value innovative approaches to spreading scientific discovery, and I am delighted to welcome IntechOpen, a leading scholarly Open Access book publisher as our member,&rdquo; said Darrell W. Gunter, Director, STM North America and Director of Membership.</em></p>\\n\\n<p>IntechOpen is the market leader in scientific publishing of Open Access books with more than 3 350 published OA books to date and 1.7 million downloads of scientific chapters and books in the last year. More than 107 500 researchers, including Nobel Prize laureates, have published their research on the platform.</p>\\n\\n<p><strong>About IntechOpen</strong></p>\\n\\n<p>Founded in 2004, IntechOpen, the first native scientific publisher of Open Access books, provides a collaborative environment for peer-reviewed scholarly content and book publishing of academic research, giving scientific thinking its home. The scientific community of editors, authors, funders and librarians worldwide benefit from open access research dissemination, ensuring faster spreading and advancement of scientific knowledge. The company&rsquo;s global headquarter is in London, UK. <a href=\\"http://www.intechopen.com\\">www.intechopen.com</a></p>\\n"}]',published:!0,mainMedia:null},components:[{type:"htmlEditorComponent",content:'<p>IntechOpen, the first native scientific publisher of Open Access books, announced today it joined the International Association of Scientific, Technical and Medical Publishers (STM), the leading global trade association for academic and professional publishers.&nbsp;</p>\n\n<p><em>&ldquo;As Open Access publishing changes, it is important for us to engage in conversations with peers in this trade association that convenes and educates about trends in the industry, and this enables us to participate in defining answers to the scientific community&rsquo;s publishing needs in Open Access books&rdquo;, said Alex Lazinica, IntechOpen&rsquo;s co-founder and CEO. &ldquo;IntechOpen as a company is only as good as our editors and authors who follow STM&rsquo;s Ethical Principles for Scholarly Publishing. I am also confident that with Dr. Anke Beck, our incoming CEO, IntechOpen will become a significant contributor to defining the future of STM&rsquo;s publishing.&rdquo;</em></p>\n\n<p>STM is the leading global trade association for academic and professional publishers. It has 145 members in 21 countries who each year collectively publish nearly 66% of all journal articles and tens of thousands of monographs and reference works. STM members include learned societies, university presses, both subscription and open access publishers, new starts and established players.</p>\n\n<p><em>&ldquo;As a trade association we value innovative approaches to spreading scientific discovery, and I am delighted to welcome IntechOpen, a leading scholarly Open Access book publisher as our member,&rdquo; said Darrell W. Gunter, Director, STM North America and Director of Membership.</em></p>\n\n<p>IntechOpen is the market leader in scientific publishing of Open Access books with more than 3 350 published OA books to date and 1.7 million downloads of scientific chapters and books in the last year. More than 107 500 researchers, including Nobel Prize laureates, have published their research on the platform.</p>\n\n<p><strong>About IntechOpen</strong></p>\n\n<p>Founded in 2004, IntechOpen, the first native scientific publisher of Open Access books, provides a collaborative environment for peer-reviewed scholarly content and book publishing of academic research, giving scientific thinking its home. The scientific community of editors, authors, funders and librarians worldwide benefit from open access research dissemination, ensuring faster spreading and advancement of scientific knowledge. The company&rsquo;s global headquarter is in London, UK. <a href="http://www.intechopen.com">www.intechopen.com</a></p>\n'}],latestNews:[{slug:"intechopen-partners-with-ehs-for-digital-advertising-representation-20210514",title:"IntechOpen Partners with EHS for Digital Advertising Representation"},{slug:"intechopen-is-the-open-access-publisher-with-the-most-titles-available-in-doab-20210427",title:"IntechOpen is the Open Access Publisher with the Most Titles Available in DOAB"},{slug:"intechopen-signs-new-contract-with-cepiec-china-for-distribution-of-open-access-books-20210319",title:"IntechOpen Signs New Contract with CEPIEC, China for Distribution of Open Access Books"},{slug:"150-million-downloads-and-counting-20210316",title:"150 Million Downloads and Counting"},{slug:"intechopen-secures-indefinite-content-preservation-with-clockss-20210309",title:"IntechOpen Secures Indefinite Content Preservation with CLOCKSS"},{slug:"intechopen-expands-to-all-global-amazon-channels-with-full-catalog-of-books-20210308",title:"IntechOpen Expands to All Global Amazon Channels with Full Catalog of Books"},{slug:"stanford-university-identifies-top-2-scientists-over-1-000-are-intechopen-authors-and-editors-20210122",title:"Stanford University Identifies Top 2% Scientists, Over 1,000 are IntechOpen Authors and Editors"},{slug:"intechopen-authors-included-in-the-highly-cited-researchers-list-for-2020-20210121",title:"IntechOpen Authors Included in the Highly Cited Researchers List for 2020"}]},book:{item:{type:"book",id:"1511",leadTitle:null,fullTitle:"Deforestation Around the World",title:"Deforestation Around the World",subtitle:null,reviewType:"peer-reviewed",abstract:"Deforestation and forest degradation represent a significant fraction of the annual worldwide human-induced emission of greenhouse gases to the atmosphere, the main source of biodiversity losses and the destruction of millions of people's homes.  Despite local/regional causes, its consequences are global. This book provides a general view about deforestation dynamics around the  world, incorporating analyses of its causes, impacts and actions to prevent it. Its 17 Chapters, organized in three sections, refer to deforestation impacts on climate, soil, biodiversity and human population, but also describe several initiatives to prevent it. A special emphasis is given to different remote-sensing and mapping techniques that could be used as a source for decision-makers and society to promote forest conservation and control deforestation.",isbn:null,printIsbn:"978-953-51-0417-9",pdfIsbn:"978-953-51-5264-4",doi:"10.5772/1979",price:139,priceEur:155,priceUsd:179,slug:"deforestation-around-the-world",numberOfPages:388,isOpenForSubmission:!1,isInWos:1,hash:"9eeb50fd58ff5ebb4151b5368105e9ef",bookSignature:"Paulo Moutinho",publishedDate:"March 30th 2012",coverURL:"https://cdn.intechopen.com/books/images_new/1511.jpg",numberOfDownloads:46219,numberOfWosCitations:34,numberOfCrossrefCitations:10,numberOfDimensionsCitations:37,hasAltmetrics:1,numberOfTotalCitations:81,isAvailableForWebshopOrdering:!0,dateEndFirstStepPublish:"April 19th 2011",dateEndSecondStepPublish:"May 17th 2011",dateEndThirdStepPublish:"September 21st 2011",dateEndFourthStepPublish:"October 21st 2011",dateEndFifthStepPublish:"February 20th 2012",currentStepOfPublishingProcess:5,indexedIn:"1,2,3,4,5,6",editedByType:"Edited by",kuFlag:!1,editors:[{id:"115144",title:"Dr.",name:"Paulo",middleName:null,surname:"Moutinho",slug:"paulo-moutinho",fullName:"Paulo Moutinho",profilePictureURL:"https://mts.intechopen.com/storage/users/115144/images/system/115144.jpg",biography:"Current Executive Director for the Amazon Environmental Research Institute (IPAM), Dr. Paulo Moutinho has worked with the Amazon region over the past twenty years. His studies are related to deforestation patterns and their effects on biodiversity, climate and local communities. He carried out pioneering research on the processes of forest recovery on degraded areas and on the impacts of rainfall reduction on ecological function of Amazon forests. He is one of the authors of the proposal for compensating reduced deforestation, which supports international financial incentives for developing countries making efforts to reduce deforestation rates. Such proposal provided the basis for the REDD mechanism (Reducing Emissions from Deforestation and Forest Degradation) under discussion in the UNFCCC. He has also worked actively for the adoption of a National Policy on Climate Change, which sets up unprecedented targets for greenhouse gas emission reduction for Brazil.",institutionString:null,position:"Director",outsideEditionCount:0,totalCites:0,totalAuthoredChapters:"0",totalChapterViews:"0",totalEditedBooks:"1",institution:null}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,coeditorOne:null,coeditorTwo:null,coeditorThree:null,coeditorFour:null,coeditorFive:null,topics:[{id:"331",title:"Forestry Science",slug:"agricultural-and-biological-sciences-ecology-forestry-science"}],chapters:[{id:"34532",title:"The Climatic Effects of Deforestation in South and Southeast Asia",doi:"10.5772/34101",slug:"the-climatic-effects-of-deforestation-in-south-and-southeast-asia",totalDownloads:2651,totalCrossrefCites:3,totalDimensionsCites:5,signatures:"Rachindra Mawalagedara and Robert J. Oglesby",downloadPdfUrl:"/chapter/pdf-download/34532",previewPdfUrl:"/chapter/pdf-preview/34532",authors:[{id:"98711",title:"Prof.",name:"Robert",surname:"Oglesby",slug:"robert-oglesby",fullName:"Robert Oglesby"},{id:"105712",title:"MSc.",name:"Rachindra",surname:"Mawalagedara",slug:"rachindra-mawalagedara",fullName:"Rachindra Mawalagedara"}],corrections:null},{id:"34533",title:"Impacts of Deforestation on Climate and Water Resources in Western Amazon",doi:"10.5772/35734",slug:"impacts-of-deforestation-on-climate-and-water-resources-in-western-amazon",totalDownloads:2155,totalCrossrefCites:0,totalDimensionsCites:0,signatures:"Ranyére Silva Nóbrega",downloadPdfUrl:"/chapter/pdf-download/34533",previewPdfUrl:"/chapter/pdf-preview/34533",authors:[{id:"105663",title:"Dr.",name:"Ranyére",surname:"Nóbrega",slug:"ranyere-nobrega",fullName:"Ranyére Nóbrega"}],corrections:null},{id:"34534",title:"Deforestation and Water Borne Parasitic Zoonoses",doi:"10.5772/35798",slug:"deforestation-and-waterborne-parasitic-zoonoses",totalDownloads:2264,totalCrossrefCites:0,totalDimensionsCites:0,signatures:"Maria Anete Lallo",downloadPdfUrl:"/chapter/pdf-download/34534",previewPdfUrl:"/chapter/pdf-preview/34534",authors:[{id:"105885",title:"Dr.",name:"Maria",surname:"Lallo",slug:"maria-lallo",fullName:"Maria Lallo"}],corrections:null},{id:"34535",title:"Impact of Deforestation on the Sustainability of Biodiversity in the Mesoamerican Biological Corridor",doi:"10.5772/35173",slug:"impact-of-deforestation-on-the-sustainability-of-biodiversity-in-mesoamerican-biological-corridor",totalDownloads:3262,totalCrossrefCites:0,totalDimensionsCites:0,signatures:"Vani Starry Manoharan, John Mecikalski, Ronald Welch and Aaron Song",downloadPdfUrl:"/chapter/pdf-download/34535",previewPdfUrl:"/chapter/pdf-preview/34535",authors:[{id:"103286",title:"Dr.",name:"Vani Starry",surname:"Manoharan",slug:"vani-starry-manoharan",fullName:"Vani Starry Manoharan"},{id:"128126",title:"Dr.",name:"John",surname:"Mecikalski",slug:"john-mecikalski",fullName:"John Mecikalski"},{id:"131741",title:"Prof.",name:"Ronald",surname:"Welch",slug:"ronald-welch",fullName:"Ronald Welch"},{id:"131742",title:"Dr.",name:"Aaron",surname:"Song",slug:"aaron-song",fullName:"Aaron Song"}],corrections:null},{id:"34536",title:"Dinaric Karst - An Example of Deforestation and Desertification of Limestone Terrain",doi:"10.5772/34275",slug:"dinaric-karst-an-example-of-deforestation-and-desertification-of-limestone-terrain",totalDownloads:2081,totalCrossrefCites:1,totalDimensionsCites:4,signatures:"Andrej Kranjc",downloadPdfUrl:"/chapter/pdf-download/34536",previewPdfUrl:"/chapter/pdf-preview/34536",authors:[{id:"99468",title:"Prof.",name:"Andrej",surname:"Kranjc",slug:"andrej-kranjc",fullName:"Andrej Kranjc"}],corrections:null},{id:"34537",title:"Landslides Caused Deforestation",doi:"10.5772/36993",slug:"landslides-caused-deforestation",totalDownloads:3543,totalCrossrefCites:2,totalDimensionsCites:3,signatures:"Diandong Ren, Lance M. Leslie and Qingyun Duan",downloadPdfUrl:"/chapter/pdf-download/34537",previewPdfUrl:"/chapter/pdf-preview/34537",authors:[{id:"87393",title:"Prof.",name:"Lance",surname:"Leslie",slug:"lance-leslie",fullName:"Lance Leslie"},{id:"110769",title:"Prof.",name:"Diandong",surname:"Ren",slug:"diandong-ren",fullName:"Diandong Ren"},{id:"132708",title:"Prof.",name:"Qingyun",surname:"Duan",slug:"qingyun-duan",fullName:"Qingyun Duan"}],corrections:null},{id:"34538",title:"Deforestation Dynamics: A Review and Evaluation of Theoretical Approaches and Evidence from Greece",doi:"10.5772/35839",slug:"deforestation-dynamics-a-review-and-evaluation-of-theoretical-approaches",totalDownloads:3343,totalCrossrefCites:0,totalDimensionsCites:0,signatures:"Serafeim Polyzos and Dionysios Minetos",downloadPdfUrl:"/chapter/pdf-download/34538",previewPdfUrl:"/chapter/pdf-preview/34538",authors:[{id:"106057",title:"Dr.",name:"Serafeim",surname:"Polyzos",slug:"serafeim-polyzos",fullName:"Serafeim Polyzos"},{id:"106070",title:"Dr.",name:"Dionysios",surname:"Minetos",slug:"dionysios-minetos",fullName:"Dionysios Minetos"}],corrections:null},{id:"34539",title:"Geospatial Analysis of Deforestation and Land Use Dynamics in a Region of Southwestern Nigeria",doi:"10.5772/35117",slug:"geospatial-analysis-of-deforestation-and-land-use-dynamics",totalDownloads:3778,totalCrossrefCites:1,totalDimensionsCites:4,signatures:"Nathaniel O. Adeoye, Albert A. Abegunde and Samson Adeyinka",downloadPdfUrl:"/chapter/pdf-download/34539",previewPdfUrl:"/chapter/pdf-preview/34539",authors:[{id:"103039",title:"Dr.",name:"Nathaniel",surname:"Adeoye",slug:"nathaniel-adeoye",fullName:"Nathaniel Adeoye"}],corrections:null},{id:"34540",title:"Unsupervised Classification of Aerial Images Based on the Otsu's Method",doi:"10.5772/33670",slug:"unsupervised-classification-of-aerial-images-based-on-the-otsu-s-method",totalDownloads:2423,totalCrossrefCites:1,totalDimensionsCites:1,signatures:"Antonia Macedo-Cruz, I. Villegas-Romero, M. Santos-Peñas and G. Pajares-Martinsanz",downloadPdfUrl:"/chapter/pdf-download/34540",previewPdfUrl:"/chapter/pdf-preview/34540",authors:[{id:"13697",title:"Dr.",name:"Gonzalo",surname:"Pajares",slug:"gonzalo-pajares",fullName:"Gonzalo Pajares"},{id:"96619",title:"Dr.",name:"Antonia",surname:"Macedo-Cruz",slug:"antonia-macedo-cruz",fullName:"Antonia Macedo-Cruz"},{id:"106676",title:"Dr.",name:"Isidro",surname:"Villegas",slug:"isidro-villegas",fullName:"Isidro Villegas"},{id:"106677",title:"Dr.",name:"Matilde",surname:"Santos",slug:"matilde-santos",fullName:"Matilde Santos"}],corrections:null},{id:"34541",title:"Deforestation and Waodani Lands in Ecuador: Mapping and Demarcation Amidst Shaky Politics",doi:"10.5772/35851",slug:"deforestation-and-waorani-lands-in-ecuador-mapping-and-demarcation-amidst-shaky-politics",totalDownloads:2524,totalCrossrefCites:1,totalDimensionsCites:2,signatures:"Anthony Stocks, Andrew Noss, Malgorzata Bryja and Santiago Arce",downloadPdfUrl:"/chapter/pdf-download/34541",previewPdfUrl:"/chapter/pdf-preview/34541",authors:[{id:"106095",title:"Dr.",name:"Anthony",surname:"Stocks",slug:"anthony-stocks",fullName:"Anthony Stocks"},{id:"117897",title:"Dr.",name:"Andrew",surname:"Noss",slug:"andrew-noss",fullName:"Andrew Noss"},{id:"135199",title:"Mr.",name:"Santiago",surname:"Arce",slug:"santiago-arce",fullName:"Santiago Arce"},{id:"135592",title:"Dr.",name:"Malgorzata",surname:"Bryja",slug:"malgorzata-bryja",fullName:"Malgorzata Bryja"}],corrections:null},{id:"34542",title:"Sustainable Forest Management Techniques",doi:"10.5772/35823",slug:"sustainable-techniques-to-prevent-the-deforestation-",totalDownloads:4292,totalCrossrefCites:0,totalDimensionsCites:1,signatures:"K.P. Chethan, Jayaraman Srinivasan, Kumar Kriti and Kaki Sivaji",downloadPdfUrl:"/chapter/pdf-download/34542",previewPdfUrl:"/chapter/pdf-preview/34542",authors:[{id:"59563",title:"Dr.",name:"Srinivasan",surname:"Jayaraman",slug:"srinivasan-jayaraman",fullName:"Srinivasan Jayaraman"},{id:"105989",title:"Mr.",name:"Chethan",surname:"Kp",slug:"chethan-kp",fullName:"Chethan Kp"},{id:"105990",title:"Ms.",name:"Kriti",surname:"Kumar",slug:"kriti-kumar",fullName:"Kriti Kumar"},{id:"105992",title:"Mr.",name:"Sivaji",surname:"Kaki",slug:"sivaji-kaki",fullName:"Sivaji Kaki"}],corrections:null},{id:"34543",title:"Bunjil Forest Watch a Community-Based Forest Monitoring Service",doi:"10.5772/34808",slug:"bunjil-forest-watch-a-community-based-forest-monitoring-service",totalDownloads:1826,totalCrossrefCites:0,totalDimensionsCites:0,signatures:"Chris Goodman",downloadPdfUrl:"/chapter/pdf-download/34543",previewPdfUrl:"/chapter/pdf-preview/34543",authors:[{id:"101697",title:"Mr.",name:"Chris",surname:"Goodman",slug:"chris-goodman",fullName:"Chris Goodman"}],corrections:null},{id:"34544",title:"Remnant Vegetation Analysis of Guanabara Bay Basin, Rio de Janeiro, Brazil, Using Geographical Information System",doi:"10.5772/35774",slug:"remnant-vegetation-analysis-of-guanabara-bay-basin-rio-de-janeiro-brazil-using-geographical-informat",totalDownloads:2546,totalCrossrefCites:0,totalDimensionsCites:1,signatures:"Luzia Alice Ferreira de Moraes",downloadPdfUrl:"/chapter/pdf-download/34544",previewPdfUrl:"/chapter/pdf-preview/34544",authors:[{id:"105811",title:"Dr.",name:"Luzia Alice Ferreira",surname:"De Moraes",slug:"luzia-alice-ferreira-de-moraes",fullName:"Luzia Alice Ferreira De Moraes"}],corrections:null},{id:"34545",title:"Preserving Biodiversity and Ecosystems: Catalyzing Conservation Contagion",doi:"10.5772/35435",slug:"preserving-biodiversity-and-ecosystems-catalyzing-conservation-contagion",totalDownloads:2141,totalCrossrefCites:0,totalDimensionsCites:6,signatures:"Robert H. Horwich, Jonathan Lyon, Arnab Bose and Clara B. Jones",downloadPdfUrl:"/chapter/pdf-download/34545",previewPdfUrl:"/chapter/pdf-preview/34545",authors:[{id:"104422",title:"Dr.",name:"Robert",surname:"Horwich",slug:"robert-horwich",fullName:"Robert Horwich"},{id:"105667",title:"Dr.",name:"Jonathan",surname:"Lyon",slug:"jonathan-lyon",fullName:"Jonathan Lyon"},{id:"105668",title:"Mr.",name:"Arnab",surname:"Bose",slug:"arnab-bose",fullName:"Arnab Bose"},{id:"105669",title:"Dr.",name:"Clara",surname:"Jones",slug:"clara-jones",fullName:"Clara Jones"}],corrections:null},{id:"34546",title:"Efficiency of the Strategies to Prevent and Mitigate the Deforestation in Costa Rica",doi:"10.5772/33527",slug:"efficiency-of-the-strategies-to-prevent-and-mitigate-the-deforestation-in-costa-rica",totalDownloads:2238,totalCrossrefCites:0,totalDimensionsCites:0,signatures:"Óscar M. Chaves",downloadPdfUrl:"/chapter/pdf-download/34546",previewPdfUrl:"/chapter/pdf-preview/34546",authors:[{id:"96000",title:"Dr.",name:"Óscar M.",surname:"Chaves",slug:"oscar-m.-chaves",fullName:"Óscar M. Chaves"}],corrections:null},{id:"34547",title:"Agroforestry Systems and Local Institutional Development for Preventing Deforestation in Chiapas, Mexico",doi:"10.5772/35172",slug:"agroforestry-systems-and-local-institutional-development-for-preventing-deforestation-in-chiapas-mex",totalDownloads:3001,totalCrossrefCites:0,totalDimensionsCites:7,signatures:"Lorena Soto-Pinto, Miguel A. Castillo-Santiago and Guillermo Jiménez-Ferrer",downloadPdfUrl:"/chapter/pdf-download/34547",previewPdfUrl:"/chapter/pdf-preview/34547",authors:[{id:"103284",title:"Dr.",name:"Lorena",surname:"Soto-Pinto",slug:"lorena-soto-pinto",fullName:"Lorena Soto-Pinto"},{id:"105073",title:"Dr.",name:"Miguel A.",surname:"Castillo",slug:"miguel-a.-castillo",fullName:"Miguel A. Castillo"},{id:"105075",title:"Dr.",name:"Guillermo",surname:"Jimenez-Ferrer",slug:"guillermo-jimenez-ferrer",fullName:"Guillermo Jimenez-Ferrer"}],corrections:null},{id:"34548",title:"Economic Models of Shifting Cultivation: A Review",doi:"10.5772/35745",slug:"economic-models-of-shifting-cultivation-a-review",totalDownloads:2179,totalCrossrefCites:1,totalDimensionsCites:3,signatures:"Yoshito Takasaki",downloadPdfUrl:"/chapter/pdf-download/34548",previewPdfUrl:"/chapter/pdf-preview/34548",authors:[{id:"105713",title:"Prof.",name:"Yoshito",surname:"Takasaki",slug:"yoshito-takasaki",fullName:"Yoshito Takasaki"}],corrections:null}],productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"}},relatedBooks:[{type:"book",id:"2246",title:"Global Perspectives on Sustainable Forest Management",subtitle:null,isOpenForSubmission:!1,hash:"b633fc6fc6a3a8f24dd4c4373fb14cb7",slug:"global-perspectives-on-sustainable-forest-management",bookSignature:"Okia Clement Akais",coverURL:"https://cdn.intechopen.com/books/images_new/2246.jpg",editedByType:"Edited by",editors:[{id:"119660",title:"Dr.",name:"Dr. Clement A.",surname:"Okia",slug:"dr.-clement-a.-okia",fullName:"Dr. Clement A. Okia"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"616",title:"Forest Ecosystems",subtitle:"More than Just Trees",isOpenForSubmission:!1,hash:"00ecaa84de1aa2d7116ab5871b353b82",slug:"forest-ecosystems-more-than-just-trees",bookSignature:"Juan A. Blanco and Yueh-Hsin Lo",coverURL:"https://cdn.intechopen.com/books/images_new/616.jpg",editedByType:"Edited by",editors:[{id:"51995",title:"Dr.",name:"Juan",surname:"Blanco",slug:"juan-blanco",fullName:"Juan Blanco"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"617",title:"Sustainable Forest Management",subtitle:"Current Research",isOpenForSubmission:!1,hash:"a8d91cf4745e90f7510e056fd508dc46",slug:"sustainable-forest-management-current-research",bookSignature:"Jorge Martin Garcia and Julio Javier Diez Casero",coverURL:"https://cdn.intechopen.com/books/images_new/617.jpg",editedByType:"Edited by",editors:[{id:"88987",title:"Dr.",name:"Julio J.",surname:"Diez",slug:"julio-j.-diez",fullName:"Julio J. Diez"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"2073",title:"Sustainable Forest Management",subtitle:"Case Studies",isOpenForSubmission:!1,hash:"656069330afd66b7a27ca8963a544092",slug:"sustainable-forest-management-case-studies",bookSignature:"Jorge Martin-Garcia and Julio Javier Diez",coverURL:"https://cdn.intechopen.com/books/images_new/2073.jpg",editedByType:"Edited by",editors:[{id:"88987",title:"Dr.",name:"Julio J.",surname:"Diez",slug:"julio-j.-diez",fullName:"Julio J. Diez"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"1815",title:"New Advances and Contributions to Forestry Research",subtitle:null,isOpenForSubmission:!1,hash:"fb2caa8ab3683ea8aeba1810e7903a4a",slug:"new-advances-and-contributions-to-forestry-research",bookSignature:"Andrew Akwasi Oteng-Amoako",coverURL:"https://cdn.intechopen.com/books/images_new/1815.jpg",editedByType:"Edited by",editors:[{id:"119148",title:"Dr.",name:"Dr. Andrew A.",surname:"Oteng-Amoako",slug:"dr.-andrew-a.-oteng-amoako",fullName:"Dr. Andrew A. Oteng-Amoako"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"4757",title:"Precious Forests",subtitle:"Precious Earth",isOpenForSubmission:!1,hash:"6bd8329fb8128da2fc08c1c6d8a22613",slug:"precious-forests-precious-earth",bookSignature:"Miodrag Zlatic",coverURL:"https://cdn.intechopen.com/books/images_new/4757.jpg",editedByType:"Edited by",editors:[{id:"174414",title:"Dr.",name:"Miodrag",surname:"Zlatic",slug:"miodrag-zlatic",fullName:"Miodrag Zlatic"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"5877",title:"Plant Ecology",subtitle:"Traditional Approaches to Recent Trends",isOpenForSubmission:!1,hash:"788a981ecedf0d9c0205869788524a80",slug:"plant-ecology-traditional-approaches-to-recent-trends",bookSignature:"Zubaida Yousaf",coverURL:"https://cdn.intechopen.com/books/images_new/5877.jpg",editedByType:"Edited by",editors:[{id:"196003",title:"Dr.",name:"Zubaida",surname:"Yousaf",slug:"zubaida-yousaf",fullName:"Zubaida Yousaf"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"5455",title:"Global Exposition of Wildlife Management",subtitle:null,isOpenForSubmission:!1,hash:"0c60fd890b4af7771afc5211fdabe762",slug:"global-exposition-of-wildlife-management",bookSignature:"Gbolagade Stephen A. Lameed",coverURL:"https://cdn.intechopen.com/books/images_new/5455.jpg",editedByType:"Edited by",editors:[{id:"142349",title:"Dr.",name:"Gbolagade Akeem",surname:"Lameed",slug:"gbolagade-akeem-lameed",fullName:"Gbolagade Akeem Lameed"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"6162",title:"New Perspectives in Forest Science",subtitle:null,isOpenForSubmission:!1,hash:"514f8da8e59157028c3707db0deec202",slug:"new-perspectives-in-forest-science",bookSignature:"Helder Filipe dos Santos Viana and Francisco Antonio García Morote",coverURL:"https://cdn.intechopen.com/books/images_new/6162.jpg",editedByType:"Edited by",editors:[{id:"37172",title:"Prof.",name:"Helder",surname:"Viana",slug:"helder-viana",fullName:"Helder Viana"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"6304",title:"Forest Fire",subtitle:null,isOpenForSubmission:!1,hash:"5d379ad4bcbaa4c9b702c13254a45f76",slug:"forest-fire",bookSignature:"Janusz Szmyt",coverURL:"https://cdn.intechopen.com/books/images_new/6304.jpg",editedByType:"Edited by",editors:[{id:"180608",title:"Dr.",name:"Janusz",surname:"Szmyt",slug:"janusz-szmyt",fullName:"Janusz Szmyt"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}}],ofsBooks:[]},correction:{item:{id:"68990",slug:"erratum-application-of-design-for-manufacturing-and-assembly-development-of-a-multifeedstock-biodies",title:"Erratum - Application of Design for Manufacturing and Assembly: Development of a Multifeedstock Biodiesel Processor",doi:null,correctionPDFUrl:"https://cdn.intechopen.com/pdfs/68990.pdf",downloadPdfUrl:"/chapter/pdf-download/68990",previewPdfUrl:"/chapter/pdf-preview/68990",totalDownloads:null,totalCrossrefCites:null,bibtexUrl:"/chapter/bibtex/68990",risUrl:"/chapter/ris/68990",chapter:{id:"63204",slug:"application-of-design-for-manufacturing-and-assembly-development-of-a-multifeedstock-biodiesel-proce",signatures:"Ilesanmi Afolabi Daniyan and Khumbulani Mpofu",dateSubmitted:"March 15th 2018",dateReviewed:"July 9th 2018",datePrePublished:"November 5th 2018",datePublished:"January 3rd 2019",book:{id:"7460",title:"Applications of Design for Manufacturing and Assembly",subtitle:null,fullTitle:"Applications of Design for Manufacturing and Assembly",slug:"applications-of-design-for-manufacturing-and-assembly",publishedDate:"January 3rd 2019",bookSignature:"Ancuţa Păcurar",coverURL:"https://cdn.intechopen.com/books/images_new/7460.jpg",licenceType:"CC BY 3.0",editedByType:"Edited by",editors:[{id:"184794",title:"Dr.",name:"Ancuta Carmen",middleName:null,surname:"Păcurar",slug:"ancuta-carmen-pacurar",fullName:"Ancuta Carmen Păcurar"}],productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"}},authors:[{id:"11921",title:"Prof.",name:"Khumbulani",middleName:null,surname:"Mpofu",fullName:"Khumbulani Mpofu",slug:"khumbulani-mpofu",email:"mpofuk@tut.ac.za",position:null,institution:{name:"Tshwane University of Technology",institutionURL:null,country:{name:"South Africa"}}},{id:"260269",title:"Dr.",name:"Ilesanmi Afolabi",middleName:null,surname:"Daniyan",fullName:"Ilesanmi Afolabi Daniyan",slug:"ilesanmi-afolabi-daniyan",email:"afolabiilesanmi@yahoo.com",position:null,institution:null}]}},chapter:{id:"63204",slug:"application-of-design-for-manufacturing-and-assembly-development-of-a-multifeedstock-biodiesel-proce",signatures:"Ilesanmi Afolabi Daniyan and Khumbulani Mpofu",dateSubmitted:"March 15th 2018",dateReviewed:"July 9th 2018",datePrePublished:"November 5th 2018",datePublished:"January 3rd 2019",book:{id:"7460",title:"Applications of Design for Manufacturing and Assembly",subtitle:null,fullTitle:"Applications of Design for Manufacturing and Assembly",slug:"applications-of-design-for-manufacturing-and-assembly",publishedDate:"January 3rd 2019",bookSignature:"Ancuţa Păcurar",coverURL:"https://cdn.intechopen.com/books/images_new/7460.jpg",licenceType:"CC BY 3.0",editedByType:"Edited by",editors:[{id:"184794",title:"Dr.",name:"Ancuta Carmen",middleName:null,surname:"Păcurar",slug:"ancuta-carmen-pacurar",fullName:"Ancuta Carmen Păcurar"}],productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"}},authors:[{id:"11921",title:"Prof.",name:"Khumbulani",middleName:null,surname:"Mpofu",fullName:"Khumbulani Mpofu",slug:"khumbulani-mpofu",email:"mpofuk@tut.ac.za",position:null,institution:{name:"Tshwane University of Technology",institutionURL:null,country:{name:"South Africa"}}},{id:"260269",title:"Dr.",name:"Ilesanmi Afolabi",middleName:null,surname:"Daniyan",fullName:"Ilesanmi Afolabi Daniyan",slug:"ilesanmi-afolabi-daniyan",email:"afolabiilesanmi@yahoo.com",position:null,institution:null}]},book:{id:"7460",title:"Applications of Design for Manufacturing and Assembly",subtitle:null,fullTitle:"Applications of Design for Manufacturing and Assembly",slug:"applications-of-design-for-manufacturing-and-assembly",publishedDate:"January 3rd 2019",bookSignature:"Ancuţa Păcurar",coverURL:"https://cdn.intechopen.com/books/images_new/7460.jpg",licenceType:"CC BY 3.0",editedByType:"Edited by",editors:[{id:"184794",title:"Dr.",name:"Ancuta Carmen",middleName:null,surname:"Păcurar",slug:"ancuta-carmen-pacurar",fullName:"Ancuta Carmen Păcurar"}],productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"}}},ofsBook:{item:{type:"book",id:"8956",leadTitle:null,title:"Ornamental Plants and Trees - Perspectives and Challenges",subtitle:null,reviewType:"peer-reviewed",abstract:"<p>\r\n\tSince ancient times ornamental plants and trees have been produced for recreational purposes and gardening. The diversity and richness of plants used is beyond measure. Aside from this, ornamental plants and trees have been used for production of pharmaceuticals, nutrition and often both uses are combined in one plant species. The future of ornamental plants and trees is beyond ornamental plants by developing new products, alternative uses, or innovative value chains.</p>\r\n<p>\r\n\tBy doing so we need sustainable productions systems and have to cope with future challenges and meet societal requests. And of course new uses will affect breeding strategies for new varieties with improved traits meeting the expectations of grower, consumer, society and environment.</p>\r\n<p>\r\n\tIn this area of conflict ornamental plants and trees are produced. This book aims to provide an insight into old and possible future uses, which plants can be used, how breeding technologies will improve plant traits, what challenges do we have to deal with, what are the societal expectations and what developments could be made. Ornamental plants and trees production will undergo a rapid change in the near future. The book will highlight developments and implications.</p>",isbn:null,printIsbn:"979-953-307-X-X",pdfIsbn:null,doi:null,price:0,priceEur:0,priceUsd:0,slug:null,numberOfPages:0,isOpenForSubmission:!1,hash:"10ddbf1a87f25d1f54c4750e557ff9af",bookSignature:"Dr. Thorsten Kraska",publishedDate:null,coverURL:"https://cdn.intechopen.com/books/images_new/8956.jpg",keywords:"Floriculture, Biobased Materials and Chemicals, Phytoremediation, New Plants and Cultivars, Ecosystem Services, Plant Selection, Multipurpose Plants, Emerging Threads, Public Perception, Precision Horticulture, Sustainability, Bioeconomy",numberOfDownloads:null,numberOfWosCitations:0,numberOfCrossrefCitations:null,numberOfDimensionsCitations:null,numberOfTotalCitations:null,isAvailableForWebshopOrdering:!0,dateEndFirstStepPublish:"August 19th 2019",dateEndSecondStepPublish:"September 9th 2019",dateEndThirdStepPublish:"November 8th 2019",dateEndFourthStepPublish:"January 27th 2020",dateEndFifthStepPublish:"March 27th 2020",remainingDaysToSecondStep:"2 years",secondStepPassed:!0,currentStepOfPublishingProcess:5,editedByType:null,kuFlag:!1,biosketch:null,coeditorOneBiosketch:null,coeditorTwoBiosketch:null,coeditorThreeBiosketch:null,coeditorFourBiosketch:null,coeditorFiveBiosketch:null,editors:[{id:"306920",title:"Dr.",name:"Thorsten",middleName:null,surname:"Kraska",slug:"thorsten-kraska",fullName:"Thorsten Kraska",profilePictureURL:"https://mts.intechopen.com/storage/users/306920/images/system/306920.jpg",biography:"Dr. Thorsten Kraska has a PhD in horticulture (plant pathology) and he worked for some time as postdoc (formulation of plant protection products) and as a scientist in regulatory affairs. After change to University of Bonn (Germany), he worked for study affairs. Since 2010 he has been a scientist at the field lab Campus Klein-Altendorf responsible for horticultural trials. Since 2019 he has also been a member of the research group “Renewable Resources” at the Inst. f. Crop Science and Resource Conservation (Univ. Bonn). Dr Kraska’s research focus is soilless cultivation of horticultural plants, environmental friendly plant protection products, and sustainable utilization or ornamental plants. He is a lecturer in different study programs focusing on sustainable horticultural production systems, ornamentals, urban horticulture, renewable resources, as well as phenotyping. More on him can be found at: https://www.nawaro.uni-bonn.de/mitarbeiter/Thorsten%20Kraska",institutionString:"University of Bonn",position:null,outsideEditionCount:0,totalCites:0,totalAuthoredChapters:"0",totalChapterViews:"0",totalEditedBooks:"0",institution:{name:"University of Bonn",institutionURL:null,country:{name:"Germany"}}}],coeditorOne:null,coeditorTwo:null,coeditorThree:null,coeditorFour:null,coeditorFive:null,topics:[{id:"5",title:"Agricultural and Biological Sciences",slug:"agricultural-and-biological-sciences"}],chapters:null,productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"},personalPublishingAssistant:{id:"278926",firstName:"Ivana",lastName:"Barac",middleName:null,title:"Ms.",imageUrl:"https://mts.intechopen.com/storage/users/278926/images/8058_n.jpg",email:"ivana.b@intechopen.com",biography:"As an Author Service Manager my responsibilities include monitoring and facilitating all publishing activities for authors and editors. From chapter submission and review, to approval and revision, copyediting and design, until final publication, I work closely with authors and editors to ensure a simple and easy publishing process. I maintain constant and effective communication with authors, editors and reviewers, which allows for a level of personal support that enables contributors to fully commit and concentrate on the chapters they are writing, editing, or reviewing. I assist authors in the preparation of their full chapter submissions and track important deadlines and ensure they are met. I help to coordinate internal processes such as linguistic review, and monitor the technical aspects of the process. As an ASM I am also involved in the acquisition of editors. Whether that be identifying an exceptional author and proposing an editorship collaboration, or contacting researchers who would like the opportunity to work with IntechOpen, I establish and help manage author and editor acquisition and contact."}},relatedBooks:[{type:"book",id:"6418",title:"Hyperspectral Imaging in Agriculture, Food and Environment",subtitle:null,isOpenForSubmission:!1,hash:"9005c36534a5dc065577a011aea13d4d",slug:"hyperspectral-imaging-in-agriculture-food-and-environment",bookSignature:"Alejandro Isabel Luna Maldonado, Humberto Rodríguez Fuentes and Juan Antonio Vidales Contreras",coverURL:"https://cdn.intechopen.com/books/images_new/6418.jpg",editedByType:"Edited by",editors:[{id:"105774",title:"Prof.",name:"Alejandro Isabel",surname:"Luna Maldonado",slug:"alejandro-isabel-luna-maldonado",fullName:"Alejandro Isabel Luna Maldonado"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"1591",title:"Infrared Spectroscopy",subtitle:"Materials Science, Engineering and Technology",isOpenForSubmission:!1,hash:"99b4b7b71a8caeb693ed762b40b017f4",slug:"infrared-spectroscopy-materials-science-engineering-and-technology",bookSignature:"Theophile Theophanides",coverURL:"https://cdn.intechopen.com/books/images_new/1591.jpg",editedByType:"Edited by",editors:[{id:"37194",title:"Dr.",name:"Theophile",surname:"Theophanides",slug:"theophile-theophanides",fullName:"Theophile Theophanides"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"3161",title:"Frontiers in Guided Wave Optics and Optoelectronics",subtitle:null,isOpenForSubmission:!1,hash:"deb44e9c99f82bbce1083abea743146c",slug:"frontiers-in-guided-wave-optics-and-optoelectronics",bookSignature:"Bishnu Pal",coverURL:"https://cdn.intechopen.com/books/images_new/3161.jpg",editedByType:"Edited by",editors:[{id:"4782",title:"Prof.",name:"Bishnu",surname:"Pal",slug:"bishnu-pal",fullName:"Bishnu Pal"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"3092",title:"Anopheles mosquitoes",subtitle:"New insights into malaria vectors",isOpenForSubmission:!1,hash:"c9e622485316d5e296288bf24d2b0d64",slug:"anopheles-mosquitoes-new-insights-into-malaria-vectors",bookSignature:"Sylvie Manguin",coverURL:"https://cdn.intechopen.com/books/images_new/3092.jpg",editedByType:"Edited by",editors:[{id:"50017",title:"Prof.",name:"Sylvie",surname:"Manguin",slug:"sylvie-manguin",fullName:"Sylvie Manguin"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"371",title:"Abiotic Stress in Plants",subtitle:"Mechanisms and Adaptations",isOpenForSubmission:!1,hash:"588466f487e307619849d72389178a74",slug:"abiotic-stress-in-plants-mechanisms-and-adaptations",bookSignature:"Arun Shanker and B. Venkateswarlu",coverURL:"https://cdn.intechopen.com/books/images_new/371.jpg",editedByType:"Edited by",editors:[{id:"58592",title:"Dr.",name:"Arun",surname:"Shanker",slug:"arun-shanker",fullName:"Arun Shanker"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"72",title:"Ionic Liquids",subtitle:"Theory, Properties, New Approaches",isOpenForSubmission:!1,hash:"d94ffa3cfa10505e3b1d676d46fcd3f5",slug:"ionic-liquids-theory-properties-new-approaches",bookSignature:"Alexander Kokorin",coverURL:"https://cdn.intechopen.com/books/images_new/72.jpg",editedByType:"Edited by",editors:[{id:"19816",title:"Prof.",name:"Alexander",surname:"Kokorin",slug:"alexander-kokorin",fullName:"Alexander Kokorin"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"314",title:"Regenerative Medicine and Tissue Engineering",subtitle:"Cells and Biomaterials",isOpenForSubmission:!1,hash:"bb67e80e480c86bb8315458012d65686",slug:"regenerative-medicine-and-tissue-engineering-cells-and-biomaterials",bookSignature:"Daniel Eberli",coverURL:"https://cdn.intechopen.com/books/images_new/314.jpg",editedByType:"Edited by",editors:[{id:"6495",title:"Dr.",name:"Daniel",surname:"Eberli",slug:"daniel-eberli",fullName:"Daniel Eberli"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"57",title:"Physics and Applications of Graphene",subtitle:"Experiments",isOpenForSubmission:!1,hash:"0e6622a71cf4f02f45bfdd5691e1189a",slug:"physics-and-applications-of-graphene-experiments",bookSignature:"Sergey Mikhailov",coverURL:"https://cdn.intechopen.com/books/images_new/57.jpg",editedByType:"Edited by",editors:[{id:"16042",title:"Dr.",name:"Sergey",surname:"Mikhailov",slug:"sergey-mikhailov",fullName:"Sergey Mikhailov"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"1373",title:"Ionic Liquids",subtitle:"Applications and Perspectives",isOpenForSubmission:!1,hash:"5e9ae5ae9167cde4b344e499a792c41c",slug:"ionic-liquids-applications-and-perspectives",bookSignature:"Alexander Kokorin",coverURL:"https://cdn.intechopen.com/books/images_new/1373.jpg",editedByType:"Edited by",editors:[{id:"19816",title:"Prof.",name:"Alexander",surname:"Kokorin",slug:"alexander-kokorin",fullName:"Alexander Kokorin"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"2270",title:"Fourier Transform",subtitle:"Materials Analysis",isOpenForSubmission:!1,hash:"5e094b066da527193e878e160b4772af",slug:"fourier-transform-materials-analysis",bookSignature:"Salih Mohammed Salih",coverURL:"https://cdn.intechopen.com/books/images_new/2270.jpg",editedByType:"Edited by",editors:[{id:"111691",title:"Dr.Ing.",name:"Salih",surname:"Salih",slug:"salih-salih",fullName:"Salih Salih"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}}]},chapter:{item:{type:"chapter",id:"65993",title:"Automatic Speech Emotion Recognition Using Machine Learning",doi:"10.5772/intechopen.84856",slug:"automatic-speech-emotion-recognition-using-machine-learning",body:'\n<div class="section" id="sec_1" data-lvl="1">\n<h2 class="heading main-title">1. Introduction</h2>\n<p id="p2">Emotion plays a significant role in daily interpersonal human interactions. This is essential to our rational as well as intelligent decisions. It helps us to match and understand the feelings of others by conveying our feelings and giving feedback to others. Research has revealed the powerful role that emotion play in shaping human social interaction. Emotional displays convey considerable information about the mental state of an individual. This has opened up a new research field called automatic emotion recognition, having basic goals to understand and retrieve desired emotions. In prior studies, several modalities have been explored to recognize the emotional states such as facial expressions [<a href="#B1" class="ref-link" data-ref-style="bibr">1</a>], speech [<a href="#B2" class="ref-link" data-ref-style="bibr">2</a>], physiological signals [<a href="#B3" class="ref-link" data-ref-style="bibr">3</a>], etc. Several inherent advantages make speech signals a good source for affective computing. For example, compared to many other biological signals (e.g., electrocardiogram), speech signals usually can be acquired more readily and economically. This is why the majority of researchers are interested in speech emotion recognition (SER). SER aims to recognize the underlying emotional state of a speaker from her voice. The area has received increasing research interest all through current years. There are many applications of detecting the emotion of the persons like in the interface with robots, audio surveillance, web-based E-learning, commercial applications, clinical studies, entertainment, banking, call centers, cardboard systems, computer games, etc. For classroom orchestration or E-learning, information about the emotional state of students can provide focus on the enhancement of teaching quality. For example, a teacher can use SER to decide what subjects can be taught and must be able to develop strategies for managing emotions within the learning environment. That is why learner&rsquo;s emotional state should be considered in the classroom.</p>\n<p id="p3">Three key issues need to be addressed for successful SER system, namely, (1) choice of a good emotional speech database, (2) extracting effective features, and (3) designing reliable classifiers using machine learning algorithms. In fact, the emotional feature extraction is a main issue in the SER system. Many researchers [<a href="#B4" class="ref-link" data-ref-style="bibr">4</a>] have proposed important speech features which contain emotion information, such as energy, pitch, formant frequency, Linear Prediction Cepstrum Coefficients (LPCC), Mel-frequency cepstrum coefficients (MFCC), and modulation spectral features (MSFs) [<a href="#B5" class="ref-link" data-ref-style="bibr">5</a>]. Thus, most researchers prefer to use combining feature set that is composed of many kinds of features containing more emotional information [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>]. However, using a combining feature set may give rise to high dimension and redundancy of speech features; thereby, it makes the learning process complicated for most machine learning algorithms and increases the likelihood of overfitting. Therefore, feature selection is indispensable to reduce the dimensions redundancy of features. A review for feature selection models and techniques is presented in [<a href="#B7" class="ref-link" data-ref-style="bibr">7</a>]. Both feature extraction and feature selection are capable of improving learning performance, lowering computational complexity, building better generalizable models, and decreasing required storage. The last step of speech emotion recognition is classification. It involves classifying the raw data in the form of utterance or frame of the utterance into a particular class of emotion on the basis of features extracted from the data. In recent years in speech emotion recognition, researchers proposed many classification algorithms, such as Gaussian mixture model (GMM) [<a href="#B8" class="ref-link" data-ref-style="bibr">8</a>], hidden Markov model (HMM) [<a href="#B9" class="ref-link" data-ref-style="bibr">9</a>], support vector machine (SVM) [<a href="#B10" class="ref-link" data-ref-style="bibr">10</a>, <a href="#B11" class="ref-link" data-ref-style="bibr">11</a>, <a href="#B12" class="ref-link" data-ref-style="bibr">12</a>, <a href="#B13" class="ref-link" data-ref-style="bibr">13</a>, <a href="#B14" class="ref-link" data-ref-style="bibr">14</a>], neural networks (NN) [<a href="#B15" class="ref-link" data-ref-style="bibr">15</a>], and recurrent neural networks (RNN) [<a href="#B16" class="ref-link" data-ref-style="bibr">16</a>, <a href="#B17" class="ref-link" data-ref-style="bibr">17</a>, <a href="#B18" class="ref-link" data-ref-style="bibr">18</a>]. Some other types of classifiers are also proposed by some researchers such as a modified brain emotional learning model (BEL) [<a href="#B19" class="ref-link" data-ref-style="bibr">19</a>] in which the adaptive neuro-fuzzy inference system (ANFIS) and multilayer perceptron (MLP) are merged for speech emotion recognition. Another proposed strategy is a multiple kernel Gaussian process (GP) classification [<a href="#B17" class="ref-link" data-ref-style="bibr">17</a>], in which two similar notions in the learning algorithm are presented by combining the linear kernel and radial basis function (RBF) kernel. The Voiced Segment Selection (VSS) algorithm also proposed in [<a href="#B20" class="ref-link" data-ref-style="bibr">20</a>] deals with the voiced signal segment as the texture image processing feature which is different from the traditional method. It uses the Log-Gabor filters to extract the voiced and unvoiced features from spectrogram to make the classification.</p>\n<p id="p4">In previous work [<a href="#B21" class="ref-link" data-ref-style="bibr">21</a>], we present a system for the recognition of &laquo;seven acted emotional states (anger, disgust, fear, joy, sadness, and surprise)&raquo;. To do that, we extracted the MFCC and MS features and used them to train three different machine learning paradigms (MLR, SVM, and RNN). We demonstrated that the combination of both features has a high accuracy above 94% on the Spanish database. All previously published works generally use the Berlin database. To our knowledge, the Spanish emotional database has never been used before. For this reason, we have chosen to compare them. In this chapter, we concentrate to improve accuracy; more experiments have been performed. This chapter mainly makes the following contributions:<ul><li><p id="p5">The effect of speaker normalization (SN) is also studied, which removes the mean of features and normalizes them to unit variance. Experiments are performed under a speaker-independent condition.</p></li><li><p id="p6">Additionally, a feature selection technique is assessed to obtain good features from the set of features extracted in [<a href="#B21" class="ref-link" data-ref-style="bibr">21</a>].</p></li></ul></p>\n<p id="p7">The rest of the chapter is organized as follows. In the next section, we start by introducing the nature of speech emotions. Section 3 describes features we extracted from a speech signal. A feature selection method and machine learning algorithms used for SER are presented. Section 4 reports on the databases we used and presents the simulation results obtained using different features and different machine learning (ML) paradigms. Section 5 closes this chapter by analyses and conclusion.</p>\n</div>\n<div class="section" id="sec_2" data-lvl="1">\n<h2 class="heading main-title">2. Emotion and classification</h2>\n<p id="p8">This section is concerned with defining the term emotion, presenting its different models. Also for recognizing emotions, there are several techniques and inputs that can be used. A brief description of all of the techniques is presented here.</p>\n<div class="section" id="sec_2_2" data-lvl="2">\n<h3 class="heading section-title">2.1 Definition</h3>\n<p id="p9">A definition is both important and difficult because the everyday word &ldquo;emotion&rdquo; is a notoriously fluid term in meaning. Emotion is one of the most difficult concepts to define in psychology. In fact, there are different definitions of emotions in the scientific literature. In everyday speech, emotion is any relatively brief conscious experience characterized by intense mental activity and a high degree of pleasure or displeasure [<a href="#B22" class="ref-link" data-ref-style="bibr">22</a>, <a href="#B23" class="ref-link" data-ref-style="bibr">23</a>]. Scientific discourse has drifted to other meanings and there is no consensus on a definition. Emotion is often entwined with temperament, mood, personality, motivation, and disposition. In psychology, emotion is frequently defined as a complex state of feeling that results in physical and psychological changes. These changes influence thought and behavior. According to other theories, emotions are not causal forces but simply syndromes of components such as motivation, feeling, behavior, and physiological changes [<a href="#B24" class="ref-link" data-ref-style="bibr">24</a>]. In 1884, in <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">What is an emotion?</italic></em> [<a href="#B25" class="ref-link" data-ref-style="bibr">25</a>], American psychologist and philosopher William James proposed a theory of emotion whose influence was considerable. According to his thesis, the feeling of intense emotion corresponds to the perception of specific bodily changes. This approach is found in many current theories: the bodily reaction is the cause and not the consequence of the emotion. The scope of this theory is measured by the many debates it provokes. This illustrates the difficulty of agreeing on a definition of this dynamic and complex phenomenon that we call emotion. &ldquo;Emotion&rdquo; refers to a wide range of affective processes such as moods, feelings, affects, and well-being [<a href="#B26" class="ref-link" data-ref-style="bibr">26</a>]. The term &ldquo;emotion&rdquo; in [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>] has been also referred to an extremely complex state associated with a wide variety of mental, physiological, and physical events.</p>\n</div>\n<div class="section" id="sec_3_2" data-lvl="2">\n<h3 class="heading section-title">2.2 Categorization of emotions</h3>\n<p id="p10">The categorization of emotions has long been a hot subject of debate in different fields of psychology, affective science, and emotion research. It is mainly based on two popular approaches: categorical (termed discrete) and dimensional (termed continuous). In the first approach, emotions are described with a discrete number of classes. Many theorists have conducted studies to determine which emotions are basic [<a href="#B27" class="ref-link" data-ref-style="bibr">27</a>]. A most popular example is Ekman [<a href="#B28" class="ref-link" data-ref-style="bibr">28</a>] who proposed a list of six basic emotions, which are anger, disgust, fear, happiness, sadness, and surprise. He explains that each emotion acts as a discrete category rather than an individual emotional state. In the second approach, emotions are a combination of several psychological dimensions and identified by axes. Other researchers define emotions according to one or more dimensions. Wilhelm Max Wundt proposed in 1897 that emotions can be described by three dimensions: (1) strain versus relaxation, (2) pleasurable versus unpleasurable, and (3) arousing versus subduing [<a href="#B29" class="ref-link" data-ref-style="bibr">29</a>]. PAD emotional state model is another three-dimensional approach by Albert Mehrabian and James Russell where PAD stands for pleasure, arousal, and dominance. Another popular dimensional model was proposed by James Russell in 1977. Unlike the earlier three-dimensional models, Russell&rsquo;s model features only two dimensions which include (1) arousal (or activation) and (2) valence (or evaluation) [<a href="#B29" class="ref-link" data-ref-style="bibr">29</a>].</p>\n<p id="p11">The categorical approach is commonly used in SER [<a href="#B30" class="ref-link" data-ref-style="bibr">30</a>]. It characterizes emotions used in everyday emotion words such as joy and anger. In this work, a set of six basic emotions (anger, disgust, fear, joy, sadness, and surprise) plus neutral, corresponding to the six emotions of Ekman&rsquo;s model, were used for the recognition of emotion from speech using the categorical approach.</p>\n</div>\n<div class="section" id="sec_4_2" data-lvl="2">\n<h3 class="heading section-title">2.3 Sensory modalities for emotion expression</h3>\n<p id="p12">There is vigorous debate about what exactly individual can express nonverbally. Humans can express their emotions through many different types of nonverbal communication including facial expressions, quality of speech produced, and physiological signals of the human body. In this section, we discuss each of these categories.</p>\n<div class="section" id="sec_4_3" data-lvl="3">\n<h4 class="heading subsection-title">2.3.1 Facial expressions</h4>\n<p id="p13">The human face is extremely expressive, able to express countless emotions without saying a word [<a href="#B31" class="ref-link" data-ref-style="bibr">31</a>]. And unlike some forms of nonverbal communication, facial expressions are universal. The facial expressions for happiness, sadness, anger, surprise, fear, and disgust are the same across cultures.</p>\n</div>\n<div class="section" id="sec_5_3" data-lvl="3">\n<h4 class="heading subsection-title">2.3.2 Speech</h4>\n<p id="p14">In addition to faces, voices are an important modality for emotional expression. Speech is a relevant communicational channel enriched with emotions: the voice in speech not only conveys a semantic message but also the information about the emotional state of the speaker. Some important voice feature vectors that have been chosen for research such as fundamental frequency, mel-frequency cepstral coefficient (MFCC), prediction cepstral coefficient (LPCC), etc.</p>\n</div>\n<div class="section" id="sec_6_3" data-lvl="3">\n<h4 class="heading subsection-title">2.3.3 Physiological signals</h4>\n<p id="p15">The physiological signals related to autonomic nervous system allow to assess objectively emotions. These include electroencephalogram (EEG), heart rate (HR), electrocardiogram (ECG), respiration (RSP), blood pressure (BP), electromyogram (EMG), skin conductance (SC), blood volume pulse (BVP), and skin temperature (ST) [<a href="#B32" class="ref-link" data-ref-style="bibr">32</a>]. Using physiological signals to recognize emotions is also helpful to those people who suffer from physical or mental illness thus exhibit problems with facial expressions or tone of voice.</p>\n</div>\n</div>\n</div>\n<div class="section" id="sec_9" data-lvl="1">\n<h2 class="heading main-title">3. Speech emotion recognition (SER) system</h2>\n<div class="section" id="sec_9_2" data-lvl="2">\n<h3 class="heading section-title">3.1 Block diagram</h3>\n<p id="p16">Our SER system consists of four main steps. First is the voice sample collection. The second features vector that is formed by extracting the features. As the next step, we tried to determine which features are most relevant to differentiate each emotion. These features are introduced to machine learning classifier for recognition. This process is described in <a href="#F1" class="ref-link" data-ref-style="fig">Figure 1</a>.</p>\n<figure class="media-panel" id="F1"><div class="media"><img src="/media/chapter/65993/media/F1.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 1.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p17">Block diagram of the proposed system.</p></p></figcaption></figure>\n</div>\n<div class="section" id="sec_10_2" data-lvl="2">\n<h3 class="heading section-title">3.2. Feature extraction</h3>\n<p id="p18">The speech signal contains a large number of parameters that reflect the emotional characteristics. One of the sticking points in emotion recognition is what features should be used. In recent research, many common features are extracted, such as energy, pitch, formant, and some spectrum features such as linear prediction coefficients (LPC), mel-frequency cepstrum coefficients (MFCC), and modulation spectral features. In this work, we have selected modulation spectral features and MFCC, to extract the emotional features.</p>\n<p id="p19"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Mel-frequency cepstrum coefficient (MFCC)</bold></strong> is the most used representation of the spectral property of voice signals. These are the best for speech recognition as it takes human perception sensitivity with respect to frequencies into consideration. For each frame, the Fourier transform and the energy spectrum were estimated and mapped into the Mel-frequency scale. The discrete cosine transform (DCT) of the Mel log energies was estimated, and the first 12 DCT coefficients provided the MFCC values used in the classification process. Usually, the process of calculating MFCC is shown in <a href="#F2" class="ref-link" data-ref-style="fig">Figure 2</a>.</p>\n<figure class="media-panel" id="F2"><div class="media"><img src="/media/chapter/65993/media/F2.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 2.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p20">Schema of MFCC extraction [<xref ref-type="bibr" rid="B33">33</xref>].</p></p></figcaption></figure>\n<p id="p21">In our research, we extract the first 12 order of the MFCC coefficients where the speech signals are sampled at 16 KHz. For each order coefficients, we calculate the mean, variance, standard deviation, kurtosis, and skewness, and this is for the other all the frames of an utterance. Each MFCC feature vector is 60-dimensional.</p>\n<p id="p22"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Modulation spectral features (MSFs)</bold></strong> are extracted from an auditory-inspired long-term spectro-temporal representation. These features are obtained by emulating the spectro-temporal (ST) processing performed in the human auditory system and consider regular acoustic frequency jointly with modulation frequency. The steps for computing the ST representation are illustrated in <a href="#F3" class="ref-link" data-ref-style="fig">Figure 3</a>. In order to obtain the ST representation, the speech signal is first decomposed by an auditory filterbank (19 filters in total). The Hilbert envelopes of the critical-band outputs are computed to form the modulation signals. A modulation filterbank is further applied to the Hilbert envelopes to perform frequency analysis. The spectral contents of the modulation signals are referred to as modulation spectra, and the proposed features are thereby named modulation spectral features (MSFs) [<a href="#B5" class="ref-link" data-ref-style="bibr">5</a>]. Lastly, the ST representation is formed by measuring the energy of the decomposed envelope signals, as a function of regular acoustic frequency and modulation frequency. The energy, taken over all frames in every spectral band, provides a feature. In our experiment, an auditory filterbank with <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m1">\n<mml:mi>N</mml:mi>\n<mml:mo>=</mml:mo>\n<mml:mn>19</mml:mn>\n</mml:math>\n</span> filters and a modulation filterbank with <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m2">\n<mml:mi>M</mml:mi>\n<mml:mo>=</mml:mo>\n<mml:mn>5</mml:mn>\n</mml:math>\n</span> filters are used. In total, 95 <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m3">\n<mml:mfenced open="(" close=")">\n<mml:mrow>\n<mml:mn>19</mml:mn>\n<mml:mo>&times;</mml:mo>\n<mml:mn>5</mml:mn>\n</mml:mrow>\n</mml:mfenced>\n</mml:math>\n</span> MSFs are calculated in this work from the ST representation.</p>\n<figure class="media-panel" id="F3"><div class="media"><img src="/media/chapter/65993/media/F3.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 3.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p23">Process for computing the ST representation [<xref ref-type="bibr" rid="B5">5</xref>].</p></p></figcaption></figure>\n</div>\n<div class="section" id="sec_11_2" data-lvl="2">\n<h3 class="heading section-title">3.3 Feature selection</h3>\n<p id="p24">As reported by Aha and Bankert [<a href="#B34" class="ref-link" data-ref-style="bibr">34</a>], the objective of feature selection in ML is to &ldquo;reduce the number of features used to characterize a dataset so as to improve a learning algorithm&rsquo;s performance on a given task.&rdquo; The objective will be the maximization of the classification accuracy in a specific task for a certain learning algorithm; as a collateral effect, the number of features to induce the final classification model will be reduced. Feature selection (FS) aims to choose a subset of the relevant features from the original ones according to certain relevance evaluation criterion, which usually leads to higher recognition accuracy [<a href="#B35" class="ref-link" data-ref-style="bibr">35</a>]. It can drastically reduce the running time of the learning algorithms. In this section, we present an effective feature selection method used in our work, named recursive feature elimination with linear regression (LR-RFE).</p>\n<p id="p25"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Recursive feature elimination (RFE)</bold></strong> uses a model (e.g., linear regression or SVM) to select either the best- or worst-performing feature and then excludes this feature. These estimators assign weights to features (e.g., the coefficients of a linear model), so the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features, and the predictive power of each feature is measured [<a href="#B36" class="ref-link" data-ref-style="bibr">36</a>]. Then, the least important features are removed from the current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached. In this work, we implemented the recursive feature elimination method of feature ranking via the use of basic linear regression (LR-RFE) [<a href="#B37" class="ref-link" data-ref-style="bibr">37</a>]. Other research also uses RFE with another linear model such as SVM-RFE that is an SVM-based feature selection algorithm created by [<a href="#B38" class="ref-link" data-ref-style="bibr">38</a>]. Using SVM-RFE, Guyon et al. selected key and important feature sets. In addition to improving the classification accuracy rate, it can reduce classification computational time.</p>\n</div>\n<div class="section" id="sec_12_2" data-lvl="2">\n<h3 class="heading section-title">3.4 Classification methods</h3>\n<p id="p26">Many machine learning algorithms have been used for discrete emotion classification. The goal of these algorithms is to learn from the training samples and then use this learning to classify new observation. In fact, there is no definitive answer to the choice of the learning algorithm; every technique has its own advantages and limitations. For this reason, here we chose to compare the performance of three different classifiers.</p>\n<p id="p27"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Multivariate linear regression classification (MLR)</bold></strong> is a simple and efficient computation of machine learning algorithms, and it can be used for both regression and classification problems. We have slightly modified the LRC algorithm described as follow Algorithm 1 [<a href="#B39" class="ref-link" data-ref-style="bibr">39</a>]. We calculated (in step 3) the absolute value of the difference between original and predicted response vectors (<span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m4">\n<mml:mo>&#8739;</mml:mo>\n<mml:mi>y</mml:mi>\n<mml:mo>&minus;</mml:mo>\n<mml:msub>\n<mml:mi>y</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>&#8739;</mml:mo>\n</mml:math>\n</span>), instead of the Euclidean distance between them (<span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m5">\n<mml:mo stretchy="true">&#8214;</mml:mo>\n<mml:mi>y</mml:mi>\n<mml:mo>&minus;</mml:mo>\n<mml:msub>\n<mml:mi>y</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo stretchy="true">&#8214;</mml:mo>\n</mml:math>\n</span>).</p>\n<p id="p28"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Support vector machines (SVM)</bold></strong> are an optimal margin classifier in machine learning. It is also used extensively in many studies that related to audio emotion recognition which can be found in [<a href="#B10" class="ref-link" data-ref-style="bibr">10</a>, <a href="#B13" class="ref-link" data-ref-style="bibr">13</a>, <a href="#B14" class="ref-link" data-ref-style="bibr">14</a>]. It can have a very good classification performance compared to other classifiers especially for limited training data [<a href="#B11" class="ref-link" data-ref-style="bibr">11</a>]. SVM theoretical background can be found in [<a href="#B40" class="ref-link" data-ref-style="bibr">40</a>]. A MATLAB toolbox implementing SVM is freely available in [<a href="#B41" class="ref-link" data-ref-style="bibr">41</a>]. A polynomial kernel is investigated in this work.</p>\n<p id="p29"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Algorithm 1.</bold></strong> Linear Regression Classification (LRC)</p>\n<p id="p30">Inputs: Class models <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m6">\n<mml:msub>\n<mml:mi>X</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>&isin;</mml:mo>\n<mml:msup>\n<mml:mi mathvariant="double-struck">R</mml:mi>\n<mml:mrow>\n<mml:mi>q</mml:mi>\n<mml:mo>&times;</mml:mo>\n<mml:msub>\n<mml:mi>p</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n</mml:mrow>\n</mml:msup>\n<mml:mo>,</mml:mo>\n<mml:mi>i</mml:mi>\n<mml:mo>=</mml:mo>\n<mml:mn>1</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mn>2</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mo>&hellip;</mml:mo>\n<mml:mo>,</mml:mo>\n<mml:mi>N</mml:mi>\n</mml:math>\n</span> and a test speech vector <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m7">\n<mml:mi>y</mml:mi>\n<mml:mo>&isin;</mml:mo>\n<mml:msup>\n<mml:mi mathvariant="double-struck">R</mml:mi>\n<mml:mrow>\n<mml:mi>q</mml:mi>\n<mml:mo>&times;</mml:mo>\n<mml:mn>1</mml:mn>\n</mml:mrow>\n</mml:msup>\n</mml:math>\n</span></p>\n<p id="p31">Output: Class of <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m8">\n<mml:mi>y</mml:mi>\n</mml:math>\n</span></p>\n<p id="p32">1. <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m9">\n<mml:msub>\n<mml:mover accent="true">\n<mml:mi>&beta;</mml:mi>\n<mml:mo stretchy="false">&#770;</mml:mo>\n</mml:mover>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>&isin;</mml:mo>\n<mml:msup>\n<mml:mi mathvariant="double-struck">R</mml:mi>\n<mml:mrow>\n<mml:msub>\n<mml:mi>p</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>&times;</mml:mo>\n<mml:mn>1</mml:mn>\n</mml:mrow>\n</mml:msup>\n</mml:math>\n</span> is evaluated against each class model, <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m10">\n<mml:msub>\n<mml:mover accent="true">\n<mml:mi>&beta;</mml:mi>\n<mml:mo stretchy="false">&#770;</mml:mo>\n</mml:mover>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>=</mml:mo>\n<mml:msup>\n<mml:mfenced open="(" close=")">\n<mml:mrow>\n<mml:msubsup>\n<mml:mi>X</mml:mi>\n<mml:mi>i</mml:mi>\n<mml:mi>T</mml:mi>\n</mml:msubsup>\n<mml:msub>\n<mml:mi>X</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n</mml:mrow>\n</mml:mfenced>\n<mml:mfenced open="(" close=")">\n<mml:mrow>\n<mml:mo>&minus;</mml:mo>\n<mml:mn>1</mml:mn>\n</mml:mrow>\n</mml:mfenced>\n</mml:msup>\n<mml:msubsup>\n<mml:mi>X</mml:mi>\n<mml:mi>i</mml:mi>\n<mml:mi>T</mml:mi>\n</mml:msubsup>\n<mml:mi>y</mml:mi>\n<mml:mo>,</mml:mo>\n</mml:math>\n</span> <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m11">\n<mml:mi>i</mml:mi>\n<mml:mo>=</mml:mo>\n<mml:mn>1</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mn>2</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mo>&hellip;</mml:mo>\n<mml:mo>,</mml:mo>\n<mml:mi>N</mml:mi>\n</mml:math>\n</span></p>\n<p id="p33">2. <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m12">\n<mml:msub>\n<mml:mover accent="true">\n<mml:mi>y</mml:mi>\n<mml:mo stretchy="false">&#770;</mml:mo>\n</mml:mover>\n<mml:mi>i</mml:mi>\n</mml:msub>\n</mml:math>\n</span> is computed for each <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m13">\n<mml:msub>\n<mml:mover accent="true">\n<mml:mi>&beta;</mml:mi>\n<mml:mo stretchy="false">&#770;</mml:mo>\n</mml:mover>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>,</mml:mo>\n<mml:msub>\n<mml:mover accent="true">\n<mml:mi>y</mml:mi>\n<mml:mo stretchy="false">&#770;</mml:mo>\n</mml:mover>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>=</mml:mo>\n<mml:msub>\n<mml:mi>X</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:msub>\n<mml:mover accent="true">\n<mml:mi>&beta;</mml:mi>\n<mml:mo stretchy="false">&#770;</mml:mo>\n</mml:mover>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>,</mml:mo>\n<mml:mspace width="1em"></mml:mspace>\n<mml:mi>i</mml:mi>\n<mml:mo>=</mml:mo>\n<mml:mn>1</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mn>2</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mo>&hellip;</mml:mo>\n<mml:mo>,</mml:mo>\n<mml:mi>N</mml:mi>\n</mml:math>\n</span>;</p>\n<p id="p34">3. Distance calculation between original and predicted response variables <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m14">\n<mml:msub>\n<mml:mi>d</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mfenced open="(" close=")">\n<mml:mi>y</mml:mi>\n</mml:mfenced>\n<mml:mo>=</mml:mo>\n<mml:mo>&#8739;</mml:mo>\n<mml:mi>y</mml:mi>\n<mml:mo>&minus;</mml:mo>\n<mml:msub>\n<mml:mi>y</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mo>&#8739;</mml:mo>\n<mml:mo>,</mml:mo>\n<mml:mspace width="1em"></mml:mspace>\n<mml:mi>i</mml:mi>\n<mml:mo>=</mml:mo>\n<mml:mn>1</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mn>2</mml:mn>\n<mml:mo>,</mml:mo>\n<mml:mo>&hellip;</mml:mo>\n<mml:mo>,</mml:mo>\n<mml:mi>N</mml:mi>\n</mml:math>\n</span>;</p>\n<p id="p35">4. Decision is made in favor of the class with the minimum distance <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m15">\n<mml:msub>\n<mml:mi>d</mml:mi>\n<mml:mi>i</mml:mi>\n</mml:msub>\n<mml:mfenced open="(" close=")">\n<mml:mi>y</mml:mi>\n</mml:mfenced>\n</mml:math>\n</span></p>\n<p id="p36"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Recurrent neural networks (RNN)</bold></strong> are suitable for learning time series data, and it has shown improved performance for classification task [<a href="#B42" class="ref-link" data-ref-style="bibr">42</a>]. While RNN models are effective at learning temporal correlations, they suffer from the vanishing gradient problem which increases with the length of the training sequences. To resolve this problem, long short-term memory (LSTM) RNNs were proposed by Hochreiter et al. [<a href="#B43" class="ref-link" data-ref-style="bibr">43</a>]; it uses memory cells to store information so that it can exploit long-range dependencies in the data [<a href="#B17" class="ref-link" data-ref-style="bibr">17</a>].</p>\n<p id="p37"><a href="#F4" class="ref-link" data-ref-style="fig">Figure 4</a> shows a basic concept of RNN implementation. Unlike traditional neural network that uses different parameters at each layer, the RNN shares the same parameters (U, V, and W are presented in <a href="#F4" class="ref-link" data-ref-style="fig">Figure 4</a>) across all steps. The hidden state formulas and variables are as follows:</p>\n<figure class="media-panel" id="F4"><div class="media"><img src="/media/chapter/65993/media/F4.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 4.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p38">A basic concept of RNN and unfolding in time of the computation involved in its forward computation [<xref ref-type="bibr" rid="B18">18</xref>].</p></p></figcaption></figure>\n<div id="df_" class="formula panel">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" specific-use="web-only">\n<mml:msub>\n<mml:mi>s</mml:mi>\n<mml:mi>t</mml:mi>\n</mml:msub>\n<mml:mo>=</mml:mo>\n<mml:mi>f</mml:mi>\n<mml:mfenced open="(" close=")">\n<mml:mrow>\n<mml:msub>\n<mml:mi mathvariant="italic">Ux</mml:mi>\n<mml:mi>t</mml:mi>\n</mml:msub>\n<mml:mo>+</mml:mo>\n<mml:msub>\n<mml:mi mathvariant="italic">Ws</mml:mi>\n<mml:mrow>\n<mml:mi>t</mml:mi>\n<mml:mo>&minus;</mml:mo>\n<mml:mn>1</mml:mn>\n</mml:mrow>\n</mml:msub>\n</mml:mrow>\n</mml:mfenced>\n</mml:math>\n<span class="equ"></span></div>\n<p id="p39">where <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m17">\n<mml:msub>\n<mml:mi>x</mml:mi>\n<mml:mi>t</mml:mi>\n</mml:msub>\n</mml:math>\n</span>, <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m18">\n<mml:msub>\n<mml:mi>s</mml:mi>\n<mml:mi>t</mml:mi>\n</mml:msub>\n</mml:math>\n</span>, and <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m19">\n<mml:msub>\n<mml:mi>o</mml:mi>\n<mml:mi>t</mml:mi>\n</mml:msub>\n</mml:math>\n</span> are respectively the input, the hidden state, and the output at time step t and <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m20">\n<mml:mi>U</mml:mi>\n<mml:mo>,</mml:mo>\n<mml:mi>V</mml:mi>\n<mml:mo>,</mml:mo>\n<mml:mi>W</mml:mi>\n</mml:math>\n</span> are parameters matrices.</p>\n</div>\n</div>\n<div class="section" id="sec_14" data-lvl="1">\n<h2 class="heading main-title">4. Experimental results and analysis</h2>\n<div class="section" id="sec_14_2" data-lvl="2">\n<h3 class="heading section-title">4.1 Emotional speech databases</h3>\n<p id="p40">The performance and robustness of the recognition systems will be easily affected if it is not well trained with a suitable database. Therefore, it is essential to have sufficient and suitable phrases in the database to train the emotion recognition system and subsequently evaluate its performance. There are three main types of databases: acted emotions, natural spontaneous emotions, and elicited emotions [<a href="#B27" class="ref-link" data-ref-style="bibr">27</a>, <a href="#B44" class="ref-link" data-ref-style="bibr">44</a>]. In this work, we used an acted emotion databases because they contain strong emotional expressions. The literature on speech emotion recognition [<a href="#B45" class="ref-link" data-ref-style="bibr">45</a>] shows that the majority of studies have been conducted with emotional acted speech. In this section, we detailed the two emotional speech databases used for classifying discrete emotions in our experiments: Berlin Database and Spanish Database.</p>\n</div>\n<div class="section" id="sec_15_2" data-lvl="2">\n<h3 class="heading section-title">4.2 Berlin database</h3>\n<p id="p41">The Berlin database [<a href="#B46" class="ref-link" data-ref-style="bibr">46</a>] is widely used in emotional speech recognition. It contains 535 utterances spoken by 10 actors (5 female, 5 male) in 7 simulated emotions (anger, boredom, disgust, fear, joy, sadness, and neutral). This database was chosen for the following reasons: (i) the quality of its recording is very good, and (ii) it is public [<a href="#B47" class="ref-link" data-ref-style="bibr">47</a>] and popular database of emotion recognition that is recommended in the literature [<a href="#B19" class="ref-link" data-ref-style="bibr">19</a>].</p>\n</div>\n<div class="section" id="sec_16_2" data-lvl="2">\n<h3 class="heading section-title">4.3 Spanish database</h3>\n<p id="p42">The INTER1SP Spanish emotional database contains utterances from two professional actors (one female and one male speaker).The Spanish corpus that we have the right to access (free for academic and research use) [<a href="#B48" class="ref-link" data-ref-style="bibr">48</a>] was recorded twice in the &laquo;six basic emotions plus neutral (anger, sadness, joy, fear, disgust, surprise and neutral/normal)&raquo;. Four additional neutral variations (soft, loud, slow, and fast) were recorded once. This is preferred to other created database because it is available for researchers use and it contains more data (6041 utterances in total). This paper has focused on only seven main emotions from the Spanish database in order to achieve a higher and more accurate rate of recognition and to make the comparison with the Berlin database detailed above.</p>\n</div>\n<div class="section" id="sec_17_2" data-lvl="2">\n<h3 class="heading section-title">4.4 Results and analysis</h3>\n<p id="p43">In this section, experimentation results are presented and discussed. We report the recognition accuracy of using MLR, SVM, and RNN classifiers. Experimental evaluation is performed on the Berlin and Spanish databases. All classification results are obtained under tenfold cross-validation. Cross-validation is a common practice used in performance analysis that randomly partitions the data into N complementary subsets, with <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m21">\n<mml:mi>N</mml:mi>\n<mml:mo>&minus;</mml:mo>\n<mml:mn>1</mml:mn>\n</mml:math>\n</span> of them used for training in each validation and the remaining one used for testing. The neural network structure used is a simple LSTM. It consists of two consecutive LSTM layers with hyperbolic tangent activation followed by two classification dense layers. Features from data are scaled to <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m22">\n<mml:mfenced open="[" close="]" separators=",">\n<mml:mrow>\n<mml:mo>&minus;</mml:mo>\n<mml:mn>1</mml:mn>\n</mml:mrow>\n<mml:mn>1</mml:mn>\n</mml:mfenced>\n</mml:math>\n</span> before applying classifiers. Scaling features before recognition is important, because when a learning phase is fit on unscaled data, it is possible for large inputs to slow down the learning and convergence and in some cases prevent the used classifier from effectively learning for the classification problem. The effect of speaker normalization (SN) step prior to recognition is investigated, and there are three different SN schemes that are defined in [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>]. SN is useful to compensate for the variations due to speaker diversity rather than the change of emotional state. We used in this section the SN scheme that has given the best results in [<a href="#B6" class="ref-link" data-ref-style="bibr">6</a>]. The features of each speaker are normalized with a mean of <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m23">\n<mml:mn>0</mml:mn>\n</mml:math>\n</span> and a standard deviation of <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m24">\n<mml:mn>1</mml:mn>\n</mml:math>\n</span>. <a href="#tab1" class="ref-link" data-ref-style="table">Tables 1</a>, <a href="#tab2" class="ref-link" data-ref-style="table">2</a>, <a href="#tab3" class="ref-link" data-ref-style="table">3</a> show the recognition rate for each combination of various features and classifiers based on Berlin and Spanish databases. These experiments use feature set without feature selection. As shown in <a href="#tab1" class="ref-link" data-ref-style="table">Table 1</a>, SVM classifier yields better results above 81%, with feature combination of MFCC and MS for Berlin database. Our results have improved compared to previous results in [<a href="#B21" class="ref-link" data-ref-style="bibr">21</a>] because we changed the SVM parameters for each type of features to develop a good model.</p>\n<div class="table-wrap" id="tab1"><div class="table-content"><table frame="hsides" rules="groups">\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n<th colspan="7" align="left">Recognition rate (%)</th>\n<th colspan="2"></th>\n</tr>\n<tr>\n<th>Test</th>\n<th align="left">Feature</th>\n<th align="left">Method</th>\n<th align="left">SN</th>\n<th align="left">A</th>\n<th align="left">E</th>\n<th align="left">F</th>\n<th align="left">L</th>\n<th align="left">N</th>\n<th align="left">T</th>\n<th align="left">W</th>\n<th align="left">AVG.</th>\n<th align="left">(<span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m25">\n<mml:mi>&sigma;</mml:mi>\n</mml:math>\n</span>)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan="3">#1</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">MLR</td>\n<td rowspan="3" align="left">No</td>\n<td align="left">45.90</td>\n<td align="left">45.72</td>\n<td align="left">48.78</td>\n<td align="left">77.08</td>\n<td align="left">59.43</td>\n<td align="left">79.91</td>\n<td align="left">75.94</td>\n<td align="left">66.23</td>\n<td align="left">(5.85)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">56.55</td>\n<td align="left">62.28</td>\n<td align="left">45.60</td>\n<td align="left">54.97</td>\n<td align="left">57.35</td>\n<td align="left">74.36</td>\n<td align="left">91.37</td>\n<td align="left">64.70</td>\n<td align="left">(3.20)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">70.26</td>\n<td align="left">73.04</td>\n<td align="left">51.95</td>\n<td align="left">82.44</td>\n<td align="left">69.55</td>\n<td align="left">82.49</td>\n<td align="left">76.55</td>\n<td align="left">73.00</td>\n<td align="left">(3.23)</td>\n</tr>\n<tr>\n<td rowspan="3" align="left">#2</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">SVM</td>\n<td rowspan="3" align="left">No</td>\n<td align="left">56.61</td>\n<td align="left">54.78</td>\n<td align="left">51.17</td>\n<td align="left">70.98</td>\n<td align="left">67.32</td>\n<td align="left">67.50</td>\n<td align="left">73.13</td>\n<td align="left">70.63</td>\n<td align="left">(6.45)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">73.99</td>\n<td align="left">64.14</td>\n<td align="left">64.76</td>\n<td align="left">55.30</td>\n<td align="left">62.28</td>\n<td align="left">84.13</td>\n<td align="left">83.13</td>\n<td align="left">71.70</td>\n<td align="left">(4.24)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">82.03</td>\n<td align="left">68.70</td>\n<td align="left">69.09</td>\n<td align="left">79.16</td>\n<td align="left">76.99</td>\n<td align="left">80.89</td>\n<td align="left">80.63</td>\n<td align="left">81.10</td>\n<td align="left">(2.73)</td>\n</tr>\n<tr>\n<td rowspan="3" align="left">#3</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">MLR</td>\n<td rowspan="3" align="left">Yes</td>\n<td align="left">48.98</td>\n<td align="left">35.54</td>\n<td align="left">32.66</td>\n<td align="left">80.35</td>\n<td align="left">55.54</td>\n<td align="left">88.79</td>\n<td align="left">85.77</td>\n<td align="left">64.20</td>\n<td align="left">(5.27)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">59.71</td>\n<td align="left">59.72</td>\n<td align="left">48.65</td>\n<td align="left">67.10</td>\n<td align="left">67.98</td>\n<td align="left">91.73</td>\n<td align="left">87.51</td>\n<td align="left">71.00</td>\n<td align="left">(4.19)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">72.32</td>\n<td align="left">68.82</td>\n<td align="left">51.98</td>\n<td align="left">82.60</td>\n<td align="left">81.72</td>\n<td align="left">91.96</td>\n<td align="left">80.71</td>\n<td align="left">75.25</td>\n<td align="left">(2.49)</td>\n</tr>\n<tr>\n<td rowspan="3" align="left">#4</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">SVM</td>\n<td rowspan="3" align="left">Yes</td>\n<td align="left">62.72</td>\n<td align="left">49.44</td>\n<td align="left">37.29</td>\n<td align="left">76.14</td>\n<td align="left">71.30</td>\n<td align="left">88.44</td>\n<td align="left">80.15</td>\n<td align="left">71.90</td>\n<td align="left">(2.38)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">70.68</td>\n<td align="left">56.55</td>\n<td align="left">56.99</td>\n<td align="left">59.88</td>\n<td align="left">68.14</td>\n<td align="left">91.88</td>\n<td align="left">85.44</td>\n<td align="left">77.60</td>\n<td align="left">(4.35)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">77.37</td>\n<td align="left">69.67</td>\n<td align="left">58.16</td>\n<td align="left">79.87</td>\n<td align="left">88.57</td>\n<td align="left">98.75</td>\n<td align="left">86.64</td>\n<td align="left">81.00</td>\n<td align="left">(2.45)</td>\n</tr>\n</tbody>\n</table></div><div class="table-caption"><h3 class="heading">Table 1.</h3><div class="text"><p id="p45">Recognition results with MS, MFCC features, and their combination on Berlin database; AVG. denotes average recognition rate; <span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m26">\n<mml:mi>&sigma;</mml:mi>\n</mml:math>\n</span> denotes standard deviation of the 10-cross-validation accuracies.</p></div><div class="text"><p id="p44">Berlin (a, fear; e, disgust; f, happiness; l, boredom; n, neutral; t, sadness; w, anger).</p></div></div></div>\n<div class="table-wrap" id="tab2"><div class="table-content"><table frame="hsides" rules="groups">\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n<th colspan="7" align="left">Recognition rate (%)</th>\n<th></th>\n<th></th>\n</tr>\n<tr>\n<th>Test</th>\n<th align="left">Feature</th>\n<th align="left">Method</th>\n<th align="left">SN</th>\n<th align="left">A</th>\n<th align="left">D</th>\n<th align="left">F</th>\n<th align="left">J</th>\n<th align="left">N</th>\n<th align="left">S</th>\n<th align="left">T</th>\n<th align="left">AVG.</th>\n<th align="left">(<span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m27">\n<mml:mi>&sigma;</mml:mi>\n</mml:math>\n</span>)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan="3">#1</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">MLR</td>\n<td rowspan="3" align="left">No</td>\n<td align="left">67.72</td>\n<td align="left">44.04</td>\n<td align="left">68.78</td>\n<td align="left">46.95</td>\n<td align="left">89.58</td>\n<td align="left">63.10</td>\n<td align="left">78.49</td>\n<td align="left">69.22</td>\n<td align="left">(1.37)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">67.85</td>\n<td align="left">61.41</td>\n<td align="left">75.97</td>\n<td align="left">60.17</td>\n<td align="left">95.79</td>\n<td align="left">71.89</td>\n<td align="left">84.94</td>\n<td align="left">77.21</td>\n<td align="left">(0.76)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">78.75</td>\n<td align="left">78.18</td>\n<td align="left">80.68</td>\n<td align="left">63.84</td>\n<td align="left">96.80</td>\n<td align="left">82.44</td>\n<td align="left">89.01</td>\n<td align="left">83.55</td>\n<td align="left">(0.55)</td>\n</tr>\n<tr>\n<td rowspan="3">#2</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">SVM</td>\n<td rowspan="3" align="left">No</td>\n<td align="left">70.33</td>\n<td align="left">69.38</td>\n<td align="left">78.09</td>\n<td align="left">60.97</td>\n<td align="left">89.25</td>\n<td align="left">69.38</td>\n<td align="left">85.95</td>\n<td align="left">80.98</td>\n<td align="left">(1.09)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">79.93</td>\n<td align="left">79.02</td>\n<td align="left">81.81</td>\n<td align="left">75.71</td>\n<td align="left">93.77</td>\n<td align="left">80.15</td>\n<td align="left">92.01</td>\n<td align="left">90.94</td>\n<td align="left">(0.93)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">84.90</td>\n<td align="left">88.26</td>\n<td align="left">89.44</td>\n<td align="left">80.90</td>\n<td align="left">96.58</td>\n<td align="left">83.89</td>\n<td align="left">95.63</td>\n<td align="left">89.69</td>\n<td align="left">(0.62)</td>\n</tr>\n<tr>\n<td rowspan="3">#3</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">MLR</td>\n<td rowspan="3" align="left">Yes</td>\n<td align="left">64.76</td>\n<td align="left">49.02</td>\n<td align="left">66.87</td>\n<td align="left">44.52</td>\n<td align="left">87.50</td>\n<td align="left">58.26</td>\n<td align="left">78.70</td>\n<td align="left">67.84</td>\n<td align="left">(1.27)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">66.54</td>\n<td align="left">57.83</td>\n<td align="left">74.56</td>\n<td align="left">56.98</td>\n<td align="left">94.02</td>\n<td align="left">72.32</td>\n<td align="left">89.63</td>\n<td align="left">76.47</td>\n<td align="left">(1.51)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">77.01</td>\n<td align="left">78.45</td>\n<td align="left">80.50</td>\n<td align="left">64.18</td>\n<td align="left">94.42</td>\n<td align="left">80.14</td>\n<td align="left">91.29</td>\n<td align="left">83.03</td>\n<td align="left">(0.97)</td>\n</tr>\n<tr>\n<td rowspan="3">#4</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">SVM</td>\n<td rowspan="3" align="left">Yes</td>\n<td align="left">69.81</td>\n<td align="left">70.35</td>\n<td align="left">75.44</td>\n<td align="left">52.60</td>\n<td align="left">86.77</td>\n<td align="left">66.94</td>\n<td align="left">82.57</td>\n<td align="left">78.40</td>\n<td align="left">(1.64)</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">77.45</td>\n<td align="left">77.41</td>\n<td align="left">80.99</td>\n<td align="left">69.47</td>\n<td align="left">91.89</td>\n<td align="left">75.17</td>\n<td align="left">93.50</td>\n<td align="left">87.47</td>\n<td align="left">(0.95)</td>\n</tr>\n<tr>\n<td align="left">MFCC+SM</td>\n<td align="left">85.28</td>\n<td align="left">84.54</td>\n<td align="left">84.49</td>\n<td align="left">73.47</td>\n<td align="left">93.43</td>\n<td align="left">81.79</td>\n<td align="left">94.04</td>\n<td align="left">86.57</td>\n<td align="left">(0.72)</td>\n</tr>\n</tbody>\n</table></div><div class="table-caption"><h3 class="heading">Table 2.</h3><div class="text"><p id="p47">Recognition results with MS, MFCC features, and their combination on Spanish database.</p></div><div class="text"><p id="p46">Spanish (a, anger; d, disgust; f, fear; j, joy; n, neutral; s, surprise; t, sadness).</p></div></div></div>\n<div class="table-wrap" id="tab3"><div class="table-content"><table frame="hsides" rules="groups">\n<col>\n<col>\n<col>\n<col>\n<col>\n<thead>\n<tr>\n<th>Dataset</th>\n<th align="left">Feature</th>\n<th align="left">SN</th>\n<th align="left">Average (avg)</th>\n<th align="left">Standard deviation (<span class="inline-formula">\n<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="m28">\n<mml:mi>&sigma;</mml:mi>\n</mml:math>\n</span>)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan="6">Berlin</td>\n<td align="left">MS</td>\n<td rowspan="2" align="left">No</td>\n<td align="left">66.32</td>\n<td align="left">5.93</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">69.55</td>\n<td align="left">3.91</td>\n</tr>\n<tr>\n<td align="left">MFCC+MS</td>\n<td rowspan="3" align="left">Yes</td>\n<td align="left">63.67</td>\n<td align="left">7.74</td>\n</tr>\n<tr>\n<td align="left">MS</td>\n<td align="left">68.94</td>\n<td align="left">5.65</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">73.08</td>\n<td align="left">5.17</td>\n</tr>\n<tr>\n<td align="left">MFCC+MS</td>\n<td></td>\n<td align="left">76.98</td>\n<td align="left">4.79</td>\n</tr>\n<tr>\n<td rowspan="6">Spanish</td>\n<td align="left">MS</td>\n<td rowspan="3" align="left">No</td>\n<td align="left">82.30</td>\n<td align="left">2.88</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">86.56</td>\n<td align="left">2.80</td>\n</tr>\n<tr>\n<td align="left">MFCC+MS</td>\n<td align="left">90.05</td>\n<td align="left">1.64</td>\n</tr>\n<tr>\n<td align="left">MS</td>\n<td rowspan="3" align="left">Yes</td>\n<td align="left">82.14</td>\n<td align="left">1.67</td>\n</tr>\n<tr>\n<td align="left">MFCC</td>\n<td align="left">86.21</td>\n<td align="left">1.22</td>\n</tr>\n<tr>\n<td align="left">MFCC+MS</td>\n<td align="left">87.02</td>\n<td align="left">0.36</td>\n</tr>\n</tbody>\n</table></div><div class="table-caption"><h3 class="heading">Table 3.</h3><div class="text"><p id="p48">Recognition results using RNN classifier based on Berlin and Spanish databases.</p></div><div class="text"></div></div></div>\n<p id="p49">From <a href="#tab1" class="ref-link" data-ref-style="table">Table 1</a>, it can be concluded that applying SN improves recognition results for Berlin database. But this is not the case for the Spanish database, as demonstrated in <a href="#tab2" class="ref-link" data-ref-style="table">Tables 2</a> and <a href="#tab3" class="ref-link" data-ref-style="table">3</a>. Results are the same with the three different classifiers. This can be explained by the number of speakers in each database. The Berlin database contains 10 different speakers, compared to the Spanish database that contains only two speakers and probably the language impact. As regarding the RNN method, we found that combining both types of features has the worst recognition rate for the Berlin database, as shown in <a href="#tab3" class="ref-link" data-ref-style="table">Table 3</a>. That is because the RNN model has too many parameters (155 coefficients in total) and a poor training data. This is the phenomena of overfitting. This is confirmed by the fact that when we reduced the number of features from 155 to 59 features, the results show an increase of above 13%, as shown in <a href="#tab4" class="ref-link" data-ref-style="table">Table 4</a>. To investigate whether a smaller feature space leads to better recognition performance, we repeated all evaluations on the development set by applying a recursive feature elimination (LR-RFE) for each modality combination. The stability of RFE depends heavily on the type of model that is used for feature ranking at each iteration. In our case, we tested the RFE based on an SVM and regression models; we found that using linear regression provides more stable results. We observed from the previous results that the combination of the features gives the best results. So we applied LR-RFE feature selection only for this combination to improve accuracy. In this work, a total of 155 features were used; best features were chosen from feature selection. Fifty-nine features were selected by RFE feature selection method based on LR from the Berlin database and 110 features from the Spanish database. The corresponding results of LR-RFE can be seen in <a href="#tab4" class="ref-link" data-ref-style="table">Table 4</a>. For most setting using the Spanish database, LR-RFE does not significantly improve the average accuracy. However, for recognition based on Berlin database using the three classifiers, LR-RFE leads to a remarkable performance gain, as shown in <a href="#F5" class="ref-link" data-ref-style="fig">Figure 5</a>. This increases the average of MFCC combined with MS features from 63.67 to 78.11% for RNN classifier. These results are illustrated in <a href="#tab4" class="ref-link" data-ref-style="table">Table 4</a>. For the Spanish database, the feature combination of MFCC and MS after applying LR-RFE selection using RNN has the best recognition rate which is above 94.01%.</p>\n<div class="table-wrap" id="tab4"><div class="table-content"><table frame="hsides" rules="groups">\n<col>\n<col>\n<col>\n<col>\n<col>\n<thead>\n<tr>\n<th>SN</th>\n<th align="left">Classifier</th>\n<th align="left">LR-RFE</th>\n<th align="left">Berlin</th>\n<th align="left">Spanish</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan="6">No</td>\n<td rowspan="2" align="left">MLR</td>\n<td align="left">No</td>\n<td align="left">73.00 (3.23)</td>\n<td align="left">83.55 (0.55)</td>\n</tr>\n<tr>\n<td align="left">Yes</td>\n<td align="left">79.40 (3.09)</td>\n<td align="left">84.19 (0.96)</td>\n</tr>\n<tr>\n<td rowspan="2" align="left">SVM</td>\n<td align="left">No</td>\n<td align="left">81.10 (2.73)</td>\n<td align="left">89.69 (0.62)</td>\n</tr>\n<tr>\n<td align="left">Yes</td>\n<td align="left">80.90 (3.17)</td>\n<td align="left">90.05 (0.80)</td>\n</tr>\n<tr>\n<td rowspan="2" align="left">RNN</td>\n<td align="left">No</td>\n<td align="left">63.67 (7.74)</td>\n<td align="left">90.05 (1.64)</td>\n</tr>\n<tr>\n<td align="left">Yes</td>\n<td align="left">78.11 (3.53)</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">94.01</bold></strong> (0.76)</td>\n</tr>\n<tr>\n<td rowspan="6">Yes</td>\n<td rowspan="2" align="left">MLR</td>\n<td align="left">No</td>\n<td align="left">75.25 (2.49)</td>\n<td align="left">83.03 (0.97)</td>\n</tr>\n<tr>\n<td align="left">Yes</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">83.20</bold></strong> (3.25)</td>\n<td align="left">82.27 (1.12)</td>\n</tr>\n<tr>\n<td rowspan="2" align="left">SVM</td>\n<td align="left">No</td>\n<td align="left">81.00 (2.45)</td>\n<td align="left">86.57 (0.72)</td>\n</tr>\n<tr>\n<td align="left">Yes</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">83.90</bold></strong> (2.46)</td>\n<td align="left">86.47 (1.34)</td>\n</tr>\n<tr>\n<td rowspan="2">RNN</td>\n<td align="left">No</td>\n<td align="left">76.98 (4.79)</td>\n<td align="left">87.02 (0.36)</td>\n</tr>\n<tr>\n<td align="left">Yes</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">83.42</bold></strong> (0.70)</td>\n<td align="left">85.00 (0.93)</td>\n</tr>\n</tbody>\n</table></div><div class="table-caption"><h3 class="heading">Table 4.</h3><div class="text"><p id="p50">Recognition results with combination of MFCC and MS features using ML paradigm before and after applying LR-RFE feature selection method (Berlin and Spanish databases).</p></div><div class="text"></div></div></div>\n<figure class="media-panel" id="F5"><div class="media"><img src="/media/chapter/65993/media/F5.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 5.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p51">Performance comparison of three machine learning paradigms (MLR, SVM, RNN) using speaker normalization (SN) and RFE feature selection (FS), for the Berlin database, is shown.</p></p></figcaption></figure>\n<p id="p52">The confusion matrix for the best recognition of emotions using MFCC and MS features with RNN based on Spanish database is shown in <a href="#tab5" class="ref-link" data-ref-style="table">Table 5</a>. The rate column lists per class recognition rates and precision for a class are the number of samples correctly classified divided by the total number of samples classified to the class. It can be seen that <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Neutral</italic></em> was the emotion that was least difficult to recognize from speech as opposed to <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Disgust</italic></em> which was the most difficult and it forms the most notable confusion pair with <em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Fear</italic></em>.</p>\n<div class="table-wrap" id="tab5"><div class="table-content"><table frame="hsides" rules="groups">\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n<thead>\n<tr>\n<th>Emotion</th>\n<th align="left">Anger</th>\n<th align="left">Disgust</th>\n<th align="left">Fear</th>\n<th align="left">Joy</th>\n<th align="left">Neutral</th>\n<th align="left">Surprise</th>\n<th align="left">Sadness</th>\n<th align="left">Rate (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align="left">Anger</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">79</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">2</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">3</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">91.86</bold></strong></td>\n</tr>\n<tr>\n<td align="left">Disgust</td>\n<td align="left">0</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">67</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">3</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">93.05</bold></strong></td>\n</tr>\n<tr>\n<td align="left">Fear</td>\n<td align="left">0</td>\n<td align="left">3</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">70</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">2</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">93.33</bold></strong></td>\n</tr>\n<tr>\n<td align="left">Joy</td>\n<td align="left">3</td>\n<td align="left">1</td>\n<td align="left">1</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">71</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">93.42</bold></strong></td>\n</tr>\n<tr>\n<td align="left">Neutral</td>\n<td align="left">2</td>\n<td align="left">0</td>\n<td align="left">1</td>\n<td align="left">0</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">156</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">1</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">97.50</bold></strong></td>\n</tr>\n<tr>\n<td align="left">surprise</td>\n<td align="left">2</td>\n<td align="left">1</td>\n<td align="left">0</td>\n<td align="left">3</td>\n<td align="left">0</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">60</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">0</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">92.30</bold></strong></td>\n</tr>\n<tr>\n<td align="left">Sadness</td>\n<td align="left">0</td>\n<td align="left">0</td>\n<td align="left">1</td>\n<td align="left">0</td>\n<td align="left">2</td>\n<td align="left">0</td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">66</bold></strong></td>\n<td align="left"><strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">95.65</bold></strong></td>\n</tr>\n<tr>\n<td align="left">Precision (%)</td>\n<td align="left">91.86</td>\n<td align="left">91.78</td>\n<td align="left">92.10</td>\n<td align="left">94.66</td>\n<td align="left">96.29</td>\n<td align="left">95.23</td>\n<td align="left">94.28</td>\n<td></td>\n</tr>\n</tbody>\n</table></div><div class="table-caption"><h3 class="heading">Table 5.</h3><div class="text"><p id="p53">Confusion matrix for feature combination after LR-RFE selection based on Spanish database.</p></div><div class="text"></div></div></div>\n</div>\n</div>\n<div class="section" id="sec_19" data-lvl="1">\n<h2 class="heading main-title">5. Conclusion</h2>\n<p id="p54">In this current study, we presented an automatic speech emotion recognition (SER) system using three machine learning algorithms (MLR, SVM, and RNN) to classify seven emotions. Thus, two types of features (MFCC and MS) were extracted from two different acted databases (Berlin and Spanish databases), and a combination of these features was presented. In fact, we study how classifiers and features impact recognition accuracy of emotions in speech. A subset of highly discriminant features is selected. Feature selection techniques show that more information is not always good in machine learning applications. The machine learning models were trained and evaluated to recognize emotional states from these features. SER reported the best recognition rate of 94% on the Spanish database using RNN classifier without speaker normalization (SN) and with feature selection (FS). For Berlin database, all of the classifiers achieve an accuracy of 83% when a speaker normalization (SN) and a feature selection (FS) are applied to the features. From this result, we can see that RNN often perform better with more data and it suffers from the problem of very long training times. Therefore, we concluded that the SVM and MLR models have a good potential for practical usage for limited data in comparison with RNN .</p>\n<p id="p55">Enhancement of the robustness of emotion recognition system is still possible by combining databases and by fusion of classifiers. The effect of training multiple emotion detectors can be investigated by fusing these into a single detection system. We aim also to use other feature selection methods because the quality of the feature selection affects the emotion recognition rate: a good emotion feature selection method can select features reflecting emotion state quickly. The overall aim of our work is to develop a system that will be used in a pedagogical interaction in classrooms, in order to help the teacher to orchestrate his class. For achieving this goal, we aim to test the system proposed in this work.</p>\n</div>\n\n',keywords:"speech emotion recognition, feature extraction recurrent neural, network SVM, multivariate linear regression, MFCC, modulation spectral features, machine learning",chapterPDFUrl:"https://cdn.intechopen.com/pdfs/65993.pdf",chapterXML:"https://mts.intechopen.com/source/xml/65993.xml",downloadPdfUrl:"/chapter/pdf-download/65993",previewPdfUrl:"/chapter/pdf-preview/65993",totalDownloads:3123,totalViews:0,totalCrossrefCites:13,totalDimensionsCites:25,hasAltmetrics:1,dateSubmitted:"February 21st 2018",dateReviewed:"January 31st 2019",datePrePublished:"March 25th 2019",datePublished:"February 19th 2020",dateFinished:"March 6th 2019",readingETA:"0",abstract:"This chapter presents a comparative study of speech emotion recognition (SER) systems. Theoretical definition, categorization of affective state and the modalities of emotion expression are presented. To achieve this study, an SER system, based on different classifiers and different methods for features extraction, is developed. Mel-frequency cepstrum coefficients (MFCC) and modulation spectral (MS) features are extracted from the speech signals and used to train different classifiers. Feature selection (FS) was applied in order to seek for the most relevant feature subset. Several machine learning paradigms were used for the emotion classification task. A recurrent neural network (RNN) classifier is used first to classify seven emotions. Their performances are compared later to multivariate linear regression (MLR) and support vector machines (SVM) techniques, which are widely used in the field of emotion recognition for spoken audio signals. Berlin and Spanish databases are used as the experimental data set. This study shows that for Berlin database all classifiers achieve an accuracy of 83% when a speaker normalization (SN) and a feature selection are applied to the features. For Spanish database, the best accuracy (94 %) is achieved by RNN classifier without SN and with FS.",reviewType:"peer-reviewed",bibtexUrl:"/chapter/bibtex/65993",risUrl:"/chapter/ris/65993",book:{slug:"social-media-and-machine-learning"},signatures:"Leila Kerkeni, Youssef Serrestou, Mohamed Mbarki, Kosai Raoof, Mohamed Ali Mahjoub and Catherine Cleder",authors:[{id:"247090",title:"Ph.D. Student",name:"Leila",middleName:null,surname:"Kerkeni",fullName:"Leila Kerkeni",slug:"leila-kerkeni",email:"kerkeni.leila@gmail.com",position:null,institution:null}],sections:[{id:"sec_1",title:"1. Introduction",level:"1"},{id:"sec_2",title:"2. Emotion and classification",level:"1"},{id:"sec_2_2",title:"2.1 Definition",level:"2"},{id:"sec_3_2",title:"2.2 Categorization of emotions",level:"2"},{id:"sec_4_2",title:"2.3 Sensory modalities for emotion expression",level:"2"},{id:"sec_4_3",title:"2.3.1 Facial expressions",level:"3"},{id:"sec_5_3",title:"2.3.2 Speech",level:"3"},{id:"sec_6_3",title:"2.3.3 Physiological signals",level:"3"},{id:"sec_9",title:"3. Speech emotion recognition (SER) system",level:"1"},{id:"sec_9_2",title:"3.1 Block diagram",level:"2"},{id:"sec_10_2",title:"3.2. Feature extraction",level:"2"},{id:"sec_11_2",title:"3.3 Feature selection",level:"2"},{id:"sec_12_2",title:"3.4 Classification methods",level:"2"},{id:"sec_14",title:"4. Experimental results and analysis",level:"1"},{id:"sec_14_2",title:"4.1 Emotional speech databases",level:"2"},{id:"sec_15_2",title:"4.2 Berlin database",level:"2"},{id:"sec_16_2",title:"4.3 Spanish database",level:"2"},{id:"sec_17_2",title:"4.4 Results and analysis",level:"2"},{id:"sec_19",title:"5. Conclusion",level:"1"}],chapterReferences:[{id:"B1",body:'<ref id="B1"><mixed-citation publication-type="journal">Ali H, Hariharan M, Yaacob S, Adom AH. Facial emotion recognition using empirical mode decomposition. Expert Systems with Applications. 2015;<bold>42</bold>(3):1261-1277</mixed-citation>\n</ref>'},{id:"B2",body:'<ref id="B2"><mixed-citation publication-type="journal">Liu ZT, Wu M, Cao WH, Mao JW, Xu JP, Tan GZ. Speech emotion recognition based on feature selection and extreme learning machine decision tree. Neurocomputing. 2018;<bold>273</bold>:271-280</mixed-citation>\n</ref>'},{id:"B3",body:'<ref id="B3"><mixed-citation publication-type="other">Ragot M, Martin N, Em S, Pallamin N, Diverrez JM. Emotion recognition using physiological signals: Laboratory vs. wearable sensors. In: International Conference on Applied Human Factors and Ergonomics. Springer; 2017. pp. 15-22</mixed-citation>\n</ref>'},{id:"B4",body:'<ref id="B4"><mixed-citation publication-type="journal">Surabhi V, Saurabh M. Speech emotion recognition: A review. International Research Journal of Engineering and Technology (IRJET). 2016;<bold>03</bold>:313-316</mixed-citation>\n</ref>'},{id:"B5",body:'<ref id="B5"><mixed-citation publication-type="journal">Wu S, Falk TH, Chan WY. Automatic speech emotion recognition using modulation spectral features. Speech Communication. 2011;<bold>53</bold>:768-785</mixed-citation>\n</ref>'},{id:"B6",body:'<ref id="B6"><mixed-citation publication-type="other">Wu S. Recognition of human emotion in speech using modulation spectral features and support vector machines [PhD thesis]. 2009</mixed-citation>\n</ref>'},{id:"B7",body:'<ref id="B7"><mixed-citation publication-type="journal">Tang J, Alelyani S, Liu H. Feature selection for classification: A review. Data Classification: Algorithms and Applications. 2014:37</mixed-citation>\n</ref>'},{id:"B8",body:'<ref id="B8"><mixed-citation publication-type="journal">Martin V, Robert V. Recognition of emotions in German speech using Gaussian mixture models. LNAI. 2009;<bold>5398</bold>:256-263</mixed-citation>\n</ref>'},{id:"B9",body:'<ref id="B9"><mixed-citation publication-type="journal">Ingale AB, Chaudhari D. Speech emotion recognition using hidden Markov model and support vector machine. International Journal of Advanced Engineering Research and Studies. 2012:316-318</mixed-citation>\n</ref>'},{id:"B10",body:'<ref id="B10"><mixed-citation publication-type="journal">Milton A, Sharmy Roy S, Tamil Selvi S. SVM scheme for speech emotion recognition using MFCC feature. International Journal of Computer Applications. 2013;<bold>69</bold></mixed-citation>\n</ref>'},{id:"B11",body:'<ref id="B11"><mixed-citation publication-type="journal">Divya Sree GS, Chandrasekhar P, Venkateshulu B. SVM based speech emotion recognition compared with GMM-UBM and NN. IJESC. 2016;<bold>6</bold></mixed-citation>\n</ref>'},{id:"B12",body:'<ref id="B12"><mixed-citation publication-type="journal">Melki G, Kecman V, Ventura S, Cano A. OLLAWV: Online learning algorithm using worst-violators. Applied Soft Computing. 2018;<bold>66</bold>:384-393</mixed-citation>\n</ref>'},{id:"B13",body:'<ref id="B13"><mixed-citation publication-type="journal">Pan Y, Shen P, Shen L. Speech emotion recognition using support vector machine. International Journal of Smart Home. 2012;<bold>6</bold>:101-108</mixed-citation>\n</ref>'},{id:"B14",body:'<ref id="B14"><mixed-citation publication-type="other">Peipei S, Zhou C, Xiong C. Automatic speech emotion recognition using support vector machine. IEEE. 2011;<bold>2</bold>:621-625</mixed-citation>\n</ref>'},{id:"B15",body:'<ref id="B15"><mixed-citation publication-type="other">Sathit P. Improvement of speech emotion recognition with neural network classifier by using speech spectrogram. International Conference on Systems, Signals and Image Processing (IWSSIP). 2015:73-76</mixed-citation>\n</ref>'},{id:"B16",body:'<ref id="B16"><mixed-citation publication-type="other">Alex G, Navdeep J. Towards end-to-end speech recognition with recurrent neural networks. In: International Conference on Machine Learning. Vol. 32. 2014</mixed-citation>\n</ref>'},{id:"B17",body:'<ref id="B17"><mixed-citation publication-type="book">Chen S, Jin Q. Multi-Modal Dimensional Emotion Recognition using Recurrent Neural Networks. Australia: Brisbane; 2015</mixed-citation>\n</ref>'},{id:"B18",body:'<ref id="B18"><mixed-citation publication-type="journal">Lim W, Jang D, Lee T. Speech emotion recognition using convolutional and recurrent neural networks. Asia-Pacific. 2017:1-4</mixed-citation>\n</ref>'},{id:"B19",body:'<ref id="B19"><mixed-citation publication-type="book">Sara M, Saeed S, Rabiee A. Speech Emotion Recognition Based on a Modified Brain Emotional Learning Model. Biologically inspired cognitive architectures. Elsevier; 2017;<bold>19</bold>:32-38</mixed-citation>\n</ref>'},{id:"B20",body:'<ref id="B20"><mixed-citation publication-type="journal">Yu G, Eric P, Hai-Xiang L, van den HJ. Speech emotion recognition using voiced segment selection algorithm. ECAI. 2016;<bold>285</bold>:1682-1683</mixed-citation>\n</ref>'},{id:"B21",body:'<ref id="B21"><mixed-citation publication-type="other">Kerkeni L, Serrestou Y, Mbarki M, Mahjoub M, Raoof K. Speech emotion recognition: Methods and cases study. In: International Conference on Agents and Artificial Intelligence (ICAART); 2018</mixed-citation>\n</ref>'},{id:"B22",body:'<ref id="B22"><mixed-citation publication-type="journal">Cabanac M. What is emotion? Behavioural Processes. 2002;<bold>60</bold>(2):69-83</mixed-citation>\n</ref>'},{id:"B23",body:'<ref id="B23"><mixed-citation publication-type="other">Schacter DL, Gilbert DT, Wegner DM. Psychology (2nd Edition). New York: Worth; 2011</mixed-citation>\n</ref>'},{id:"B24",body:'<ref id="B24"><mixed-citation publication-type="book">Barrett LF, Russell JA. The Psychological Construction of Emotion. Guilford Publications; 2014</mixed-citation>\n</ref>'},{id:"B25",body:'<ref id="B25"><mixed-citation publication-type="journal">James W. What is an emotion? Mind. 1884;<bold>9</bold>(34):188-205</mixed-citation>\n</ref>'},{id:"B26",body:'<ref id="B26"><mixed-citation publication-type="other">Boekaerts M. The Crucial Role of Motivation and Emotion in Classroom Learning. The Nature of Learning: Using Research to Inspire Practice 2010. Paris: OECD Publishing; pp. 91-111</mixed-citation>\n</ref>'},{id:"B27",body:'<ref id="B27"><mixed-citation publication-type="other">Kerkeni L, Serrestou Y, Mbarki M, Raoof K, Mahjoub MA. A review on speech emotion recognition: Case of pedagogical interaction in classroom. In: 2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP). IEEE; 2017. pp. 1-7</mixed-citation>\n</ref>'},{id:"B28",body:'<ref id="B28"><mixed-citation publication-type="journal">Ekman P. An argument for basic emotions. Cognition &amp; Emotion. 1992;<bold>6</bold>(3–4):169-200</mixed-citation>\n</ref>'},{id:"B29",body:'<ref id="B29"><mixed-citation publication-type="journal">Matilda S. Emotion recognition: A survey. International Journal of Advanced Computer Research. 2015;<bold>3</bold>(1):14-19</mixed-citation>\n</ref>'},{id:"B30",body:'<ref id="B30"><mixed-citation publication-type="journal">Koolagudi SG, Rao KS. Emotion recognition from speech: A review. International Journal of Speech Technology. 2012;<bold>15</bold>(2):99-117</mixed-citation>\n</ref>'},{id:"B31",body:'<ref id="B31"><mixed-citation publication-type="journal">Schirmer A, Adolphs R. Emotion perception from face, voice, and touch: Comparisons and convergence. Trends in Cognitive Sciences. 2017;<bold>21</bold>(3):216-228</mixed-citation>\n</ref>'},{id:"B32",body:'<ref id="B32"><mixed-citation publication-type="book">He C, Yao Yj, Ye Xs. An emotion recognition system based on physiological signals obtained by wearable sensors. In: Wearable Sensors and Robots. Springer; 2017. pp. 15-25</mixed-citation>\n</ref>'},{id:"B33",body:'<ref id="B33"><mixed-citation publication-type="other">Srinivasan V, Ramalingam V, Arulmozhi P. Artificial Neural Network Based Pathological Voice Classification Using MFCC Features. International Journal of Science, Environment and Technology (Citeseer). 2014;<bold>3</bold>:291-302</mixed-citation>\n</ref>'},{id:"B34",body:'<ref id="B34"><mixed-citation publication-type="other">Aha DW, Bankert RL. Feature selection for case-based classification of cloud types: An empirical comparison. In: Proceedings of the AAAI-94 Workshop on Case-Based Reasoning. Vol. 106. 1994. p. 112</mixed-citation>\n</ref>'},{id:"B35",body:'<ref id="B35"><mixed-citation publication-type="journal">Song P, Zheng W. Feature selection based transfer subspace learning for speech emotion recognition. IEEE Transactions on Affective Computing. 2018</mixed-citation>\n</ref>'},{id:"B36",body:'<ref id="B36"><mixed-citation publication-type="journal">Duan KB, Rajapakse JC, Wang H, Azuaje F. Multiple SVM-RFE for gene selection in cancer classification with expression data. IEEE Transactions on NanoBioscience. 2005;<bold>4</bold>(3):228-234</mixed-citation>\n</ref>'},{id:"B37",body:'<ref id="B37"><mixed-citation publication-type="journal">Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. SCIKIT-learn: Machine learning in Python. Journal of Machine Learning Research. 2011;<bold>12</bold>:2825-2830</mixed-citation>\n</ref>'},{id:"B38",body:'<ref id="B38"><mixed-citation publication-type="journal">Guyon I, Weston J, Barnhill S, Vapnik V. Gene selection for cancer classification using support vector machines. Machine Learning. 2002;<bold>46</bold>(1–3):389-422</mixed-citation>\n</ref>'},{id:"B39",body:'<ref id="B39"><mixed-citation publication-type="journal">Naseem I, Togneri R, Bennamoun M. Linear regression for face recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence. 2010;<bold>32</bold>:2106-2112</mixed-citation>\n</ref>'},{id:"B40",body:'<ref id="B40"><mixed-citation publication-type="other">Gunn SR. Support vector machines for classification and regression [PhD thesis]. 1998</mixed-citation>\n</ref>'},{id:"B41",body:'<ref id="B41"><mixed-citation publication-type="other">SVM and Kernel Methods MATLAB Toolbox. Available from: <ext-link ext-link-type="uri" xlink:href="http://asi.insa-rouen.fr/enseignants/∼arakoto/toolbox/">http://asi.insa-rouen.fr/enseignants/</ext-link>\n<ext-link ext-link-type="uri" xlink:href="http://asi.insa-rouen.fr/enseignants/∼arakoto/toolbox/">∼arakoto/toolbox/</ext-link>\n</mixed-citation>\n</ref>'},{id:"B42",body:'<ref id="B42"><mixed-citation publication-type="other">Parthasarathy S, Tashev I. Convolutional neural network techniques for speech emotion recognition. In: 2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC). IEEE; 2018. pp. 121-125</mixed-citation>\n</ref>'},{id:"B43",body:'<ref id="B43"><mixed-citation publication-type="journal">Sepp H, Jurgen S. Long Short-term Memory. Neural Computation. 1997;<bold>9</bold>:1735-1780</mixed-citation>\n</ref>'},{id:"B44",body:'<ref id="B44"><mixed-citation publication-type="other">Vaudable C. Analyse et reconnaissance des émotions lors de conversations de centres d’appels [PhD thesis]. Université Paris Sud-Paris XI; 2012</mixed-citation>\n</ref>'},{id:"B45",body:'<ref id="B45"><mixed-citation publication-type="journal">Swain M, Routray A, Kabisatpathy P. Databases, features and classifiers for speech emotion recognition: A review. International Journal of Speech Technology. 2018;<bold>21</bold>:1-28</mixed-citation>\n</ref>'},{id:"B46",body:'<ref id="B46"><mixed-citation publication-type="book">Burkhardt F, Paeschke A, Rolfes M, Sendlmeier W, Weiss B. A Database of German Emotional Speech. INTERSPEECH; 2005</mixed-citation>\n</ref>'},{id:"B47",body:'<ref id="B47"><mixed-citation publication-type="other">Berlin Database of Emotional Speech. Available from: <ext-link ext-link-type="uri" xlink:href="http://emodb.bilderbar.info/start.html">http://emodb.bilderbar.info/start.html</ext-link>\n</mixed-citation>\n</ref>'},{id:"B48",body:'<ref id="B48"><mixed-citation publication-type="other">Berlin Database of Emotional Speech. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.elra.info/en/catalogues/catalogue-language-resources/">http://www.elra.info/en/catalogues/ catalogue-language-resources/</ext-link>\n</mixed-citation>\n</ref>'}],footnotes:[],contributors:[{corresp:"yes",contributorFullName:"Leila Kerkeni",address:"kerkeni.leila@gmail.com",affiliation:'<ul class="list"><li>LAUM UMR CNRS 6613, Le Mans Université, France</li><li>LATIS Lab, ENISo Université de Sousse, Tunisia</li></ul>'},{corresp:null,contributorFullName:"Youssef Serrestou",address:null,affiliation:'<ul class="list"><li>LAUM UMR CNRS 6613, Le Mans Université, France</li></ul>'},{corresp:null,contributorFullName:"Mohamed Mbarki",address:null,affiliation:'<ul class="list"><li>ISSAT, Université de Sousse, Tunisia</li></ul>'},{corresp:null,contributorFullName:"Kosai Raoof",address:null,affiliation:'<ul class="list"><li>LAUM UMR CNRS 6613, Le Mans Université, France</li></ul>'},{corresp:null,contributorFullName:"Mohamed Ali Mahjoub",address:null,affiliation:'<ul class="list"><li>LATIS Lab, ENISo Université de Sousse, Tunisia</li></ul>'},{corresp:null,contributorFullName:"Catherine Cleder",address:null,affiliation:'<ul class="list"><li>CREN Lab, Université de Nantes, France</li></ul>'}],corrections:null},book:{id:"8141",title:"Social Media and Machine Learning",subtitle:null,fullTitle:"Social Media and Machine Learning",slug:"social-media-and-machine-learning",publishedDate:"February 19th 2020",bookSignature:"Alberto Cano",coverURL:"https://cdn.intechopen.com/books/images_new/8141.jpg",licenceType:"CC BY 3.0",editedByType:"Edited by",isbn:"978-1-78984-028-5",printIsbn:"978-1-78984-027-8",pdfIsbn:"978-1-83880-616-3",editors:[{id:"200724",title:"Dr.",name:"Alberto",middleName:null,surname:"Cano",slug:"alberto-cano",fullName:"Alberto Cano"}],productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"},chapters:[{id:"70687",title:"Introductory Chapter: Data Streams and Online Learning in Social Media",slug:"introductory-chapter-data-streams-and-online-learning-in-social-media",totalDownloads:434,totalCrossrefCites:0,signatures:"Alberto Cano",authors:[{id:"200724",title:"Dr.",name:"Alberto",middleName:null,surname:"Cano",fullName:"Alberto Cano",slug:"alberto-cano"}]},{id:"65993",title:"Automatic Speech Emotion Recognition Using Machine Learning",slug:"automatic-speech-emotion-recognition-using-machine-learning",totalDownloads:3123,totalCrossrefCites:13,signatures:"Leila Kerkeni, Youssef Serrestou, Mohamed Mbarki, Kosai Raoof, Mohamed Ali Mahjoub and Catherine Cleder",authors:[{id:"247090",title:"Ph.D. Student",name:"Leila",middleName:null,surname:"Kerkeni",fullName:"Leila Kerkeni",slug:"leila-kerkeni"}]},{id:"67538",title:"A Case Study of Using Big Data Processing in Education: Method of Matching Members by Optimizing Collaborative Learning Environment",slug:"a-case-study-of-using-big-data-processing-in-education-method-of-matching-members-by-optimizing-coll",totalDownloads:722,totalCrossrefCites:3,signatures:"Keiko Tsujioka",authors:[{id:"276365",title:"M.A.",name:"Keiko",middleName:null,surname:"Tsujioka",fullName:"Keiko Tsujioka",slug:"keiko-tsujioka"}]},{id:"69743",title:"Literature Review on Big Data Analytics Methods",slug:"literature-review-on-big-data-analytics-methods",totalDownloads:962,totalCrossrefCites:1,signatures:"Iman Raeesi Vanani and Setareh Majidian",authors:[{id:"296037",title:"Mrs.",name:"Setareh",middleName:null,surname:"Majidian",fullName:"Setareh Majidian",slug:"setareh-majidian"},{id:"296039",title:"Dr.",name:"Iman",middleName:null,surname:"Raeesi Vanaei",fullName:"Iman Raeesi Vanaei",slug:"iman-raeesi-vanaei"}]},{id:"70437",title:"Information and Communication-Based Collaborative Learning and Behavior Modeling Using Machine Learning Algorithm",slug:"information-and-communication-based-collaborative-learning-and-behavior-modeling-using-machine-learn",totalDownloads:425,totalCrossrefCites:0,signatures:"Nityashree Nadar and R. Kamatchi",authors:[{id:"313995",title:"Dr.",name:"Anil",middleName:null,surname:"Kumar",fullName:"Anil Kumar",slug:"anil-kumar"}]}]},relatedBooks:[{type:"book",id:"1358",title:"Knowledge-Oriented Applications in Data Mining",subtitle:null,isOpenForSubmission:!1,hash:"ab9e02a9453e1c7bd85182eb3f322e11",slug:"knowledge-oriented-applications-in-data-mining",bookSignature:"Kimito Funatsu",coverURL:"https://cdn.intechopen.com/books/images_new/1358.jpg",editedByType:"Edited by",editors:[{id:"16715",title:"Prof.",name:"Kimito",surname:"Funatsu",slug:"kimito-funatsu",fullName:"Kimito Funatsu"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"},chapters:[{id:"13157",title:"Data Mining Classification Techniques for Human Talent Forecasting",slug:"data-mining-classification-techniques-for-human-talent-forecasting",signatures:"Hamidah Jantan, Abdul Razak Hamdan and Zulaiha Ali Othman",authors:[{id:"16517",title:"Dr.",name:"Hamidah",middleName:null,surname:"Jantan",fullName:"Hamidah Jantan",slug:"hamidah-jantan"}]},{id:"13158",title:"New Implementations of Data Mining in a Plethora of Human Activities",slug:"new-implementations-of-data-mining-in-a-plethora-of-human-activities",signatures:"Alberto Ochoa, Julio Ponce, Francisco Ornelas, Rubén Jaramillo, Ramón Zataraín, María Barrón, Claudia Gómez, José Martínez and Arturo Elias",authors:[{id:"2944",title:"Dr.",name:"Alberto",middleName:null,surname:"Ochoa",fullName:"Alberto Ochoa",slug:"alberto-ochoa"}]},{id:"13159",title:"Data Mining Techniques for Explaining Social Events",slug:"data-mining-techniques-for-explaining-social-events",signatures:"Krivec Jana and Gams Matjaz",authors:[{id:"16089",title:"Dr.",name:"Jana",middleName:null,surname:"Krivec",fullName:"Jana Krivec",slug:"jana-krivec"},{id:"16782",title:"PhD.",name:"Matjaž",middleName:null,surname:"Gams",fullName:"Matjaž Gams",slug:"matjaz-gams"}]},{id:"13160",title:"Mining Enrollment Data Using Descriptive and Predictive Approaches",slug:"mining-enrollment-data-using-descriptive-and-predictive-approaches",signatures:"Fadzilah Siraj and Mansour Ali Abdoulha",authors:[{id:"17159",title:"Dr.",name:"Fadzilah",middleName:null,surname:"Siraj",fullName:"Fadzilah Siraj",slug:"fadzilah-siraj"}]},{id:"13161",title:"Online Insurance Consumer Targeting and Lifetime Value Evaluating - A Mathematics and Data Mining Approach",slug:"online-insurance-consumer-targeting-and-lifetime-value-evaluating-a-mathematics-and-data-mining-appr",signatures:"Yuanya Li, Gail Cook and Oliver Wreford",authors:[{id:"14395",title:"Dr.",name:"Yuanya",middleName:null,surname:"Li",fullName:"Yuanya Li",slug:"yuanya-li"}]},{id:"13162",title:"Data Mining Using RFM Analysis",slug:"data-mining-using-rfm-analysis",signatures:"Derya Birant",authors:[{id:"15609",title:"Dr.",name:"Derya",middleName:null,surname:"Birant",fullName:"Derya Birant",slug:"derya-birant"}]},{id:"13163",title:"Seasonal Climate Prediction for the Australian Sugar Industry Using Data Mining Techniques",slug:"seasonal-climate-prediction-for-the-australian-sugar-industry-using-data-mining-techniques",signatures:"Lachlan Mckinna and Yvette Everingham",authors:[{id:"16244",title:"Dr.",name:"Yvette",middleName:null,surname:"Everingham",fullName:"Yvette Everingham",slug:"yvette-everingham"},{id:"16245",title:"Prof.",name:"Lachlan",middleName:null,surname:"McKinna",fullName:"Lachlan McKinna",slug:"lachlan-mckinna"}]},{id:"13164",title:"Monthly River Flow Forecasting by Data Mining Process",slug:"monthly-river-flow-forecasting-by-data-mining-process",signatures:"Özlem Terzi",authors:[{id:"15161",title:"Dr.",name:"Özlem",middleName:null,surname:"Terzi",fullName:"Özlem Terzi",slug:"ozlem-terzi"}]},{id:"13165",title:"Monitoring of Water Quality Using Remote Sensing Data Mining",slug:"monitoring-of-water-quality-using-remote-sensing-data-mining",signatures:"Xing-Ping Wen and Xiao-Feng Yang",authors:[{id:"15632",title:"Dr.",name:"Xing-Ping",middleName:null,surname:"Wen",fullName:"Xing-Ping Wen",slug:"xing-ping-wen"}]},{id:"13166",title:"Applications of Data Mining to Diagnosis and Control of Manufacturing Processes",slug:"applications-of-data-mining-to-diagnosis-and-control-of-manufacturing-processes",signatures:"Marcin Perzyk, Robert Biernacki, Andrzej Kochanski, Jacek Kozlowski and Artur Soroczynski",authors:[{id:"14269",title:"Prof.",name:"Marcin",middleName:null,surname:"Perzyk",fullName:"Marcin Perzyk",slug:"marcin-perzyk"},{id:"16475",title:"Dr.",name:"Robert",middleName:null,surname:"Biernacki",fullName:"Robert Biernacki",slug:"robert-biernacki"},{id:"16476",title:"Dr.",name:"Andrzej",middleName:null,surname:"Kochanski",fullName:"Andrzej Kochanski",slug:"andrzej-kochanski"},{id:"16477",title:"Dr.",name:"Jacek",middleName:null,surname:"Kozlowski",fullName:"Jacek Kozlowski",slug:"jacek-kozlowski"},{id:"16478",title:"MSc.",name:"Artur",middleName:null,surname:"Soroczynski",fullName:"Artur Soroczynski",slug:"artur-soroczynski"}]},{id:"13167",title:"Atom Coloring for Chemical Interpretation and De Novo Design for Molecular Design",slug:"atom-coloring-for-chemical-interpretation-and-de-novo-design-for-molecular-design",signatures:"Kiyoshi Hasegawa, Keiya Migita and Kimito Funatsu",authors:[{id:"16715",title:"Prof.",name:"Kimito",middleName:null,surname:"Funatsu",fullName:"Kimito Funatsu",slug:"kimito-funatsu"},{id:"16823",title:"Dr.",name:"Kiyoshi",middleName:null,surname:"Hasegawa",fullName:"Kiyoshi Hasegawa",slug:"kiyoshi-hasegawa"},{id:"16824",title:"Prof.",name:"Keiya",middleName:null,surname:"Migita",fullName:"Keiya Migita",slug:"keiya-migita"}]},{id:"13168",title:"Hyperspectral Data Analysis and Visualization",slug:"hyperspectral-data-analysis-and-visualization",signatures:"Maarten A. Hogervorst and Piet B.W. Schwering",authors:[{id:"10060",title:"Dr.",name:"Maarten",middleName:"Andreas",surname:"Hogervorst",fullName:"Maarten Hogervorst",slug:"maarten-hogervorst"},{id:"24678",title:"Dr.",name:"Piet B.W.",middleName:null,surname:"Schwering",fullName:"Piet B.W. Schwering",slug:"piet-b.w.-schwering"}]},{id:"13169",title:"Data Retrieval and Visualization for Setting Research Priorities in Biomedical Research",slug:"data-retrieval-and-visualization-for-setting-research-priorities-in-biomedical-research",signatures:"Hailin Chen and Vincent VanBuren",authors:[{id:"16710",title:"Dr.",name:"Vincent",middleName:null,surname:"VanBuren",fullName:"Vincent VanBuren",slug:"vincent-vanburen"},{id:"16714",title:"Dr.",name:"Hailin",middleName:null,surname:"Chen",fullName:"Hailin Chen",slug:"hailin-chen"}]},{id:"13170",title:"DNA Microarray Applied to Data Mining of Bradyrhizobium Elkanii Genome and Prospection of Active Genes",slug:"dna-microarray-applied-to-data-mining-of-bradyrhizobium-elkanii-genome-and-prospection-of-active-gen",signatures:"Jackson Marcondes and Eliana G. M. Lemos",authors:[{id:"16604",title:"Dr.",name:"Jackson",middleName:null,surname:"Marcondes de Souza",fullName:"Jackson Marcondes de Souza",slug:"jackson-marcondes-de-souza"},{id:"16609",title:"Prof.",name:"Eliana Gertudes",middleName:null,surname:"Macedo Lemos",fullName:"Eliana Gertudes Macedo Lemos",slug:"eliana-gertudes-macedo-lemos"}]},{id:"13171",title:"Visual Gene Ontology Based Knowledge Discovery in Functional Genomics",slug:"visual-gene-ontology-based-knowledge-discovery-in-functional-genomics",signatures:"Stefan Götz and Ana Conesa",authors:[{id:"16874",title:"Dr.",name:"Ana",middleName:null,surname:"Conesa",fullName:"Ana Conesa",slug:"ana-conesa"},{id:"16876",title:"Dr.",name:"Stefan",middleName:null,surname:"Götz",fullName:"Stefan Götz",slug:"stefan-gotz"}]},{id:"13172",title:"Data Mining in Neurology",slug:"data-mining-in-neurology",signatures:"Antonio Candelieri, Giuliano Dolce, Francesco Riganello and Walter G Sannita",authors:[{id:"15010",title:"Dr.",name:"Antonio",middleName:null,surname:"Candelieri",fullName:"Antonio Candelieri",slug:"antonio-candelieri"},{id:"15156",title:"Prof.",name:"Walter G.",middleName:null,surname:"Sannita",fullName:"Walter G. Sannita",slug:"walter-g.-sannita"},{id:"16397",title:"Dr.",name:"Giuliano",middleName:null,surname:"Dolce",fullName:"Giuliano Dolce",slug:"giuliano-dolce"},{id:"16407",title:"Dr.",name:"Francesco",middleName:null,surname:"Riganello",fullName:"Francesco Riganello",slug:"francesco-riganello"}]},{id:"13173",title:"Glucose Prediction in Type 1 and Type 2 Diabetic Patients Using Data Driven Techniques",slug:"glucose-prediction-in-type-1-and-type-2-diabetic-patients-using-data-driven-techniques",signatures:"Eleni I. Georga, Vasilios C. Protopappas and Dimitrios I. Fotiadis",authors:[{id:"14138",title:"Prof.",name:"Eleni",middleName:null,surname:"Georga",fullName:"Eleni Georga",slug:"eleni-georga"},{id:"16827",title:"Dr.",name:"Vasilios C.",middleName:null,surname:"Protopappas",fullName:"Vasilios C. Protopappas",slug:"vasilios-c.-protopappas"},{id:"16828",title:"Prof",name:"Dimitrios",middleName:null,surname:"Fotiadis",fullName:"Dimitrios Fotiadis",slug:"dimitrios-fotiadis"}]},{id:"13174",title:"Data Mining Based Establishment and Evaluation of Porcine Model for Syndrome in Traditional Chinese Medicine in the Context of Unstable Angina (Myocardial Ischemia)",slug:"data-mining-based-establishment-and-evaluation-of-porcine-model-for-syndrome-in-traditional-chinese-",signatures:"Huihui Zhao, Jianxin Chen, Qi Shi and Wei Wang",authors:[{id:"14611",title:"Dr.",name:"Jianxin",middleName:null,surname:"Chen",fullName:"Jianxin Chen",slug:"jianxin-chen"},{id:"16390",title:"Prof.",name:"Wei",middleName:null,surname:"Wang",fullName:"Wei Wang",slug:"wei-wang"},{id:"23733",title:"Dr.",name:"Qi",middleName:null,surname:"Shi",fullName:"Qi Shi",slug:"qi-shi"},{id:"23735",title:"Dr.",name:"Huihui",middleName:null,surname:"Zhao",fullName:"Huihui Zhao",slug:"huihui-zhao"}]},{id:"13175",title:"Results of Data Mining Technique Applied to a Home Enteral Nutrition Database",slug:"results-of-data-mining-technique-applied-to-a-home-enteral-nutrition-database",signatures:"Maria Eliana M. Shieferdecker, Carlos Henrique Kuretzki, José Simão de Paula Pinto, Antônio Carlos Ligoki Campos and Osvaldo Malafaia",authors:[{id:"16855",title:"Dr.",name:"Antonio Carlos",middleName:"L.",surname:"Campos",fullName:"Antonio Carlos Campos",slug:"antonio-carlos-campos"},{id:"16868",title:"Ph.D.",name:"Maria Eliana",middleName:null,surname:"Schieferdecker",fullName:"Maria Eliana Schieferdecker",slug:"maria-eliana-schieferdecker"},{id:"16869",title:"MSc",name:"Carlos",middleName:"Henrique",surname:"Kuretzki",fullName:"Carlos Kuretzki",slug:"carlos-kuretzki"},{id:"16870",title:"Dr.",name:"José Simão",middleName:"De Paula",surname:"Pinto",fullName:"José Simão Pinto",slug:"jose-simao-pinto"},{id:"16871",title:"Dr.",name:"Osvaldo",middleName:null,surname:"Malafaia",fullName:"Osvaldo Malafaia",slug:"osvaldo-malafaia"}]},{id:"13176",title:"Data Mining in Personalized Speech Disorders Therapy Optimization",slug:"data-mining-in-personalized-speech-disorders-therapy-optimization",signatures:"Danubianu Mirela, Tobolcea Iolanda and Stefan Gheorghe Pentiuc",authors:[{id:"16634",title:"Prof.",name:"Mirela",middleName:null,surname:"Danubianu",fullName:"Mirela Danubianu",slug:"mirela-danubianu"},{id:"16909",title:"Prof.",name:"Iolanda",middleName:null,surname:"Tobolcea",fullName:"Iolanda Tobolcea",slug:"iolanda-tobolcea"},{id:"24109",title:"Prof.",name:"Stefan Gheorghe",middleName:null,surname:"Pentiuc",fullName:"Stefan Gheorghe Pentiuc",slug:"stefan-gheorghe-pentiuc"}]},{id:"13177",title:"Data Mining Method For Energy System Aplications",slug:"data-mining-method-for-energy-system-aplications",signatures:"Reşat Selbaş, Arzu Şencan and Ecir U. Küçüksille",authors:[{id:"15617",title:"Dr.",name:"Reşat",middleName:null,surname:"Selbaş",fullName:"Reşat Selbaş",slug:"resat-selbas"},{id:"15889",title:"Dr.",name:"Arzu",middleName:null,surname:"Şencan",fullName:"Arzu Şencan",slug:"arzu-sencan"},{id:"15890",title:"Dr.",name:"Ecir U.",middleName:null,surname:"Küçüksille",fullName:"Ecir U. Küçüksille",slug:"ecir-u.-kucuksille"}]},{id:"13178",title:"Regression",slug:"regression",signatures:"Mohsen Hajsalehi Sichani and Saeed khalafinejad",authors:[{id:"16248",title:"Dr.",name:"Mohsen",middleName:null,surname:"Hajsalehi Sichani",fullName:"Mohsen Hajsalehi Sichani",slug:"mohsen-hajsalehi-sichani"},{id:"23381",title:"MSc.",name:"Saeed",middleName:null,surname:"Khalafinejad",fullName:"Saeed Khalafinejad",slug:"saeed-khalafinejad"}]},{id:"13179",title:"Data Mining: Machine Learning and Statistical Techniques",slug:"data-mining-machine-learning-and-statistical-techniques",signatures:"Alfonso Palmer, Rafael Jiménez and Elena Gervilla",authors:[{id:"15429",title:"Dr.",name:"Alfonso",middleName:null,surname:"Palmer Pol",fullName:"Alfonso Palmer Pol",slug:"alfonso-palmer-pol"},{id:"16667",title:"Prof.",name:"Rafael",middleName:null,surname:"Jiménez López",fullName:"Rafael Jiménez López",slug:"rafael-jimenez-lopez"},{id:"16668",title:"Prof.",name:"Elena",middleName:null,surname:"Gervilla García",fullName:"Elena Gervilla García",slug:"elena-gervilla-garcia"}]},{id:"13180",title:"Dynamic Data Mining: Synergy of Bio-Inspired Clustering Methods",slug:"dynamic-data-mining-synergy-of-bio-inspired-clustering-methods",signatures:"Elena N. Benderskaya and Sofya V. Zhukova",authors:[{id:"14041",title:"Dr.",name:"Sofya",middleName:null,surname:"Zhukova",fullName:"Sofya Zhukova",slug:"sofya-zhukova"},{id:"14046",title:"Dr.",name:"Elena",middleName:null,surname:"Benderskaya",fullName:"Elena Benderskaya",slug:"elena-benderskaya"}]},{id:"13181",title:"Exploiting Inter-Sample Information and Exploring Visualization in Data Mining: from Bioinformatics to Anthropology and Aesthetics Disciplines",slug:"exploiting-inter-sample-information-and-exploring-visualization-in-data-mining-from-bioinformatics-t",signatures:"Kuan-Ming Lin and Jung-Hua Liu",authors:[{id:"14835",title:"Dr.",name:"Kuan-Ming",middleName:null,surname:"Lin",fullName:"Kuan-Ming Lin",slug:"kuan-ming-lin"},{id:"16764",title:"Prof.",name:"Jung-Hua",middleName:null,surname:"Liu",fullName:"Jung-Hua Liu",slug:"jung-hua-liu"}]},{id:"13182",title:"Data Mining Industrial Applications",slug:"data-mining-industrial-applications",signatures:"Waldemar Wójcik and Konrad Gromaszek",authors:[{id:"15208",title:"Dr.",name:"Waldemar",middleName:null,surname:"Wójcik",fullName:"Waldemar Wójcik",slug:"waldemar-wojcik"},{id:"24059",title:"Dr.Ing.",name:"Konrad",middleName:null,surname:"Gromaszek",fullName:"Konrad Gromaszek",slug:"konrad-gromaszek"}]}]}]},onlineFirst:{chapter:{type:"chapter",id:"72797",title:"Peripheral Edema: Differential Diagnosis",doi:"10.5772/intechopen.82400",slug:"peripheral-edema-differential-diagnosis",body:'\n<div class="section" id="sec_1" data-lvl="1">\n<h2 class="heading main-title">1. Introduction</h2>\n<p id="p2">Lower limb edema recognizes more etiological factors that are frequently confused during differential diagnosis. Sometimes there are more causes with preponderance of one over the other, either local or systemic.</p>\n<p id="p3">The doubts in the diagnostic definition derive from an insufficient evaluation of clinical symptomatological aspects and of any instrumental and hemato-chemical tests performed in individual cases.</p>\n<p id="p4">From a correct clinical and consequently ethiopathogenetic classification derives the most appropriate therapeutic option. Pharmacological, physical rehabilitative, or surgical therapies not inspired by edema correction principles based on its ethiopathogenesis may result in therapeutic failure or even in the worsening of local or systemic clinical status.</p>\n<div class="section" id="sec_1_2" data-lvl="2">\n<h3 class="heading section-title">1.1 Description</h3>\n<p id="p5">The causes of edema of the lower limbs are various (local and/or systemic), sometimes multiple, and are to be found on the basis of a series of anamnestic and semeiological elements that, if properly considered and identified, allow better management of the clinical picture [<a href="#B1" class="ref-link" data-ref-style="bibr">1</a>].</p>\n<p id="p6">Too often, in fact, even today we are witnessing the diagnosis of lymphostatic edemas of lower limbs, ignoring that in many cases the loco-regional lymphatic system is normally developed and adequately functional.</p>\n<p id="p7">The same monolaterality of edema, by itself alone, allows to address the diagnostic suspicions towards a local and non-systemic cause. A systemic cause of edema of lower limbs, in fact, always determines bilateral edema (albeit with relative prevalence in one of the two limbs), never being unilateral [<a href="#B1" class="ref-link" data-ref-style="bibr">1</a>].</p>\n<p id="p8">Therefore, on the one hand, it is necessary to have a clear presence of the systemic causes of edema and of the loco-regional ones and, on the other hand, the clinical and instrumental criteria which, together, allow to formulate the correct diagnosis and to prepare the most indicated therapeutic measures.</p>\n</div>\n</div>\n<div class="section" id="sec_3" data-lvl="1">\n<h2 class="heading main-title">2. Causes of edema of the lower limbs</h2>\n<div class="section" id="sec_3_2" data-lvl="2">\n<h3 class="heading section-title">2.1 Local</h3>\n<p id="p9">\n<ul><li><p id="p10">Insufficiency of the superficial lymphatic system (the deep one does not assume the importance that it has as in the venous system); it can be unilateral or bilateral [<a href="#B2" class="ref-link" data-ref-style="bibr">2</a>, <a href="#B3" class="ref-link" data-ref-style="bibr">3</a>, <a href="#B4" class="ref-link" data-ref-style="bibr">4</a>, <a href="#B5" class="ref-link" data-ref-style="bibr">5</a>, <a href="#B6" class="ref-link" data-ref-style="bibr">6</a>, <a href="#B7" class="ref-link" data-ref-style="bibr">7</a>].</p></li><li><p id="p11">Insufficiency of the deep venous system (the insufficiency of the superficial one is not able to autonomously generate edema, as many subjects with varicose veins of the lower limbs do not have localized or widespread edema and, above all, clinically present the feet &lsquo;dry&rsquo;). In these cases the edema is unilateral (post-thrombotic syndrome) [<a href="#B8" class="ref-link" data-ref-style="bibr">8</a>, <a href="#B9" class="ref-link" data-ref-style="bibr">9</a>].</p></li><li><p id="p12">Lipedema which is normally bilateral and frequently associated with a similar clinical aspect of the upper limbs [<a href="#B10" class="ref-link" data-ref-style="bibr">10</a>, <a href="#B11" class="ref-link" data-ref-style="bibr">11</a>, <a href="#B12" class="ref-link" data-ref-style="bibr">12</a>].</p></li><li><p id="p13">Inflammatory/infectious states of the soft tissues (joints, tendons, muscles) or&nbsp;bones.</p></li><li><p id="p14">Benign or malignant neoplasms (primitive or metastatic).</p></li></ul>\n</p>\n</div>\n<div class="section" id="sec_4_2" data-lvl="2">\n<h3 class="heading section-title">2.2 Systemic</h3>\n<p id="p15">\n<ul><li><p id="p16">Heart failure (from diastolic dysfunction) [<a href="#B13" class="ref-link" data-ref-style="bibr">13</a>]</p></li><li><p id="p17">Hepatic insufficiency [<a href="#B14" class="ref-link" data-ref-style="bibr">14</a>]</p></li><li><p id="p18">Acute and chronic renal failure</p></li><li><p id="p19">Myxedema [<a href="#B15" class="ref-link" data-ref-style="bibr">15</a>]</p></li><li><p id="p20">Drugs edema</p></li><li><p id="p21">Idiopathic edema</p></li></ul>\n</p>\n<p id="p22">Among the <strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">loco-regional</bold></strong> causes, the most important and frequent is represented by lymphedema (primary and secondary).</p>\n</div>\n<div class="section" id="sec_5_2" data-lvl="2">\n<h3 class="heading section-title">2.3 Lymphedema</h3>\n<p id="p23">Lymphedema derives from an altered (qualitative or quantitative) development of the loco-regional system. In primary forms (which may occur at birth or, more frequently, in the second, third, fourth, fifth decade of life), an altered development of the lymphatic pathways, an altered lymph-node architectural code (lymphadenodysplasia), or an insufficient number of them (often on a genetic basis in the development of lymph glandular stations) causes a slowing of the lymphatic return that can go as far as the stop of the flow at the loco-regional level. In some cases the familiarity for the affection is documented, in others (the so-called sporadic forms, because we do not know their existence in other family members), the lymphedema appears in the only subject clinically affected without affecting other members of the same family nucleus; then there is a third type of primary lymphedema in which the edema constitutes only one (and not always the &ldquo;determinant&rdquo;) of the various clinical aspects of a syndrome (Prader-Willi, Noonan, Proteus, Hennekam, Gorham-Stout).</p>\n<p id="p24">The secondary forms are sometimes considered primary for the predisposition in some subjects to develop secondary edema following certain clinical conditions (one example is the &ldquo;post-mastectomy lymphedema&rdquo;, which develops in one in four woman, while the others remain with the same limb, in volume and consistency, throughout their lives, even if they are of the same age and in the same physical condition, and undergo the same surgery by the same operator); the genesis and the ethiopathogenetic evolution, in these cases, are the same as in the primary forms; in these cases, as a result of inflammatory processes, traumas, or, more frequently, surgical lymphadenectomy for neoplasms or radiotherapy, the anatomical continuity of the local lymphatic circulation is lost in an acquired manner so that the clinical picture of the lymphostasis is observed. One of the clinical peculiarities of lymphedema of the lower limbs is the different progression of stasis along the limb: from the more distal portions towards the proximal ones in the primary forms and from the proximal ones to the distal ones in the secondary forms (<a href="#F1" class="ref-link" data-ref-style="fig">\nFigure 1a\n</a> and <a href="#F1" class="ref-link" data-ref-style="fig">\nb\n</a>).</p>\n<figure class="media-panel" id="F1"><div class="media"><img src="/media/chapter/72797/media/F1.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 1.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p25">Lymphedema of the lower limb: primary (a) and secondary (b).</p></p></figcaption></figure>\n<p id="p26">Lymphedema is characterized by being the only edema with high interstitial protein concentration, distinguishing itself for this from all other types of edema [<a href="#B16" class="ref-link" data-ref-style="bibr">16</a>, <a href="#B17" class="ref-link" data-ref-style="bibr">17</a>]. The presence of a high rate of proteins in the interstitium determines the activation of fibroblasts that increase their production of collagen fibers, inducing more or less early and more or less marked tissue sclerosis. Lymphatic edema, therefore, is characterized by an early increase in the consistency of the tissues in which it is located and that, in the most advanced clinical stages, can reach the wooden consistency. Under these conditions the compression of the skin generates a depression (or &ldquo;pitting test&rdquo;) that can be &ldquo;fleeting&rdquo; or even absent [<a href="#B18" class="ref-link" data-ref-style="bibr">18</a>, <a href="#B19" class="ref-link" data-ref-style="bibr">19</a>, <a href="#B20" class="ref-link" data-ref-style="bibr">20</a>, <a href="#B21" class="ref-link" data-ref-style="bibr">21</a>, <a href="#B22" class="ref-link" data-ref-style="bibr">22</a>, <a href="#B23" class="ref-link" data-ref-style="bibr">23</a>].</p>\n<p id="p27">For the rarefaction of the arteriolar capillaries which, with the same volumetric unit, is carried out in the cutaneous and subcutaneous tissues, the skin color is not &ldquo;rosy&rdquo; as in the skin of normal limbs but pale. For the same ethiopathogenetic reason, the limb skin with lymphedema is colder than of a normal limb [<a href="#B24" class="ref-link" data-ref-style="bibr">24</a>, <a href="#B25" class="ref-link" data-ref-style="bibr">25</a>, <a href="#B26" class="ref-link" data-ref-style="bibr">26</a>, <a href="#B27" class="ref-link" data-ref-style="bibr">27</a>, <a href="#B28" class="ref-link" data-ref-style="bibr">28</a>].</p>\n<p id="p28">The lymphatic system presents some well-recognizable outward signs. The lymphatic system communicates us, but often the examiner does not recognize the messages sent. An example of this is the location of the primary or metastatic cancer in the lymphatic system itself. Sometimes a monolateral edema of the upper limb, sent for decongestive complex therapy with the prescription of a manual lymphatic drainage cycle for forearm edema and a recent onset, may be the expression of a symptomatic edema of a metastatic cancer (<a href="#F2" class="ref-link" data-ref-style="fig">\nFigure 2a\n</a> and <a href="#F2" class="ref-link" data-ref-style="fig">\nb\n</a>). In these cases, an aprioristic therapeutic approach, without the most opportune clinical considerations, can fatally delay the care that the patient really needs.</p>\n<figure class="media-panel" id="F2"><div class="media"><img src="/media/chapter/72797/media/F2.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 2.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p29">Forearm and hand edema, determined by the presence of metastases of the supraclavicular lymph nodes from unknown primitive pulmonary cancer (first clinical manifestation of neoplasia).</p></p></figcaption></figure>\n<p id="p30">The commonly recognized four clinical stages of the disease are:<ul><li><p id="p31">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">First stage:</bold></strong> It is the pre-clinical stage in which there is an undoubted predisposition to the possible onset of lymphedema (a consanguinity of a patient with primary lymphedema, mastectomized with limbs coincident in terms of volume and consistency of the two limbs).</p></li><li><p id="p32">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Second stage:</bold></strong> The edema is present and regresses partially with nighttime rest and decongestive physical treatments.</p></li><li><p id="p33">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Third stage:</bold></strong> Elephantiasis with disappearance of the bony and tendon saliencies normally present in the affected limb.</p></li><li><p id="p34">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Fourth stage:</bold></strong> Elephantiasis complicated by verrucosis, pachydermia, ulcer, or tissue changes in the lymphosarcomatosis sense.</p></li></ul>\n</p>\n<p id="p35">In primary forms of lower limbs, there is also a pathognomonic sign that takes its name from the person who first described it: the Stemmer sign. Its positivity consists in the impossibility to &ldquo;pinch&rdquo; with the fingers of the examiner the skin of the patient&rsquo;s toe; you cannot lift it from the underlying bone phalanx due to the early fibrosis that is generated in the over-factory layers of the tissue itself. The diagnosis of lymphedema is clinical (fundamental is the anamnesis and a correct objective examination); however, there are some instrumental exams that complete the picture, allowing a better definition of the therapeutic approach and the prognostic one. In the primary forms, the lymphoscintigraphy is essential which consists of subcutaneous inoculation, at the root of the toes, of some drops of radioactive tracer (nanocolloids of albumin labeled with technetium-99) which has a particular tropism for the lymphatic system. After inoculation, the patient practices physical exercise to allow the tracer to &ldquo;gain&rdquo; more quickly the lymphatic pathways. After 30&prime;, and after 90&prime;, a gamma-chamber performs that uptake of the tracer which, in the meantime, is distributed in the lymphatic vessels and lymph nodes of the whole lower limb and in the iliac chains. The resulting image provides important morphological indications on the normal/pathological development of the lymphatic system allowing better orienting the therapeutic intervention and being able to conceive also a prognosis.</p>\n<p id="p36">The high-resolution ultrasound examination also highlights the thickening of the epidermis on the affected side, the increase in thickness of the over-fascial layer, and the tissue compressibility that is a function of the more or less developed fibrosis.</p>\n<p id="p37">The ultrasound also allows the monitoring of pharmacological, physical rehabilitative, and surgical treatment by comparing the pre- and posttreatment over-fascial thicknesses.</p>\n<p id="p38">Videofluoroscopy is more complex and difficult to access because it is not widely practiced at a territorial level. It consists of the study of the anatomy physio-lymphatic pathology by injection of a dye, the indocyanine green, which flows into the lymphatic vessels and allows to visualize the flow in real time (on videoscope) both basal and during manual or mechanical stimulation; the lymphangio-MR, even less widespread as practiced in very few centers at the international level, allows, in more detail, to highlight the entire local lymphatic system and its possible anatomical defects.</p>\n</div>\n<div class="section" id="sec_6_2" data-lvl="2">\n<h3 class="heading section-title">2.4 Venous edema</h3>\n<p id="p39">It is very rare, in contrast to the lymphatic stasis edema, to observe a venous edema deriving from the supra-fascial venous compartment. In this sense the lymphatic system and the venous system behave in a completely opposite way from the clinical point of view. Lymphedema never develops in deep tissues, unless congenital dysplasia is located in the deep tissues; it is always located at the supra-fascial level.</p>\n<p id="p40">Venous edema, on the other hand, never develops in the supra-fascial compartment (in the clinical practice, it is common to find patients who have large varicose veins of the lower limbs, but their feet are &ldquo;dry&rdquo;, with no signs of edema.). Venous edema is an edema that is located at a deep level (for this reason, it is difficult to manage, from the therapeutic point of view, with conventional manual or mechanical drainage techniques). It is located at the sub-fascial level and, in the overwhelming majority of cases, represents the most striking aspect of the permanent clinical picture of a so-called &ldquo;post-thrombotic syndrome&rdquo; (<a href="#F3" class="ref-link" data-ref-style="fig">\nFigure 3\n</a>).</p>\n<figure class="media-panel" id="F3"><div class="media"><img src="/media/chapter/72797/media/F3.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 3.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p41">Post-thrombotic oedema of the lower limb.</p></p></figcaption></figure>\n<p id="p42">In deep venous thrombosis of the lower limbs, in fact, after thrombotic occlusion of the deep veins, follows more or less precociously a &ldquo;compensatory&rdquo; dilatation of the deep collateral and often superficial circle in correspondence of the same anatomical district (secondary or symptomatic varices). This muscular imbibition (therefore deep) assumes the characters of chronicity and corresponds to the permanent edema in which it is not possible to observe alterations of skin color or skin temperature in its correspondence, and the pitting sign is absent and does not appreciate changes in tissue texture. In doubtful cases (previous venous thrombosis passed &ldquo;unobserved&rdquo; from a clinical point of view due to lack of characteristic signs and symptoms), a key examination is represented by the computerized tomography.</p>\n<p id="p43">According to the &ldquo;CT cuts&rdquo; of the two limbs in comparison with the lymphatic edema it is possible to observe an increase in supra-fascial thickness, over-folded with the sub-fascial compartment coinciding in the two limbs, in venous edema (from deep vein thrombosis); on the contrary, the supra-fascial thicknesses appears coincident, while the sub-fascial thickness is considerably increased in the affected side.</p>\n<p id="p44">Symptoms in the post-thrombotic syndrome of the lower limb (in the one-sided form) are generally non specific; patients often show paresthesia, rarely pain, mostly vague, hardly epicritic, and often associated with protopathic sensitivity.</p>\n<p id="p45">The so-called venous claudication which consists in pain during walking but with a variable free-range of motion (unlike &ldquo;arterial claudication&rdquo;), is rare and appears in the worsening of the deep venous circulation due to incomplete recanalization of the deep venous axis when the acute phase is past.</p>\n<p id="p46">Obviously, the high-resolution ultrasound examination in these cases shows a relative increase of the sub-fascial layers, and the echo color Doppler of the examined districts confirms the outcomes of deep vein thrombosis with frequent evidence of parietal sclerosis and partial or total disappeared endoluminal valvular structures.</p>\n</div>\n<div class="section" id="sec_7_2" data-lvl="2">\n<h3 class="heading section-title">2.5 Phlebolymphedema</h3>\n<p id="p47">Phlebolymphedema represents a particular type of peripheral edema that is determined by the contemporary ethiopathogenetic association of venous and lymphatic insufficiency. It is generally present in cancer, due to the simultaneous macroscopic and microscopic anatomical involvement of the two venous and lymphatic drainage systems of a certain anatomical district<sup>8</sup>.</p>\n<p id="p48">The most striking manifestation is a secondary lymphedema of the lower limb determined by inguinal or pelvic lymphadenectomy (necessary for compliance with surgical criteria of &ldquo;radical cancer therapy&rdquo;) associated with a partial or complete occlusion of a deep venous vessel of the limb same. In these cases the increase in interstitial oncotic pressure determined by the mechanical lymphatic stasis (removal of lymphoglandular stations) is associated with a venous hypertension (increase of the intravascular hydrostatic pressure in the venous side of the microvascular tissue unit) caused by the occlusion of the main venous axis of outflow from the lower limb itself (<a href="#F4" class="ref-link" data-ref-style="fig">\nFigure 4\n</a>).</p>\n<figure class="media-panel" id="F4"><div class="media"><img src="/media/chapter/72797/media/F4.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 4.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p49">(a and b) Phlebolymphedema: a case of prostate cancer with pelvic lymphadenectomy associated with venous left iliac thrombosis. (a) Clinical case and (b) phlebography of the lower limb.</p></p></figcaption></figure>\n</div>\n<div class="section" id="sec_8_2" data-lvl="2">\n<h3 class="heading section-title">2.6 Lipedema</h3>\n<p id="p50">Lipedema is a very common disease in the female population consisting predominantly of lipid cells that is established in certain specific anatomical districts. It has a familiar character with the male that results (as found in several pedigrees) in &ldquo;healthy carrier.&rdquo; In the lower limbs, the localization can be variable but always bilateral; it can be limited to the thighs, but it can also affect the gluteal regions, affecting only the legs, affecting the thighs and legs, or involving, in addition to these, the buttocks (<a href="#F5" class="ref-link" data-ref-style="fig">\nFigure 5\n</a>). The feet are always spared. Sometimes the arms and forearms are also affected, and hands are always spared. The edema is associated with constant pain, which becomes acute with the passing of the hours of the day and during the summer, and ease of spontaneous bruising [<a href="#B10" class="ref-link" data-ref-style="bibr">10</a>, <a href="#B11" class="ref-link" data-ref-style="bibr">11</a>, <a href="#B12" class="ref-link" data-ref-style="bibr">12</a>, <a href="#B29" class="ref-link" data-ref-style="bibr">29</a>].</p>\n<figure class="media-panel" id="F5"><div class="media"><img src="/media/chapter/72797/media/F5.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 5.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p51">Lipedema of the lower limbs.</p></p></figcaption></figure>\n<p id="p52">Edema, generally, appears at puberty and is exacerbated at some particular moments in a woman&rsquo;s life (breastfeeding more than pregnancy and menopause). The edema appears simultaneously in all the regions of the affected limbs, and there is never a progression along the limbs (neither in the distal-proximal or proximal-distal sense) but only a possible simultaneous increase of the edematous zones. It is an edema that does not respond to hypocaloric dietary treatments or physical exercise.</p>\n<p id="p53">We recognize four clinical stages of the disease:<ul><li><p id="p54">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">First stage:</bold></strong> Mild edema located in the sites already described in the possible combinations with conserved limb conformation. The skin presents slight and widespread increase in consistency.</p></li><li><p id="p55">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Second stage:</bold></strong> Important edema involving the sites described in the possible combinations, with pain and gross deformations of some regions of the limbs. Increased skin of consistency.</p></li><li><p id="p56">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Third stage:</bold></strong> Painful elephantiasis with extremely gross plication, alteration of the gait pattern, and possible cutaneous lesions, prevalent on the inner surfaces of the thighs. Occurrence of serotine foot edema or after prolonged standing station.</p></li><li><p id="p57">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">Fourth stage:</bold></strong> Painful elephantiasis with gross plication, alteration of the gait pattern, trophic lesions, and permanent edema of the feet (lipolymphedema).</p></li></ul>\n</p>\n<p id="p58">The lymphoscintigraphy of lower limbs, in the early stages, shows a normal development and draining lymphatic circulation. In the advanced clinical stages of the disease, it is possible to underline bilateral sub-rotuleous stagnation of the tracer (dermal back flow) and lymph node stop that corresponds, from the clinical point of view, to the so-called lipolymphedema of the lower limbs.</p>\n<p id="p59">High-resolution ultrasound allows to highlight a constant echogenic pattern of the supra-fascial compartment (skin-fascia). It is an extremely useful test for the differential diagnosis with lymphedema of the lower limbs. In lipedema, in fact, the compression of tissues with a linear probe shows a reduction in the sub-fascial thicknesses with the supra-fascial which remained unchanged; in the case of lymphedema, on the contrary, the compression with linear probe shows a decrease in the over-fascial thicknesses, while the sub-fascial remain unchanged. This testifies that in lipedema the volumetric increase is given by an increased cellular component (hypertrophic and hyperplastic lipid cells) while in the lymphedema the volumetric increase is given by more or less copious presence of extracellular interstitial fluids that the pressure of the probe can move.</p>\n<p id="p60">The BMI is variable in the two pathologies. In lipedema it is generally within the limits of the norm and is not minimally influenced by physical treatments nor by the overall weight loss. In lymphedema it can be equally variable even if it is higher on average than in patients with lipedema.</p>\n<p id="p61">The differential diagnosis with obesity is quite simple. In the obese patients, the collection of fatty deposits is widespread in all the body regions with a particular preference for the anatomical areas typical of each sex ( gynoid type and android type).</p>\n<p id="p62">Obesity responds positively to physical exercises and diet, in all body districts, while lipedema is not affected at all by these factors.</p>\n</div>\n<div class="section" id="sec_9_2" data-lvl="2">\n<h3 class="heading section-title">2.7 Inflammatory or infectious states</h3>\n<p id="p63">The edema of the lower limb can be determined by inflammatory and/or infectious diseases. In these cases the localization is generally monolateral and is secondary to an inflammatory/infectious process of the soft tissues (cellulitis, myositis, myofascitis, necrotizing fasciitis). The localization may involve only one area of the limb (thigh, leg, foot) assuming the topographic configuration of the &ldquo;suspended edema.&rdquo; Besides the edema, all the other characters of inflammation are generally present (increase in skin temperature, hyperemia, pain, and reduction of functional capacity (&#8202;<em><italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">functio laesa</italic></em>). The resolution of edema is due, in these cases, to anti-inflammatory and pharmacological treatment and, if necessary, to antibiotics. A special case of edema that can induce doubts of differential diagnosis with deep vein thrombosis and that is determined by the presence of serous cyst of the popliteal cable is known as Baker&rsquo;s cyst. Particularly developed, it can compress the surrounding venous and lymphatic vessels, inducing a distal edema (generally sub-patellar) also extended to the whole leg and to the foot. With the treatment of cystic formation (puncture with evacuation, surgical excision, simple anti-inflammatory therapy), we are witnessing the resolution of the edema.</p>\n</div>\n<div class="section" id="sec_10_2" data-lvl="2">\n<h3 class="heading section-title">2.8 Benign or malignant neoplasms</h3>\n<p id="p64">Benign or malignant tumoral formations may develop in the lower limbs, especially the soft tissues (mainly muscles). Their localization, particularly in the leg muscles, occupying space, also due to the compressive phenomena exerted on the surrounding vessels, can determine circumscribed or diffused edema which, for the differential diagnosis, must make use of more discriminating investigations, such as CT or MR. Obviously, the edema, in these cases, recedes only after surgical removal of the mass.</p>\n</div>\n<div class="section" id="sec_11_2" data-lvl="2">\n<h3 class="heading section-title">2.9 Systemic causes</h3>\n<div class="section" id="sec_11_3" data-lvl="3">\n<h4 class="heading subsection-title">2.9.1 Edema in heart failure (from diastolic dysfunction)</h4>\n<p id="p65">In the case of heart failure, the echocardiographic examination may be apparently normal (the ventricular ejection fraction, in these cases, provides normal indications, and no particular problems are highlighted). In these conditions, however, a careful clinical examination is required which highlights a bilateral and symmetrical lower limb edema (often confused with lymphedema); the sign of the fovea is particularly evocable and persistent over time. The Stemmer sign is negative (<a href="#F6" class="ref-link" data-ref-style="fig">\nFigure 6\n</a>). The edema is established by an important increase in venous pressure in the microvascular tissue units, whereby the normal pressure gradient at the micro-tissutal level which, from the hydrostatic point of view, under normal conditions, would help the return of fluids from the interstitium towards the venous capillaries is gone and many water molecules remain in the interstitium. The thoracic auscultation demonstrates the presence of bilateral basal crackles. The liver may appear increased in volume and with rounded margins<sup>13</sup>. The subject refers to dyspnea for slight efforts or even at rest. During nocturnal rest the patient needs to observe a decubitus which raises the thorax and head with respect to the other bodily districts. In these cases, the dosage of the inactive form of the Brain Natriuretic Peptide (BNP, substance produced by the cardiac endothelium, whose serum concentration increases in the case of inability of filling by the cardiac chambers) results elevated, suggesting that the heart has difficulty in receiving fluids returning from the periphery (second- or thirddegree diastolic dysfunction); this disfunctions are relatively frequent in women above 65 years. In these cases conventional draining physical therapies risk aggravating subjective and objective symptoms, and the same elastic garment to be worn in the morning should be prescribed only after the clinical compensation obtained with the appropriate dosage of diuretics and positive inotropic drugs e.g., digoxin) indicated for each individual case.</p>\n<figure class="media-panel" id="F6"><div class="media"><img src="/media/chapter/72797/media/F6.png" class="figure-link" alt=""></div><figcaption class="caption"><h4>Figure 6.</h4><p><p xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="p66">Stemmer sign: positive in lymphedema (a), negative in cardiac failure (b) before compression and (c) after compression.</p></p></figcaption></figure>\n</div>\n<div class="section" id="sec_12_3" data-lvl="3">\n<h4 class="heading subsection-title">2.9.2 Hepatic insufficiency</h4>\n<p id="p67">The edema of hepatic insufficiency can be defined as &ldquo;gravitational&rdquo;; it is collected mainly in the sloping body areas. It is essentially localized in the toes and feet when the subject is standing or sitting with the legs &ldquo;dangling.&rdquo; When the subject is lying on the bed, the most gravitational area is the presacral region<sup>14</sup>. It is not uncommon in these cases, if the patient holds a higher limb outside the bed, observe the edema at the level of the elbow of the arm itself. The conventional physical therapies, even in this case, do not solve the problem that benefits only from the administration of intravenous albumin. It is hypo-albumin, which in fact generates edema: since each protein molecule behaves like a kind of magnet to water molecules (it attracts them); in the case of hypo-albuminemia, liquids are no longer held within the intra-vascular compartment and tend to flee to intertial space, following the gravity.</p>\n</div>\n<div class="section" id="sec_13_3" data-lvl="3">\n<h4 class="heading subsection-title">2.9.3 Acute and chronic renal failure</h4>\n<p id="p68">In chronic renal failure at third or fourth stage, the relative inability of the nephron to produce &ldquo;pre-urine&rdquo; inevitably leads to a generalized &ldquo;water retention&rdquo; affecting all body districts. The subject, frequently, in the morning wakes up with the edematous eyelids and only an adequate dosage of diuretics, respecting the values of the electrolytes and, above all, of the renal function (azotemia, creatinine). Decongestive physical treatments cannot find an elective indication even in this form.</p>\n</div>\n<div class="section" id="sec_14_3" data-lvl="3">\n<h4 class="heading subsection-title">2.9.4 Myxedema</h4>\n<p id="p69">Myxedema is a particular form of edema affecting the lower limbs (generally bilaterally, symmetrically, and localized to the pretibial surfaces) determined by accumulation of mucopolysaccharides in the derma. In these cases, the pretibial edema is also accompanied by ocular edema (exophthalmos), with generalized dryness of the skin and, sometimes, psychic hypo-evolution [<a href="#B15" class="ref-link" data-ref-style="bibr">15</a>]. It is determined by serious conditions of hypothyroidism (congenital or acquired), in which TSH (which, for various reasons, does not respond to the thyroid parenchyma) would stimulate tissue fibroblasts and adipocytes to replicate and produce mucopolysaccharide complexes, with local deposition inside the dermis, or, on the contrary, in cases of hyperthyroidism (as in Flaiani-Basedow&rsquo;s disease). This type of edema is reversible and recognizes as a fundamental therapeutic treatment the correction of thyroid defect (in defect or excess of glandular function). It is presented as a &ldquo;suspended edema,&rdquo; not painful, and without local typical signs of inflammatory processes.</p>\n</div>\n<div class="section" id="sec_15_3" data-lvl="3">\n<h4 class="heading subsection-title">2.9.5 Drug edema</h4>\n<p id="p70">Drug edema occurs, in most cases, by a particular idiosyncrasy of the subject to certain molecules. The drugs most commonly called into question in these forms are some molecules with antihypertensive effect (especially amlodipine and other calcium antagonists, in which the edema is localized mainly in the two ankles&mdash;bilateral edema&mdash;and in the back of the feet, and the sartanics that can induce generalized edemas, up to anasarca) and the corticosteroids which cause a generalized water retention. In all these forms, physical treatment is not conclusive, and the therapy consists in the simple suspension of the drug (with substitution with different molecules). In almost all the cases, the complete resolution of the clinical picture is achieved within a maximum of 7&nbsp;days from the suspension of the drug.</p>\n</div>\n<div class="section" id="sec_16_3" data-lvl="3">\n<h4 class="heading subsection-title">2.9.6 Idiopathic edema</h4>\n<p id="p71">Many authors are reminded of the possible presence of &ldquo;idiopathic edema,&rdquo; or an edema (generally distal and bilateral) that arises at certain times of the day (especially after prolonged standing) or in the summer season. It regresses with the wearing of the definitive elastic garment for a variable period of time.</p>\n</div>\n<div class="section" id="sec_17_3" data-lvl="3">\n<h4 class="heading subsection-title">2.9.7 Differential diagnosis of edema of the lower limbs</h4>\n<p id="p72">The differential diagnosis of edema of the lower limbs can be easily formulated through simple observations concerning skin color, skin temperature, mono- or bilaterality localization, the presence of the sign of pitting, the presence of the Stemmer sign, the sense of progression of the edema along the limb, and the date of onset of edema, compared to the time of observation. From a combined analysis of these elements, it is possible to easily reach the diagnosis that can be further confirmed by other exams, already described in the individual-treated paragraphs [<a href="#B4" class="ref-link" data-ref-style="bibr">4</a>, <a href="#B12" class="ref-link" data-ref-style="bibr">12</a>, <a href="#B30" class="ref-link" data-ref-style="bibr">30</a>, <a href="#B31" class="ref-link" data-ref-style="bibr">31</a>, <a href="#B32" class="ref-link" data-ref-style="bibr">32</a>, <a href="#B33" class="ref-link" data-ref-style="bibr">33</a>, <a href="#B34" class="ref-link" data-ref-style="bibr">34</a>, <a href="#B35" class="ref-link" data-ref-style="bibr">35</a>, <a href="#B36" class="ref-link" data-ref-style="bibr">36</a>].</p>\n<p id="p73">In particular, in relation to:<ul><li><p id="p74">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>Skin color</italic>\n</bold></strong>: in the cardiac edema, it can appear bright pink up to taking on bluish-cyanotic nuances, in particular at the level of visible mucous. In the hepatic edema, it can assume a yellowish shade; in case of renal failure, it can appears &ldquo;greenish.&rdquo; In superficial venous root edema (acute varicophlebitis), it can be red to cyanosis. In the deep vein thrombosis edema, it generally maintains the rosy color that coincides with that of the healthy limb. Lipedema, myxedema, idiopathic edema and the drugs-related one keep rosy the complexion; instead the skin remains pale in primary or secondary lymphedema, tending to whitish, due to the rarefaction of the arteriolar capillaries which occurs in the tissue volumetric unit [39].</p></li><li><p id="p75">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>The cutaneous temperature</italic>\n</bold></strong> remains normal in cardiac, hepatic, renal, and idiopathic edema, in myxedema, lipedema, and drug-related edema. It remains normal also in deep vein thrombosis edema (except in cases where there is an important lymphatic overload of the superficial circle&mdash;with vicarious goals&mdash;that can cause a slight reduction of skin temperature in the affected limb compared to the contralateral one). In superficial venous root edema (varicophlebitis), the local temperature increases, while in lymphedema, primary or secondary, for the same reason for which the skin is whitish (except for concomitant acute lymphangitis), it is also characterized by a decrease in&nbsp;local temperature [<a href="#B37" class="ref-link" data-ref-style="bibr">37</a>, <a href="#B38" class="ref-link" data-ref-style="bibr">38</a>].</p></li><li><p id="p76">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>Mono- or bilateral localization</italic>\n</bold></strong>: in all edemas of a &ldquo;systemic&rdquo; cause (cardiac, hepatic, renal, myxedema, drug-related), the localization is always bilateral and generally symmetrical. Also in lipedema it is bilateral. In lymphatic edema, both primary and secondary, localization can be both unilateral and bilateral. Idiopathic edema, superficial venous cause edema (varicophlebitis), and deep venous cause (deep venous thrombosis) are generally unilateral.</p></li><li><p id="p77">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>Pain</italic>\n</bold></strong>: in the &ldquo;systemic&rdquo; causes of edema, pain is generally absent, unless concomitant algogenic irritating spines coexist. In the edema caused by superficial varicophlebitis, often cyclical exacerbations are present. In the deep vein thrombosis edema, pain is not acute; it is deaf, not well definable from the anatomical point of view, and not epicritic, diffused to the interested limb. Pain is one of the peculiar characteristics of the clinical picture in lipedema. It is variable in various hours of the day being described as particularly important in the evening hours and in the summer season (obviously also depending on the clinical stage of the disease).</p></li><li><p id="p78">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>Pitting sign</italic>\n</bold></strong>: it is particularly present and persistent in the diastolic heart dysfunction edema, as in the typical edema of the hepatic insufficiency and in that of the renal insufficiency. It is present in myxedema, idiopathic edema, drug-related edema, and edema of superficial venous affections. It is generally absent in deep vein thrombosis. It is also fleeting and not very persistent in lymphatic edema, both primary and secondary, due to tissue fibrosis that more or less establishes in the tissues due to the persistence of interstitial protein component which induces fibrosis with consequent increase of tissue consistency itself. In lipedema, in the early clinical stages, the pitting sign is absent (the volumetric increase is determined by the exclusive presence of hyperplastic and hypertrophic adipose cells and not to fluids in the interstitium). It can appear in the most advanced clinical stages (lipolymphedema) [<a href="#B39" class="ref-link" data-ref-style="bibr">39</a>].</p></li><li><p id="p79">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>Stemmer&rsquo;s sign</italic>\n</bold></strong>: it is pathognomonic of lymphedema. It is in fact undetectable in all edemas that recognize a systemic cause, in idiopathic edema, and in lipedema (in which the feet are always spared from the edematous localization). In lymphedema, it is always present, and if it would be well-known by general practitioners and, unfortunately, also by many specialists, many unnecessary examinations (repeated echo color Doppler, Rx, high-resolution ultrasound, computed tomography, and MRI) would not be prescribed, looking for what is not recognized by simple clinical examination (it is of very frequent experience, even today). In the secondary forms of lymphedema of the lower limb, the Stemmer sign is initially negative and is only positively delayed [<a href="#B40" class="ref-link" data-ref-style="bibr">40</a>].</p></li><li><p id="p80">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>Progression of edema along the limb</italic>\n</bold></strong>: in systemic edema and idiopathic edema as well as in primary lymphedema, the progression of edema in the lower limbs takes place in a distal-proximal direction (first the toes and the foot are affected and then the leg and, lastly, the thigh). In secondary lymphedema, on the contrary, the progression takes place in the opposite direction, in the proximal-distal direction (first the thigh is affected and then the leg and lastly the foot and the toes with consequent &ldquo;late&rdquo; positivity of the Stemmer sign). In Lipedema and myxedema, there is no progressive development of the edema itself, but this originates and increases simultaneously in all the body regions involved [<a href="#B41" class="ref-link" data-ref-style="bibr">41</a>, <a href="#B42" class="ref-link" data-ref-style="bibr">42</a>].</p></li><li><p id="p81">\n<strong><bold xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n<italic>Time of onset</italic>\n</bold></strong>: the time of onset of the edema is extremely variable. Cardiac edema occurs due to continuous pharmacological adjustments, especially diuretic therapy, generally given by months or years with alternating clinical intensity, as well as hepatic or renal edema. Drug-related edema appears after 1 to 3/4&nbsp;days of taking the drug responsible for the side effect (an easily traced anamnestic data), and normally, as recalled, it reduces completely after the suspension of the drug. Lipedema generally appears at puberty (between 15 and 20&nbsp;years of age) and may present clinical resurgence in particular moments of the woman&rsquo;s fertile life. Myxedema may arise at birth or develop in subsequent periods depending on thyroid glandular activity. Idiopathic edema generally occurs at puberty. Venous edema certainly occurs the most sudden, both in the superficial (varicophlebitis) and in the deep (deep vein thrombosis) form. In this last case, the edema appears absolutely fast and involves the whole limb from the level of localization of the thrombus in the deep vein. In these cases the appearance and evolution (proximal-distal) is almost immediate. From coincident arts we highlight the important edema within 6&ndash;12&nbsp;h from the onset. The formation of the thrombus precedes the clinical evidence of the edema that only manifests when the dimensions of the thrombus hinders a large part of the habitual venous return [<a href="#B43" class="ref-link" data-ref-style="bibr">43</a>, <a href="#B44" class="ref-link" data-ref-style="bibr">44</a>, <a href="#B45" class="ref-link" data-ref-style="bibr">45</a>].</p></li></ul>\n</p>\n</div>\n</div>\n</div>\n<div class="section" id="sec_20" data-lvl="1">\n<h2 class="heading main-title">3. Conclusions</h2>\n<p id="p82">The opinion that an edema of the lower limbs, regardless of the patient&rsquo;s age, of the general clinical conditions and symptoms and signs that accompany the picture, is of a lymphostatic nature is still widespread today. So it happens that many cardiologists send to the angiologist or to the vascular surgeon patients over 70 years, with a fairly delineated symptom complex, albeit unidentified, with the diagnosis of &ldquo;recent-onset limb lymphedema&rdquo;; clinical cases that, if properly considered, are of strict cardiological relevance and not of physical rehabilitative medicine. Just as Lipedema is still unknown, as a pathology, by over 50% of the same vascular surgeons and of the angiology and by the overwhelming majority of family doctors [<a href="#B46" class="ref-link" data-ref-style="bibr">46</a>].</p>\n<p id="p83">The hemato-chemical and instrumental examinations are undoubtedly useful for a better definition of individual cases, both for the purposes of the therapeutic approach and the prognosis and monitoring.</p>\n<p id="p84">However, the diagnosis must be essentially clinical and is based on the considerations described, simply by analyzing the individual objective and subjective parameters, between them, and crossing the information. Clinical experience can accelerate the diagnosis and the accuracy of the subsequent therapeutic approach, but it is fundamental, in any case, that before a definitive diagnosis, we consider the &ldquo;semeiological picture&rdquo; which, combined with an accurate clinical history, allows to reach the certainty of differential diagnosis.</p>\n<p id="p85">Even today there are diagnostic mistakes in evaluation of many edema of the lower limbs. The lack of specific clinical experience and the underestimation of important anamnestic elements, supported by clinical evidence that often are not sought in the various details or, the misinterpretation of instrumental investigations can lead to inaccurate ethiopathogenetic diagnoses with negative consequences from the point of view of treatment that is undertaken in the individual clinical case.</p>\n<p id="p86">The proposed analysis aims at avoiding reckless or &ldquo;discounted&rdquo; clinical judgments, but not responding to the real needs of the individual patient, and helping the medical doctor, the physiotherapist, and the nurse to follow the most appropriate diagnostic and therapeutic procedures in line with the current principle prevention, early diagnosis, and treatment.</p>\n</div>\n<div class="section" id="sec_24" data-lvl="1"><h2 class="heading main-title">Conflict of interest</h2><p id="p87">The authors declare no conflict of interest.</p></div>\n',keywords:"peripheral edema diagnosis, edema diagnosis, peripheral edema of limbs differential diagnosis",chapterPDFUrl:"https://cdn.intechopen.com/pdfs/72797.pdf",chapterXML:"https://mts.intechopen.com/source/xml/72797.xml",downloadPdfUrl:"/chapter/pdf-download/72797",previewPdfUrl:"/chapter/pdf-preview/72797",totalDownloads:170,totalViews:0,totalCrossrefCites:0,dateSubmitted:"August 2nd 2018",dateReviewed:"November 5th 2018",datePrePublished:"October 6th 2020",datePublished:null,dateFinished:"July 13th 2020",readingETA:"0",abstract:"Peripheral edemas can be generated by multiple causes, local and/or systemic. The difficulties in recognizing the exact nature of the edema and the cause that originates it often lead to erroneous considerations that determine an inappropriate therapeutic approach. In this chapter the various causes that generate peripheral edema are analyzed (systemic: cardiac diastolic dysfunction, kidney failure, liver failure, myxedema, from drugs, and idiopathic; and local: venous and/or lymphatic transport insufficiency). They are also described, according to the diagnosis made and the clinical and instrumental criteria to attain a correct and early diagnosis and to proceed to the most appropriate therapeutic measures (drugs, surgery, physical rehabilitative by means of manual and mechanical techniques) in individual cases.",reviewType:"peer-reviewed",bibtexUrl:"/chapter/bibtex/72797",risUrl:"/chapter/ris/72797",signatures:"Sandro Michelini, Alessandro Failla, Giovanni Moneta, Alessandro Fiorentino and Cardone Marco",book:{id:"10426",title:"Inflammation",subtitle:null,fullTitle:"Inflammation",slug:null,publishedDate:null,bookSignature:"Dr. Vijay Kumar, Dr. Alexandro Aguilera Salgado and Dr. Seyyed Shamsadin Athari",coverURL:"https://cdn.intechopen.com/books/images_new/10426.jpg",licenceType:"CC BY 3.0",editedByType:null,isbn:"978-1-83968-642-9",printIsbn:"978-1-83968-641-2",pdfIsbn:"978-1-83968-643-6",editors:[{id:"63844",title:"Dr.",name:"Vijay",middleName:null,surname:"Kumar",slug:"vijay-kumar",fullName:"Vijay Kumar"}],productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"}},authors:null,sections:[{id:"sec_1",title:"1. Introduction",level:"1"},{id:"sec_1_2",title:"1.1 Description",level:"2"},{id:"sec_3",title:"2. Causes of edema of the lower limbs",level:"1"},{id:"sec_3_2",title:"2.1 Local",level:"2"},{id:"sec_4_2",title:"2.2 Systemic",level:"2"},{id:"sec_5_2",title:"2.3 Lymphedema",level:"2"},{id:"sec_6_2",title:"2.4 Venous edema",level:"2"},{id:"sec_7_2",title:"2.5 Phlebolymphedema",level:"2"},{id:"sec_8_2",title:"2.6 Lipedema",level:"2"},{id:"sec_9_2",title:"2.7 Inflammatory or infectious states",level:"2"},{id:"sec_10_2",title:"2.8 Benign or malignant neoplasms",level:"2"},{id:"sec_11_2",title:"2.9 Systemic causes",level:"2"},{id:"sec_11_3",title:"2.9.1 Edema in heart failure (from diastolic dysfunction)",level:"3"},{id:"sec_12_3",title:"2.9.2 Hepatic insufficiency",level:"3"},{id:"sec_13_3",title:"2.9.3 Acute and chronic renal failure",level:"3"},{id:"sec_14_3",title:"2.9.4 Myxedema",level:"3"},{id:"sec_15_3",title:"2.9.5 Drug edema",level:"3"},{id:"sec_16_3",title:"2.9.6 Idiopathic edema",level:"3"},{id:"sec_17_3",title:"2.9.7 Differential diagnosis of edema of the lower limbs",level:"3"},{id:"sec_20",title:"3. Conclusions",level:"1"},{id:"sec_24",title:"Conflict of interest",level:"1"}],chapterReferences:[{id:"B1",body:'<ref id="B1">\n<mixed-citation publication-type="journal">Tiwari A, Cheng KS, Button M, Myint F, Hamilton G. Differential diagnosis, investigation, and current treatment of lower limb lymphedema. Archives of Surgery. 2003;<bold>138</bold>(2):152-161</mixed-citation>\n</ref>'},{id:"B2",body:'<ref id="B2">\n<mixed-citation publication-type="book">Michelini S. Phlebolymphoedema. From Diagnosis to Therapy. Bologna: Edizioni P.R.; 1998</mixed-citation>\n</ref>'},{id:"B3",body:'<ref id="B3">\n<mixed-citation publication-type="journal">Badini A, Fulcheri E, Campisi C, Boccardo F. A new approach in histopathological diagnosis of lymphedema: Pathophysiological and therapeutic implications. Lymphology. 1996;<bold>29</bold>(S):190-198</mixed-citation>\n</ref>'},{id:"B4",body:'<ref id="B4">\n<mixed-citation publication-type="journal">Gasbarro V, Michelini S, Antignani PL, Tsolaki E, Ricci M, Allegra C. The CEAP-L classification for lymphedemas of the limbs: The Italian experience. International Angiology. 2009;<bold>28</bold>(4):315-324</mixed-citation>\n</ref>'},{id:"B5",body:'<ref id="B5">\n<mixed-citation publication-type="other">Lee B, Andrade M, Bergan J, Boccardo F, Campisi C, Damstra R, Flour M, Gloviczki P, Laredo J, Piller N, Michelini S, Mortimer P, Villavicencio JL. Diagnosis and treatment of primary lymphedema. Consensus Document of the International Union of Phlebology (IUP)-2009. International Angiology. 2010;29(5):454-470</mixed-citation>\n</ref>'},{id:"B6",body:'<ref id="B6">\n<mixed-citation publication-type="other">International Lymph Framework. Best Practice for the Management of Lymphoedema. 2nd ed. 2012. Available at: <ext-link ext-link-type="uri" xlink:href="http://www.lympho.org">www.lympho.org</ext-link>\n</mixed-citation>\n</ref>'},{id:"B7",body:'<ref id="B7">\n<mixed-citation publication-type="journal">The diagnosis and treatment of peripheral lymphedema: 2013 consensus document of the international society of lymphology. Lymphology;<bold>46</bold>(2013):1-11</mixed-citation>\n</ref>'},{id:"B8",body:'<ref id="B8">\n<mixed-citation publication-type="book">Michelini S, Cardone M. Veno-lymphatic vascular malformations: Medical therapy. In: Mattassi R, Loose DA, Vaghi M, editors. Hemangiomas and Vascular Malformations. Italia: Springer; 2015. pp. 445-450</mixed-citation>\n</ref>'},{id:"B9",body:'<ref id="B9">\n<mixed-citation publication-type="journal">Michelini S, Pissas A, Olszewski W, Dimakakos E, Cordero IF, Caldirola R, et al. Linforoll: A new device for lymphoedema treatment: Preliminary experience. Lymphology. 2015;<bold>47</bold>(Suppl):218-221</mixed-citation>\n</ref>'},{id:"B10",body:'<ref id="B10">\n<mixed-citation publication-type="journal">Mariani G, Campisi C, Taddei G, Boccardo F, Martini F, Rahimi Mansour A, et al. The current role of lymphoscintigraphy in the diagnostic evaluation of patients with peripheral lymphedema. Lymphology. 1998;<bold>31</bold>(Suppl):316-319</mixed-citation>\n</ref>'},{id:"B11",body:'<ref id="B11">\n<mixed-citation publication-type="book">Cavezzi A, Michelini S. PHlebolymphoedema. Bologna: Edizioni P.R; 1998</mixed-citation>\n</ref>'},{id:"B12",body:'<ref id="B12">\n<mixed-citation publication-type="journal">Nicolaides AN. Therapeutic outcome and quality of life in patients with chronic venous and lymphatic disorders. Phlebolymphology. 2008;<bold>20</bold>:2-3</mixed-citation>\n</ref>'},{id:"B13",body:'<ref id="B13">\n<mixed-citation publication-type="journal">Schmeller W, Hueppe M, Meier-Vollrath I. Tumescent liposuction in lipoedema yields good long-term results. The British Journal of Dermatology. 2012;<bold>166</bold>:161-168</mixed-citation>\n</ref>'},{id:"B14",body:'<ref id="B14">\n<mixed-citation publication-type="other">Schmeller W, Meier-Vollrath. Lipödem: Ein update (Lipedema: an update). Lymphol Forsch Prax. 2005;<bold>9</bold>(1):10-20</mixed-citation>\n</ref>'},{id:"B15",body:'<ref id="B15">\n<mixed-citation publication-type="journal">Forner-Cordero I, Szolnoky G, Forner-Cordero A, Kemény L. Lipedema: An overview of its clinical manifestations, diagnosis and treatment of the disproportional fatty deposition syndrome—Systematic review. Clinical Obesity. 2012;<bold>2</bold>:86-95</mixed-citation>\n</ref>'},{id:"B16",body:'<ref id="B16">\n<mixed-citation publication-type="journal">Pascual-Figal DA, Domingo M, Casas T, Gich I, Ordoñez-Llanos J, Martínez P, et al. Usefulness of clinical and NT-proBNP monitoring for prognostic guidance in destabilized heart failure outpatients. European Heart Journal. 2008;<bold>29</bold>(8):1011-1018</mixed-citation>\n</ref>'},{id:"B17",body:'<ref id="B17">\n<mixed-citation publication-type="journal">Younossi ZM, Guyatt G, Kiwi M, Boparai N, King D. Development of a disease specific questionnaire to measure health related quality of life in patients with chronic liver disease. Gut. 1999;<bold>45</bold>:295-300</mixed-citation>\n</ref>'},{id:"B18",body:'<ref id="B18">\n<mixed-citation publication-type="journal">Schwartz KM, Fatourechi V, Ahmed DDF, Pond GR. Dermopathy of Graves’ disease (pretibial myxedema): Long-term outcome. The Journal of Clinical Endocrinology &amp; Metabolism. 2002;<bold>87</bold>(2):438-446</mixed-citation>\n</ref>'},{id:"B19",body:'<ref id="B19">\n<mixed-citation publication-type="journal">Bellini C, Arioni C, Mazzella M, Campisi C, Taddei G, Boccardo F, et al. Lymphoscintigraphic evaluation of congenital lymphedema of the newborn. Clinical Nuclear Medicine. 2002;<bold>27</bold>(5):383-384</mixed-citation>\n</ref>'},{id:"B20",body:'<ref id="B20">\n<mixed-citation publication-type="journal">Boccardo F, Michelini S, Zilli A, Campisi C. Epidemiology of lymphedema. Phlebolymphology. 1999;<bold>26</bold>:24-28</mixed-citation>\n</ref>'},{id:"B21",body:'<ref id="B21">\n<mixed-citation publication-type="journal">Werngren-Elgstrom M, Lidman D. Lymphoedema of the lower extremities after surgery and radiotherapy for cancer of the cervix. Scandinavian Journal of Plastic and Reconstructive Surgery and Hand Surgery. 1994;<bold>28</bold>(4):289-293</mixed-citation>\n</ref>'},{id:"B22",body:'<ref id="B22">\n<mixed-citation publication-type="journal">Campisi C, Michelini S, Boccardo F, Zilli A. Lymphedema epidemiology in Italy. Lymphology. 1998;<bold>31</bold>(Suppl):243-244</mixed-citation>\n</ref>'},{id:"B23",body:'<ref id="B23">\n<mixed-citation publication-type="book">Casley-Smith J. Modern Treatment for Lymphoedema. Adelaide: The Lymphoedema Association of Australia, Inc.; 1994</mixed-citation>\n</ref>'},{id:"B24",body:'<ref id="B24">\n<mixed-citation publication-type="journal">Dellachà A, Fulcheri E, Boccardo F, Campisi C. Post-surgical lymphedema: Iatrogenic or pre-existing disease? Lymphology. 1998;<bold>31</bold>:562-565</mixed-citation>\n</ref>'},{id:"B25",body:'<ref id="B25">\n<mixed-citation publication-type="book">Földi E, Földi M. Physiothérapie Complete Décongestive. Paris: Editions Frison-Roche; 1993</mixed-citation>\n</ref>'},{id:"B26",body:'<ref id="B26">\n<mixed-citation publication-type="book">Leduc A. Le drainage lymphatique. Paris, Masson: Théorie et pratique; 1980</mixed-citation>\n</ref>'},{id:"B27",body:'<ref id="B27">\n<mixed-citation publication-type="journal">Michelini S, Failla A, Moneta G, Campisi C, Boccardo F. Clinical staging of lymphedema and therapeutical implications. Lymphology. 2002;<bold>35</bold>:168-176</mixed-citation>\n</ref>'},{id:"B28",body:'<ref id="B28">\n<mixed-citation publication-type="journal">Michelini S, Failla A. Linfedemi: Inquadramento diagnostico clinico e strumentale. Minerva Cardioangiologica. 1997;<bold>45</bold>(Suppl I):11-15</mixed-citation>\n</ref>'},{id:"B29",body:'<ref id="B29">\n<mixed-citation publication-type="book">Tosatti E. Lymphatique profonds et lymphoedèmes chroniques des membres. Paris: Masson; 1974</mixed-citation>\n</ref>'},{id:"B30",body:'<ref id="B30">\n<mixed-citation publication-type="book">Vodder E. La méthode Vodder—Le drainage lymphatique manuel. DK-2880, Bagsvaer: Inst. For Lymph Drainage; 1969</mixed-citation>\n</ref>'},{id:"B31",body:'<ref id="B31">\n<mixed-citation publication-type="journal">Olszewski W. Recurrent bacterial dermatolymphangioadenitis (DLA) is responsible for progression of lymphoedema. Lymphology. 1996;<bold>29</bold>(Suppl):331</mixed-citation>\n</ref>'},{id:"B32",body:'<ref id="B32">\n<mixed-citation publication-type="journal">Michelini S, Campisi C, Failla A, Boccardo F. Proposal for stadiation of phlebolymphoedema. European Journal of Lymphology and Related Problems. 1995;<bold>6</bold>(20):I-14</mixed-citation>\n</ref>'},{id:"B33",body:'<ref id="B33">\n<mixed-citation publication-type="journal">Campisi C. Lymphoedema: Modern diagnostic and therapeutic aspects. International Angiology. 1999;<bold>18</bold>(1):14-24</mixed-citation>\n</ref>'},{id:"B34",body:'<ref id="B34">\n<mixed-citation publication-type="journal">Case TC, Witte CL, Witte MH, Unger EC, Williams WH. Magnetic resonance imaging in human lymphedema: Comparison with Lymphangioscintigraphy. Journal of Magnetic Resonance Imaging. 1992;<bold>10</bold>:549-558</mixed-citation>\n</ref>'},{id:"B35",body:'<ref id="B35">\n<mixed-citation publication-type="journal">Ferrel RE, Levinson KL, Esman JH, Komak MA, Lawrence EC, Barmada MM, et al. Hereditary lymphedema evidence for linkage and genetic heterogeneity. Human Molecular Genetics. 1998 Dec. 7;<bold>13</bold>:2073-2078</mixed-citation>\n</ref>'},{id:"B36",body:'<ref id="B36">\n<mixed-citation publication-type="journal">Michelini S, Failla A, Moneta G. Lymphedema: Epidemiology, disability and social costs. Lymphology. 2002;<bold>35</bold>:169-171</mixed-citation>\n</ref>'},{id:"B37",body:'<ref id="B37">\n<mixed-citation publication-type="journal">Michelini S, Failla A, Moneta G, Zinicola V, Romaldini PD. International classification of lymphedema functioning and disability evaluation. European Journal of Lymphology. 2007;<bold>17</bold>(51):16-19</mixed-citation>\n</ref>'},{id:"B38",body:'<ref id="B38">\n<mixed-citation publication-type="journal">Michelini S, De Giorgio D, Cestari M, Corda D, Ricci M, Cardone M, et al. Clinical and genetic study of 46 Italian patients with primary lymphoedema. Lymphology. 2012;<bold>45</bold>:3-12</mixed-citation>\n</ref>'},{id:"B39",body:'<ref id="B39">\n<mixed-citation publication-type="journal">Michelini S, Failla A, Moneta G, Cardone M, Michelotti L, Zinicola V, et al. Linee guida e protocolli diagnostico-terapeutici nel linfedema. Eur. Med. Phys. 2008;<bold>44</bold>(Suppl. 1-3)</mixed-citation>\n</ref>'},{id:"B40",body:'<ref id="B40">\n<mixed-citation publication-type="journal">Michelini S, Failla A, Moneta G, Zinicola V, Macaluso B, Cardone M, et al. Treatment of lymphedema with shockwave therapy: Preliminary study. The European Journal of Lymphology and Related Problems. 2007;<bold>17</bold>(51):29</mixed-citation>\n</ref>'},{id:"B41",body:'<ref id="B41">\n<mixed-citation publication-type="journal">Michelini S, Failla A, Moneta G, Cardone M, Fiorentino A. Immunestimulation and reduction of infective complications in patients with lymphoedema. European Journal of Lymphology and Related Problems. 2009;<bold>20</bold>(56):17-18</mixed-citation>\n</ref>'},{id:"B42",body:'<ref id="B42">\n<mixed-citation publication-type="book">Partsch H. Indirect lymphography in different kinds of leg oedema. In: Lymphology: Advances in Europe. Ecig: Genova; 1989. pp. 95-99</mixed-citation>\n</ref>'},{id:"B43",body:'<ref id="B43">\n<mixed-citation publication-type="journal">Pecking AP, Cluzan RV. Assessment of lymphatic function: 15 years experience using radionuclide methods. Lymphology. 1994;<bold>27</bold>(Suppl):301-304</mixed-citation>\n</ref>'},{id:"B44",body:'<ref id="B44">\n<mixed-citation publication-type="book">Schingale FJ. Lipoedema. In: Schingale FJ, editor. Lymphoedema, Lipoedema: A Guide for those Effected. Hannover: Schlǖtersche; 2003. pp. 64-71</mixed-citation>\n</ref>'},{id:"B45",body:'<ref id="B45">\n<mixed-citation publication-type="book">Trévidic P, Marzelle J, Cormier JM. Apport de la microchirurgie au traitement des lymphoedèmes. In: Editions Techniques -Encycl. Méd. Chir. Paris, France: Techniques chirurgicales-Chirurgie vasculaire; 1994 F.a. 43-225</mixed-citation>\n</ref>'},{id:"B46",body:'<ref id="B46">\n<mixed-citation publication-type="journal">Földi M. The therapy of lymphedema. European Society of Lymphology. 1993-1994;<bold>14</bold>:43-49</mixed-citation>\n</ref>'}],footnotes:[],contributors:[{corresp:"yes",contributorFullName:"Sandro Michelini",address:"s.michelini@acismom.it",affiliation:'<ul class="list"><li>Department of Rehabilitation, S. Giovanni Battista Hospital, Rome, Italy</li></ul>'},{corresp:null,contributorFullName:"Alessandro Failla",address:null,affiliation:'<ul class="list"><li>Department of Rehabilitation, S. Giovanni Battista Hospital, Rome, Italy</li></ul>'},{corresp:null,contributorFullName:"Giovanni Moneta",address:null,affiliation:'<ul class="list"><li>Department of Rehabilitation, S. Giovanni Battista Hospital, Rome, Italy</li></ul>'},{corresp:null,contributorFullName:"Alessandro Fiorentino",address:null,affiliation:'<ul class="list"><li>Department of Rehabilitation, S. Giovanni Battista Hospital, Rome, Italy</li></ul>'},{corresp:null,contributorFullName:"Cardone Marco",address:null,affiliation:'<ul class="list"><li>Department of Rehabilitation, S. Giovanni Battista Hospital, Rome, Italy</li></ul>'}],corrections:null},book:{id:"10426",title:"Inflammation",subtitle:null,fullTitle:"Inflammation",slug:null,publishedDate:null,bookSignature:"Dr. Vijay Kumar, Dr. Alexandro Aguilera Salgado and Dr. Seyyed Shamsadin Athari",coverURL:"https://cdn.intechopen.com/books/images_new/10426.jpg",licenceType:"CC BY 3.0",editedByType:null,isbn:"978-1-83968-642-9",printIsbn:"978-1-83968-641-2",pdfIsbn:"978-1-83968-643-6",editors:[{id:"63844",title:"Dr.",name:"Vijay",middleName:null,surname:"Kumar",slug:"vijay-kumar",fullName:"Vijay Kumar"}],productType:{id:"1",title:"Edited Volume",chapterContentType:"chapter",authoredCaption:"Edited by"}}},profile:{item:{id:"312437",title:"Dr.",name:"Justo",middleName:null,surname:"Aznar Lucea",email:"justo.aznar@ucv.es",fullName:"Justo Aznar Lucea",slug:"justo-aznar-lucea",position:null,biography:null,institutionString:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",totalCites:0,totalChapterViews:"0",outsideEditionCount:0,totalAuthoredChapters:"1",totalEditedBooks:"0",personalWebsiteURL:null,twitterURL:null,linkedinURL:null,institution:null},booksEdited:[],chaptersAuthored:[{id:"70764",title:"Bioethics of Assisted Reproductive Technology",slug:"bioethics-of-assisted-reproductive-technology",abstract:"There is no doubt that for a couple who are having difficulties in conceiving, having a child is an objective good. However, it is also indisputable that assisted reproduction techniques raise clear ethical issues. In order to begin this bioethical reflection, it should be clearly established that the early embryo, which can be manipulated or destroyed using these techniques, is a living being of our species. We believe this is unquestionable from a biological point of view, and it therefore deserves our full respect. The bioethical assessment of assisted reproduction techniques includes analysis of the embryo losses caused by their selection and manipulation through preimplantation genetic diagnosis, ‘social freezing’ or the possible lack of rigour in the information provided by the clinics involved, to which must be added the higher morbidity reported in babies born as a result of these procedures.",signatures:"Justo Aznar and Julio Tudela",authors:[{id:"312437",title:"Dr.",name:"Justo",surname:"Aznar Lucea",fullName:"Justo Aznar Lucea",slug:"justo-aznar-lucea",email:"justo.aznar@ucv.es"},{id:"312692",title:"Dr.",name:"Julio",surname:"Tudela",fullName:"Julio Tudela",slug:"julio-tudela",email:"julio.tudela@ucv.es"}],book:{id:"7725",title:"Innovations In Assisted Reproduction Technology",slug:"innovations-in-assisted-reproduction-technology",productType:{id:"1",title:"Edited Volume"}}}],collaborators:[{id:"75888",title:"Prof.",name:"Alexander",surname:"Shpakov",slug:"alexander-shpakov",fullName:"Alexander Shpakov",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:null},{id:"81685",title:"Dr.",name:"Kira",surname:"Derkach",slug:"kira-derkach",fullName:"Kira Derkach",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:null},{id:"212804",title:"Dr.",name:"Goran",surname:"Mitulović",slug:"goran-mitulovic",fullName:"Goran Mitulović",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/212804/images/system/212804.png",biography:"Dr. Goran Mitulović (ORCID 0000-0003-1964-3965) is the head of the Proteomics Core Facility, Medical University of Vienna. He has more than twenty years of experience developing hardware and analytical methods for multidimensional nano HPLC-MS separation and detection methods for proteins and peptides. He conducted his research with LC Packings/Dionex in Amsterdam; IMP and IMBA in Vienna; and the Medical University of Vienna. \nHis research interests include mechanistic chromatographic separation of peptides and proteins on different stationary phases (polar, ion-exchange, hydrophobic, and hydrophilic phases), improvement of mass spectrometric response based on the optimized composition of the chromatographic mobile phase, and development of clinical proteomics methods and approaches for use in diagnostics.",institutionString:"Medical University of Vienna",institution:{name:"Medical University of Vienna",institutionURL:null,country:{name:"Austria"}}},{id:"220214",title:"Prof.",name:"Nidhi",surname:"Sharma",slug:"nidhi-sharma",fullName:"Nidhi Sharma",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/220214/images/system/220214.jpg",biography:"Dr. Nidhi Sharma received a MBBS and MS from Banaras Hindu University,\nVaranasi, India. She is a fellow of the Indian College of Obstetrics and Gynecology, fellow of assisted reproductive techniques, and Professor of Obstetrics and Gynecology at Saveetha University, India. Dr. Sharma has 80 indexed publications and has authored several chapters in textbooks. She received her PhD in Obstetrics and Gynecology from Saveetha University, India, and Diploma in IVF and Reproductive Medicine from UKSH Universitätsklilikum Schleswig-Holstein, Germany. Dr. Sharma has been a member of the teaching faculty of MBBS, MS, and PhD for 15 years. She is course coordinator and academic supervisor of BSc in Reproductive Biology, MSc in Clinical Embryology, Fellowship in Reproductive Medicine, and PhD in Reproductive Medicine at Saveetha University.",institutionString:"Saveetha University",institution:{name:"Saveetha University",institutionURL:null,country:{name:"India"}}},{id:"224544",title:"Dr.",name:"Sudakshina",surname:"Chakrabarti",slug:"sudakshina-chakrabarti",fullName:"Sudakshina Chakrabarti",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/224544/images/13039_n.jpg",biography:"Dr. Sudakshina Chakrabarti is Associate Professor of Anatomy at Saveetha Medical College and hHospital, Chennai, India. She obtained a MBBS from Kempegowda Institute of Medical Sciences, Bangalore. Dr. Chakrabarti completed a postgraduate degree in Obstetrics and Gynecology from  J.J.M Medical College, Davangere, Karnataka, India; an MD in Anatomy from Sri Ramachandra Medical College, Chennai, India; and is currently pursuing a PhD at Saveetha University, Chennai, India.\nShe is an ACLS, BLS, and PALS instructor under the American Heart Association and involved in simulation education. She has recently completed an Advanced Course in Medical Education and is an active member of the Medical Education Unit at  Saveetha Medical College and Hospital Chennai with experience in conducting faculty development programs.",institutionString:"Saveetha University",institution:null},{id:"245241",title:"MSc.",name:"Andrey",surname:"Bakhtyukov",slug:"andrey-bakhtyukov",fullName:"Andrey Bakhtyukov",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:null},{id:"256238",title:"Dr.",name:"Tanja",surname:"Panić-Janković",slug:"tanja-panic-jankovic",fullName:"Tanja Panić-Janković",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:null},{id:"288616",title:"Dr.",name:"Jan",surname:"Tesarik",slug:"jan-tesarik",fullName:"Jan Tesarik",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:null},{id:"303442",title:"Dr.",name:"Dmitry",surname:"Dar’in",slug:"dmitry-dar'in",fullName:"Dmitry Dar’in",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:null},{id:"306939",title:"Dr.",name:"Eswari",surname:"Beeram",slug:"eswari-beeram",fullName:"Eswari Beeram",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/no_image.jpg",biography:null,institutionString:null,institution:null}]},generic:{page:{slug:"indexing-and-abstracting",title:"Indexing and Abstracting",intro:"<p>IntechOpen books are indexed by the following abstracting and indexing services:</p>",metaTitle:"Indexing and Abstracting",metaDescription:"IntechOpen was built by scientists, for scientists. We understand the community we serve, but to bring an even better service to the table for IntechOpen Authors and Academic Editors, we partnered with the leading companies and associations in the industry and beyond.",metaKeywords:null,canonicalURL:"/page/indexing-and-abstracting",contentRaw:'[{"type":"htmlEditorComponent","content":"<p><a href=\\"https://clarivate.com/webofsciencegroup/solutions/webofscience-bkci/\\" target=\\"_blank\\">Clarivate Web Of Science - Book Citation Index</a></p>\\n\\n<ul>\\n\\t<li>BKCI is a part of Web of Science Core Collection (WoSCC) and the world&rsquo;s leading citation index with multidisciplinary content from the top tier international and regional journals, conference proceedings, and books. The Book Citation Index includes over 104,500 editorially selected books, with 10,000 new books added each year. Containing more than 53.2 million cited references, coverage dates back from 2005 to present. The Book Citation Index is multidisciplinary, covering disciplines across the sciences, social sciences, and arts &amp; humanities.</li>\\n</ul>\\n\\n<p><a href=\\"https://clarivate.com/webofsciencegroup/solutions/webofscience-biosis-previews/\\" target=\\"_blank\\">BIOSIS Previews</a></p>\\n\\n<ul>\\n\\t<li>Produced by the Web Of Science group, BIOSIS Previews research database provides researchers with the most current sources of life sciences information, including journals, conferences, patents, books, review articles, and more. Researchers can also access multidisciplinary coverage via specialized indexing such as MeSH disease terms, CAS registry numbers, Sequence Databank Numbers and Major Concepts.</li>\\n</ul>\\n\\n<p><a href=\\"https://clarivate.com/webofsciencegroup/solutions/webofscience-zoological-record/\\" target=\\"_blank\\">Zoological Record</a></p>\\n\\n<ul>\\n\\t<li>Produced by the Web Of Science group, Zoological Record is the world&rsquo;s oldest continuing database of animal biology. It is considered the world&rsquo;s leading taxonomic reference, and with coverage back to 1864, has long acted as the world&rsquo;s unofficial register of animal names. The broad scope of coverage ranges from biodiversity and the environment to taxonomy and veterinary sciences.</li>\\n</ul>\\n\\n<p><a href=\\"https://scholar.google.com/intl/en/scholar/about.html\\" target=\\"_blank\\">Google Scholar</a></p>\\n\\n<ul>\\n\\t<li>Provides a simple way to search broadly for scholarly literature. Includes peer-reviewed papers, theses, books, abstracts and articles, from academic publishers, professsional societies, preprint repositories, universities and other scholarly organizations. Google Scholar sorts articles by weighing the full text of each article, the author, the publication in which the article appears, and how often the article has been cited in other scholarly literature, so that the most relevant results are returned on the first page.</li>\\n</ul>\\n\\n<p><a href=\\"https://academic.microsoft.com/\\" target=\\"_blank\\">Microsoft Academic</a></p>\\n\\n<ul>\\n\\t<li>Microsoft Academic is a project exploring how to assist human conducting scientific research by leveraging machine&rsquo;s cognitive power in memory, computation, sensing, attention, and endurance. Re-launched in 2016, the tool features an entirely new data structure and search engine using semantic search technologies. The Academic Knowledge API offers information retrieval from the underlying database using REST endpoints for advanced research purposes.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.bl.uk/\\" target=\\"_blank\\">British Library</a></p>\\n\\n<ul>\\n\\t<li>The national library of the United Kingdom includes 150 million manuscripts, maps, newspapers, magazines, prints and drawings, music scores, and patents. Online catalogues, information and exhibitions can be found on its website. The library operates the world&#39;s largest document delivery service, providing millions of items a year to national and international customers.</li>\\n</ul>\\n\\n<p><a href=\\"https://digitalna.nsk.hr/pb/\\" target=\\"_blank\\">Croatian Library (digital NSK)</a></p>\\n\\n<ul>\\n\\t<li>The digital NSK portal is the central gathering place for the digital collections of the National and University Library (NSK) in Croatia. It was established in 2016 to provide access to the Library&rsquo;s digital and digitized material collections regardless of storage location. The digital NSK portal enables a unified search of digitized material from the NSK Special Collections - books, visual material, maps and music material. From the end of 2019, all thematic portals are available independently: Digital Books, Digitized Manuscripts, Digitized Visual Materials, Digital Music Materials and Digitized Cartographic Materials (established in 2017). Currently available only in Croatian.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.crossref.org/\\" target=\\"_blank\\">Crossref</a></p>\\n\\n<ul>\\n\\t<li>The official DOI (digital object identifier) link registration agency for scholarly and professional publications. Crossref operates a cross-publisher citation linking system that allows a researcher to click on a reference citation on one publisher&rsquo;s platform and link directly to the cited content on another publisher&rsquo;s platform, subject to the target publisher&rsquo;s access control practices. This citation-linking network covers millions of articles and other content items from several hundred scholarly and professional publishers.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.dimensions.ai/\\" target=\\"_blank\\">Dimensions</a></p>\\n\\n<ul>\\n\\t<li>Dimensions is a next-generation linked research information system that makes it easier to find and access the most relevant information, analyze the academic and broader outcomes of research, and gather insights to inform future strategy. Dimensions delivers an array of search and discovery, analytical, and research management tools, all in a single platform. Developed in collaboration with over 100 leading research organizations around the world, it brings together over 128 million publications, grants, policy, data and metrics for the first time, enabling users to explore over 4 billion connections between them.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.doabooks.org/doab?uiLanguage=en\\" target=\\"_blank\\">DOAB</a></p>\\n\\n<ul>\\n\\t<li>The primary aim of DOAB (Directory of Open Access Books) is to increase discoverability of Open Access books. Metadata will be harvestable in order to maximize dissemination, visibility and impact. Aggregators can integrate the records in their commercial services and libraries can integrate the directory into their online catalogues, helping scholars and students to discover the books.</li>\\n</ul>\\n\\n<p><a href=\\"https://library.oapen.org/\\" target=\\"_blank\\">OAPEN</a></p>\\n\\n<ul>\\n\\t<li>OAPEN is dedicated to open access, peer-reviewed books. OAPEN operates two platforms, the OAPEN Library (www.oapen.org), a central repository for hosting and disseminating OA books, and the Directory of Open Access Books (DOAB, www.doabooks.org), a discovery service for OA books.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.openaire.eu/\\" target=\\"_blank\\">OpenAIRE</a></p>\\n\\n<ul>\\n\\t<li>OpenAIRE aims at promoting and implementing the directives of the European Commission (EC) and the European Research Council on the promotion and funding of science and research. OpenAIRE supports the Open Access Mandate and the Open Research Data Pilot developed as part of the Horizon 2020 projects.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.ebsco.com/products/ebscohost-research-platform\\" target=\\"_blank\\">EBSCOhost Research Platfrom</a></p>\\n\\n<ul>\\n\\t<li>An integrated information service combining reference databases, subscription management, online journals, books and linking services. Widely used by libraries, schools, government institutions, medical institutions, corporations and others.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.exlibrisgroup.com/products/primo-discovery-service/sfx-link-resolver/\\" target=\\"_blank\\">Ex Libris SFX&reg;</a></p>\\n\\n<ul>\\n\\t<li>SFX&reg; link resolver gives patrons and librarians a wealth of features that optimize management of and access to resources. It provides patrons with a direct route to electronic full-text records through OpenURL linking, delivers alternative links for further resource discovery, access to journals, and more. Released in 2001 as the first OpenURL resolver, SFX is continuously enhanced to support the newest industry developments and meet the evolving needs of customers. The records include a mix of scholarly material &ndash; primarily articles and e-books &ndash; but also conference proceedings, newspaper articles, and more.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.worldcat.org/\\" target=\\"_blank\\">OCLC (Online Computer Library Center) - WorldCat&reg; Digital Collection Gateway</a></p>\\n\\n<ul>\\n\\t<li>A non-profit, membership, computer library service and research organization dedicated to the public purposes of furthering access to the world&#39;s information and reducing information costs. More than 41,555 libraries in 112 countries and territories around the world use OCLC services to locate, acquire, catalogue, lend and preserve library materials.</li>\\n</ul>\\n\\n<p><a href=\\"https://core.ac.uk/\\" target=\\"_blank\\">CORE</a></p>\\n\\n<ul>\\n\\t<li>The world&rsquo;s largest collection of open access research papers. CORE&#39;s mission is to aggregate all open access research outputs from repositories and journals worldwide and make them available to the public. In this way CORE facilitates free unrestricted access to research for all.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.perlego.com/publisher/3346/intechopen?queryID=fbd331ba3205c743c41d8b6cefeffa24&amp;searchPosition=1&amp;searchIndexType=publishers&amp;page=1&amp;language=English&amp;publicationDate=&amp;topic=&amp;author=&amp;format=&amp;sortBy=popular\\" target=\\"_blank\\">Perlego</a></p>\\n\\n<ul>\\n\\t<li>Perlego is a digital online library focusing on the delivery of academic, professional and non-fiction eBooks. It is a subscription-based service that offers users unlimited access to these texts for the duration of their subscription, however IntechOpen content integrated on the platform will always be available for free. They have been billed as &ldquo;the Spotify for Textbooks&rdquo; by the Evening Standard. Perlego is based in London but is available to users worldwide.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.mysciencework.com/\\" target=\\"_blank\\">MyScienceWork</a></p>\\n\\n<ul>\\n\\t<li>MyScienceWork provides a suite of data-driven solutions for research institutions, scientific publishers and private-sector R&amp;D companies. MyScienceWork&#39;s comprehensive database includes more than 90 million scientific publications and 12 million patents.</li>\\n</ul>\\n\\n<p><a href=\\"http://eng.scholar.cnki.net/\\" target=\\"_blank\\">CNKI</a></p>\\n\\n<ul>\\n\\t<li>CNKI (China National Knowledge Infrastructure) is a key national information construction project under the lead of Tsinghua University, and supported by PRC Ministry of Education, PRC Ministry of Science, Propaganda Department of the Communist Party of China and PRC General Administration of Press and Publication. CNKI has built a comprehensive China Integrated Knowledge Resources System, including journals, doctoral dissertations, masters&#39; theses, proceedings, newspapers, yearbooks, statistical yearbooks, ebooks, patents, standards and so on. CNKI keeps integrating new contents and developing new products in 2 aspects: full-text academic resources, software on digitization and knowledge management. Began with academic journals, CNKI has become the largest and mostly-used academic online library in China.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.cnpereading.com/\\" target=\\"_blank\\">CNPIEC - CNPeReading</a></p>\\n\\n<ul>\\n\\t<li>As one of the largest digital content platform in China,independently developed by CNPIEC, CNPeReading positions herself as &ldquo;One Platform,Vast Content, Global Services&rdquo;. Through their new cooperation model and service philosophy, CNPeReading provides integrated promotion and marketing solutionsfor upstream publishers, one-stop, triune, recommendation, online reading and management servicesfor downstream institutions &amp; libraries.</li>\\n</ul>\\n\\n<p><a href=\\"https://eric.ed.gov/\\" target=\\"_blank\\">ERIC</a></p>\\n\\n<ul>\\n\\t<li>ERIC (Education Resources Information Center), sponsored by the Institute of Education Sciences (IES) of the U.S. Department of Education, provides access to education literature to support the use of educational research and information to improve practice in learning, teaching, educational decision-making, and research. The ERIC website is available to the public for searching more than one million citations going back to 1966.</li>\\n</ul>\\n\\n<p><a href=\\"https://dl.acm.org/\\" target=\\"_blank\\">ACM Digital Library</a></p>\\n\\n<ul>\\n\\t<li>The ACM Digital Library is a research, discovery and networking platform containing: The Full-Text Collection of all ACM publications, including journals, conference proceedings, technical magazines, newsletters and books. A collection of curated and hosted full-text publications from select publishers.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.base-search.net/\\" target=\\"_blank\\">BASE</a></p>\\n\\n<ul>\\n\\t<li>BASE (Bielefeld Academic Search Engine) is one of the world&#39;s most voluminous search sengines especially for academic web resources, e.g. journal articles, preprints, digital collections, images / videos or research data. BASE facilitates effective and targeted searches and retrieves high quality, academically relevant results. Other than search engines like Google or Bing BASE searches the deep web as well. The sources which are included in BASE are intellectually selected (by people from the BASE team) and reviewed. That&#39;s why data garbage and spam do not occur.</li>\\n</ul>\\n\\n<p><a href=\\"https://zbmath.org/\\" target=\\"_blank\\">zbMath</a></p>\\n\\n<ul>\\n\\t<li>Zentralblatt MATH (zbMATH) is the world&rsquo;s most comprehensive and longest-running abstracting and reviewing service in pure and applied mathematics. It is edited by the European Mathematical Society (EMS), the Heidelberg Academy of Sciences and Humanities and FIZ Karlsruhe. zbMATH provides easy access to bibliographic data, reviews and abstracts from all areas of pure mathematics as well as applications, in particular to natural sciences, computer science, economics and engineering. It also covers history and philosophy of mathematics and university education. All entries are classified according to the Mathematics Subject Classification Scheme (MSC 2020) and are equipped with keywords in order to characterize their particular content.</li>\\n</ul>\\n\\n<p><a href=\\"https://ideas.repec.org/\\" target=\\"_blank\\">RePEc IDEAS</a></p>\\n\\n<ul>\\n\\t<li>IDEAS is the largest bibliographic database dedicated to Economics and available freely on the Internet. Based on RePEc, it indexes over 3,100,000 items of research, including over 2,900,000 that can be downloaded in full text. RePEc (Research Papers in Economics) is a large volunteer effort to enhance the free dissemination of research in Economics which includes bibliographic metadata from over 2,000 participating archives, including all the major publishers and research outlets. IDEAS is just one of several services that use RePEc data.</li>\\n</ul>\\n\\n<p><a href=\\"https://www.cas.org/\\" target=\\"_blank\\">Chemical Abstracts Service</a></p>\\n\\n<ul>\\n\\t<li>As the authoritative source for chemical names, structures and CAS Registry Numbers&reg;, the CAS substance collection, CAS REGISTRY&reg;, serves as a universal standard for chemists worldwide. Covering advances in chemistry and related sciences over the last 150 years, the CAS content collection empowers researchers, business leaders, and information professionals around the world with immediate access to the reliable information they need to fuel innovation.</li>\\n</ul>\\n\\n<p>&nbsp;</p>\\n\\n<p>&nbsp;</p>\\n"}]'},components:[{type:"htmlEditorComponent",content:'<p><a href="https://clarivate.com/webofsciencegroup/solutions/webofscience-bkci/" target="_blank">Clarivate Web Of Science - Book Citation Index</a></p>\n\n<ul>\n\t<li>BKCI is a part of Web of Science Core Collection (WoSCC) and the world&rsquo;s leading citation index with multidisciplinary content from the top tier international and regional journals, conference proceedings, and books. The Book Citation Index includes over 104,500 editorially selected books, with 10,000 new books added each year. Containing more than 53.2 million cited references, coverage dates back from 2005 to present. The Book Citation Index is multidisciplinary, covering disciplines across the sciences, social sciences, and arts &amp; humanities.</li>\n</ul>\n\n<p><a href="https://clarivate.com/webofsciencegroup/solutions/webofscience-biosis-previews/" target="_blank">BIOSIS Previews</a></p>\n\n<ul>\n\t<li>Produced by the Web Of Science group, BIOSIS Previews research database provides researchers with the most current sources of life sciences information, including journals, conferences, patents, books, review articles, and more. Researchers can also access multidisciplinary coverage via specialized indexing such as MeSH disease terms, CAS registry numbers, Sequence Databank Numbers and Major Concepts.</li>\n</ul>\n\n<p><a href="https://clarivate.com/webofsciencegroup/solutions/webofscience-zoological-record/" target="_blank">Zoological Record</a></p>\n\n<ul>\n\t<li>Produced by the Web Of Science group, Zoological Record is the world&rsquo;s oldest continuing database of animal biology. It is considered the world&rsquo;s leading taxonomic reference, and with coverage back to 1864, has long acted as the world&rsquo;s unofficial register of animal names. The broad scope of coverage ranges from biodiversity and the environment to taxonomy and veterinary sciences.</li>\n</ul>\n\n<p><a href="https://scholar.google.com/intl/en/scholar/about.html" target="_blank">Google Scholar</a></p>\n\n<ul>\n\t<li>Provides a simple way to search broadly for scholarly literature. Includes peer-reviewed papers, theses, books, abstracts and articles, from academic publishers, professsional societies, preprint repositories, universities and other scholarly organizations. Google Scholar sorts articles by weighing the full text of each article, the author, the publication in which the article appears, and how often the article has been cited in other scholarly literature, so that the most relevant results are returned on the first page.</li>\n</ul>\n\n<p><a href="https://academic.microsoft.com/" target="_blank">Microsoft Academic</a></p>\n\n<ul>\n\t<li>Microsoft Academic is a project exploring how to assist human conducting scientific research by leveraging machine&rsquo;s cognitive power in memory, computation, sensing, attention, and endurance. Re-launched in 2016, the tool features an entirely new data structure and search engine using semantic search technologies. The Academic Knowledge API offers information retrieval from the underlying database using REST endpoints for advanced research purposes.</li>\n</ul>\n\n<p><a href="https://www.bl.uk/" target="_blank">British Library</a></p>\n\n<ul>\n\t<li>The national library of the United Kingdom includes 150 million manuscripts, maps, newspapers, magazines, prints and drawings, music scores, and patents. Online catalogues, information and exhibitions can be found on its website. The library operates the world&#39;s largest document delivery service, providing millions of items a year to national and international customers.</li>\n</ul>\n\n<p><a href="https://digitalna.nsk.hr/pb/" target="_blank">Croatian Library (digital NSK)</a></p>\n\n<ul>\n\t<li>The digital NSK portal is the central gathering place for the digital collections of the National and University Library (NSK) in Croatia. It was established in 2016 to provide access to the Library&rsquo;s digital and digitized material collections regardless of storage location. The digital NSK portal enables a unified search of digitized material from the NSK Special Collections - books, visual material, maps and music material. From the end of 2019, all thematic portals are available independently: Digital Books, Digitized Manuscripts, Digitized Visual Materials, Digital Music Materials and Digitized Cartographic Materials (established in 2017). Currently available only in Croatian.</li>\n</ul>\n\n<p><a href="https://www.crossref.org/" target="_blank">Crossref</a></p>\n\n<ul>\n\t<li>The official DOI (digital object identifier) link registration agency for scholarly and professional publications. Crossref operates a cross-publisher citation linking system that allows a researcher to click on a reference citation on one publisher&rsquo;s platform and link directly to the cited content on another publisher&rsquo;s platform, subject to the target publisher&rsquo;s access control practices. This citation-linking network covers millions of articles and other content items from several hundred scholarly and professional publishers.</li>\n</ul>\n\n<p><a href="https://www.dimensions.ai/" target="_blank">Dimensions</a></p>\n\n<ul>\n\t<li>Dimensions is a next-generation linked research information system that makes it easier to find and access the most relevant information, analyze the academic and broader outcomes of research, and gather insights to inform future strategy. Dimensions delivers an array of search and discovery, analytical, and research management tools, all in a single platform. Developed in collaboration with over 100 leading research organizations around the world, it brings together over 128 million publications, grants, policy, data and metrics for the first time, enabling users to explore over 4 billion connections between them.</li>\n</ul>\n\n<p><a href="https://www.doabooks.org/doab?uiLanguage=en" target="_blank">DOAB</a></p>\n\n<ul>\n\t<li>The primary aim of DOAB (Directory of Open Access Books) is to increase discoverability of Open Access books. Metadata will be harvestable in order to maximize dissemination, visibility and impact. Aggregators can integrate the records in their commercial services and libraries can integrate the directory into their online catalogues, helping scholars and students to discover the books.</li>\n</ul>\n\n<p><a href="https://library.oapen.org/" target="_blank">OAPEN</a></p>\n\n<ul>\n\t<li>OAPEN is dedicated to open access, peer-reviewed books. OAPEN operates two platforms, the OAPEN Library (www.oapen.org), a central repository for hosting and disseminating OA books, and the Directory of Open Access Books (DOAB, www.doabooks.org), a discovery service for OA books.</li>\n</ul>\n\n<p><a href="https://www.openaire.eu/" target="_blank">OpenAIRE</a></p>\n\n<ul>\n\t<li>OpenAIRE aims at promoting and implementing the directives of the European Commission (EC) and the European Research Council on the promotion and funding of science and research. OpenAIRE supports the Open Access Mandate and the Open Research Data Pilot developed as part of the Horizon 2020 projects.</li>\n</ul>\n\n<p><a href="https://www.ebsco.com/products/ebscohost-research-platform" target="_blank">EBSCOhost Research Platfrom</a></p>\n\n<ul>\n\t<li>An integrated information service combining reference databases, subscription management, online journals, books and linking services. Widely used by libraries, schools, government institutions, medical institutions, corporations and others.</li>\n</ul>\n\n<p><a href="https://www.exlibrisgroup.com/products/primo-discovery-service/sfx-link-resolver/" target="_blank">Ex Libris SFX&reg;</a></p>\n\n<ul>\n\t<li>SFX&reg; link resolver gives patrons and librarians a wealth of features that optimize management of and access to resources. It provides patrons with a direct route to electronic full-text records through OpenURL linking, delivers alternative links for further resource discovery, access to journals, and more. Released in 2001 as the first OpenURL resolver, SFX is continuously enhanced to support the newest industry developments and meet the evolving needs of customers. The records include a mix of scholarly material &ndash; primarily articles and e-books &ndash; but also conference proceedings, newspaper articles, and more.</li>\n</ul>\n\n<p><a href="https://www.worldcat.org/" target="_blank">OCLC (Online Computer Library Center) - WorldCat&reg; Digital Collection Gateway</a></p>\n\n<ul>\n\t<li>A non-profit, membership, computer library service and research organization dedicated to the public purposes of furthering access to the world&#39;s information and reducing information costs. More than 41,555 libraries in 112 countries and territories around the world use OCLC services to locate, acquire, catalogue, lend and preserve library materials.</li>\n</ul>\n\n<p><a href="https://core.ac.uk/" target="_blank">CORE</a></p>\n\n<ul>\n\t<li>The world&rsquo;s largest collection of open access research papers. CORE&#39;s mission is to aggregate all open access research outputs from repositories and journals worldwide and make them available to the public. In this way CORE facilitates free unrestricted access to research for all.</li>\n</ul>\n\n<p><a href="https://www.perlego.com/publisher/3346/intechopen?queryID=fbd331ba3205c743c41d8b6cefeffa24&amp;searchPosition=1&amp;searchIndexType=publishers&amp;page=1&amp;language=English&amp;publicationDate=&amp;topic=&amp;author=&amp;format=&amp;sortBy=popular" target="_blank">Perlego</a></p>\n\n<ul>\n\t<li>Perlego is a digital online library focusing on the delivery of academic, professional and non-fiction eBooks. It is a subscription-based service that offers users unlimited access to these texts for the duration of their subscription, however IntechOpen content integrated on the platform will always be available for free. They have been billed as &ldquo;the Spotify for Textbooks&rdquo; by the Evening Standard. Perlego is based in London but is available to users worldwide.</li>\n</ul>\n\n<p><a href="https://www.mysciencework.com/" target="_blank">MyScienceWork</a></p>\n\n<ul>\n\t<li>MyScienceWork provides a suite of data-driven solutions for research institutions, scientific publishers and private-sector R&amp;D companies. MyScienceWork&#39;s comprehensive database includes more than 90 million scientific publications and 12 million patents.</li>\n</ul>\n\n<p><a href="http://eng.scholar.cnki.net/" target="_blank">CNKI</a></p>\n\n<ul>\n\t<li>CNKI (China National Knowledge Infrastructure) is a key national information construction project under the lead of Tsinghua University, and supported by PRC Ministry of Education, PRC Ministry of Science, Propaganda Department of the Communist Party of China and PRC General Administration of Press and Publication. CNKI has built a comprehensive China Integrated Knowledge Resources System, including journals, doctoral dissertations, masters&#39; theses, proceedings, newspapers, yearbooks, statistical yearbooks, ebooks, patents, standards and so on. CNKI keeps integrating new contents and developing new products in 2 aspects: full-text academic resources, software on digitization and knowledge management. Began with academic journals, CNKI has become the largest and mostly-used academic online library in China.</li>\n</ul>\n\n<p><a href="https://www.cnpereading.com/" target="_blank">CNPIEC - CNPeReading</a></p>\n\n<ul>\n\t<li>As one of the largest digital content platform in China,independently developed by CNPIEC, CNPeReading positions herself as &ldquo;One Platform,Vast Content, Global Services&rdquo;. Through their new cooperation model and service philosophy, CNPeReading provides integrated promotion and marketing solutionsfor upstream publishers, one-stop, triune, recommendation, online reading and management servicesfor downstream institutions &amp; libraries.</li>\n</ul>\n\n<p><a href="https://eric.ed.gov/" target="_blank">ERIC</a></p>\n\n<ul>\n\t<li>ERIC (Education Resources Information Center), sponsored by the Institute of Education Sciences (IES) of the U.S. Department of Education, provides access to education literature to support the use of educational research and information to improve practice in learning, teaching, educational decision-making, and research. The ERIC website is available to the public for searching more than one million citations going back to 1966.</li>\n</ul>\n\n<p><a href="https://dl.acm.org/" target="_blank">ACM Digital Library</a></p>\n\n<ul>\n\t<li>The ACM Digital Library is a research, discovery and networking platform containing: The Full-Text Collection of all ACM publications, including journals, conference proceedings, technical magazines, newsletters and books. A collection of curated and hosted full-text publications from select publishers.</li>\n</ul>\n\n<p><a href="https://www.base-search.net/" target="_blank">BASE</a></p>\n\n<ul>\n\t<li>BASE (Bielefeld Academic Search Engine) is one of the world&#39;s most voluminous search sengines especially for academic web resources, e.g. journal articles, preprints, digital collections, images / videos or research data. BASE facilitates effective and targeted searches and retrieves high quality, academically relevant results. Other than search engines like Google or Bing BASE searches the deep web as well. The sources which are included in BASE are intellectually selected (by people from the BASE team) and reviewed. That&#39;s why data garbage and spam do not occur.</li>\n</ul>\n\n<p><a href="https://zbmath.org/" target="_blank">zbMath</a></p>\n\n<ul>\n\t<li>Zentralblatt MATH (zbMATH) is the world&rsquo;s most comprehensive and longest-running abstracting and reviewing service in pure and applied mathematics. It is edited by the European Mathematical Society (EMS), the Heidelberg Academy of Sciences and Humanities and FIZ Karlsruhe. zbMATH provides easy access to bibliographic data, reviews and abstracts from all areas of pure mathematics as well as applications, in particular to natural sciences, computer science, economics and engineering. It also covers history and philosophy of mathematics and university education. All entries are classified according to the Mathematics Subject Classification Scheme (MSC 2020) and are equipped with keywords in order to characterize their particular content.</li>\n</ul>\n\n<p><a href="https://ideas.repec.org/" target="_blank">RePEc IDEAS</a></p>\n\n<ul>\n\t<li>IDEAS is the largest bibliographic database dedicated to Economics and available freely on the Internet. Based on RePEc, it indexes over 3,100,000 items of research, including over 2,900,000 that can be downloaded in full text. RePEc (Research Papers in Economics) is a large volunteer effort to enhance the free dissemination of research in Economics which includes bibliographic metadata from over 2,000 participating archives, including all the major publishers and research outlets. IDEAS is just one of several services that use RePEc data.</li>\n</ul>\n\n<p><a href="https://www.cas.org/" target="_blank">Chemical Abstracts Service</a></p>\n\n<ul>\n\t<li>As the authoritative source for chemical names, structures and CAS Registry Numbers&reg;, the CAS substance collection, CAS REGISTRY&reg;, serves as a universal standard for chemists worldwide. Covering advances in chemistry and related sciences over the last 150 years, the CAS content collection empowers researchers, business leaders, and information professionals around the world with immediate access to the reliable information they need to fuel innovation.</li>\n</ul>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n'}]},successStories:{items:[]},authorsAndEditors:{filterParams:{},profiles:[{id:"396",title:"Dr.",name:"Vedran",middleName:null,surname:"Kordic",slug:"vedran-kordic",fullName:"Vedran Kordic",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/396/images/7281_n.png",biography:"After obtaining his Master's degree in Mechanical Engineering he continued his education at the Vienna University of Technology where he obtained his PhD degree in 2004. He worked as a researcher at the Automation and Control Institute, Faculty of Electrical Engineering, Vienna University of Technology until 2008. His studies in robotics lead him not only to a PhD degree but also inspired him to co-found and build the International Journal of Advanced Robotic Systems - world's first Open Access journal in the field of robotics.",institutionString:null,institution:{name:"TU Wien",country:{name:"Austria"}}},{id:"441",title:"Ph.D.",name:"Jaekyu",middleName:null,surname:"Park",slug:"jaekyu-park",fullName:"Jaekyu Park",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/441/images/1881_n.jpg",biography:null,institutionString:null,institution:{name:"LG Corporation (South Korea)",country:{name:"Korea, South"}}},{id:"465",title:"Dr",name:"Christian",middleName:null,surname:"Martens",slug:"christian-martens",fullName:"Christian Martens",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:null},{id:"479",title:"Dr.",name:"Valentina",middleName:null,surname:"Colla",slug:"valentina-colla",fullName:"Valentina Colla",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/479/images/358_n.jpg",biography:null,institutionString:null,institution:{name:"Sant'Anna School of Advanced Studies",country:{name:"Italy"}}},{id:"494",title:"PhD",name:"Loris",middleName:null,surname:"Nanni",slug:"loris-nanni",fullName:"Loris Nanni",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/494/images/system/494.jpg",biography:"Loris Nanni received his Master Degree cum laude on June-2002 from the University of Bologna, and the April 26th 2006 he received his Ph.D. in Computer Engineering at DEIS, University of Bologna. On September, 29th 2006 he has won a post PhD fellowship from the university of Bologna (from October 2006 to October 2008), at the competitive examination he was ranked first in the industrial engineering area. He extensively served as referee for several international journals. He is author/coauthor of more than 100 research papers. He has been involved in some projects supported by MURST and European Community. His research interests include pattern recognition, bioinformatics, and biometric systems (fingerprint classification and recognition, signature verification, face recognition).",institutionString:null,institution:null},{id:"496",title:"Dr.",name:"Carlos",middleName:null,surname:"Leon",slug:"carlos-leon",fullName:"Carlos Leon",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:{name:"University of Seville",country:{name:"Spain"}}},{id:"512",title:"Dr.",name:"Dayang",middleName:null,surname:"Jawawi",slug:"dayang-jawawi",fullName:"Dayang Jawawi",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:{name:"University of Technology Malaysia",country:{name:"Malaysia"}}},{id:"528",title:"Dr.",name:"Kresimir",middleName:null,surname:"Delac",slug:"kresimir-delac",fullName:"Kresimir Delac",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/528/images/system/528.jpg",biography:"K. Delac received his B.Sc.E.E. degree in 2003 and is currentlypursuing a Ph.D. degree at the University of Zagreb, Faculty of Electrical Engineering andComputing. His current research interests are digital image analysis, pattern recognition andbiometrics.",institutionString:null,institution:{name:"University of Zagreb",country:{name:"Croatia"}}},{id:"557",title:"Dr.",name:"Andon",middleName:"Venelinov",surname:"Topalov",slug:"andon-topalov",fullName:"Andon Topalov",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/557/images/1927_n.jpg",biography:"Dr. Andon V. Topalov received the MSc degree in Control Engineering from the Faculty of Information Systems, Technologies, and Automation at Moscow State University of Civil Engineering (MGGU) in 1979. He then received his PhD degree in Control Engineering from the Department of Automation and Remote Control at Moscow State Mining University (MGSU), Moscow, in 1984. From 1985 to 1986, he was a Research Fellow in the Research Institute for Electronic Equipment, ZZU AD, Plovdiv, Bulgaria. In 1986, he joined the Department of Control Systems, Technical University of Sofia at the Plovdiv campus, where he is presently a Full Professor. He has held long-term visiting Professor/Scholar positions at various institutions in South Korea, Turkey, Mexico, Greece, Belgium, UK, and Germany. And he has coauthored one book and authored or coauthored more than 80 research papers in conference proceedings and journals. His current research interests are in the fields of intelligent control and robotics.",institutionString:null,institution:{name:"Technical University of Sofia",country:{name:"Bulgaria"}}},{id:"585",title:"Prof.",name:"Munir",middleName:null,surname:"Merdan",slug:"munir-merdan",fullName:"Munir Merdan",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/585/images/system/585.jpg",biography:"Munir Merdan received the M.Sc. degree in mechanical engineering from the Technical University of Sarajevo, Bosnia and Herzegovina, in 2001, and the Ph.D. degree in electrical engineering from the Vienna University of Technology, Vienna, Austria, in 2009.Since 2005, he has been at the Automation and Control Institute, Vienna University of Technology, where he is currently a Senior Researcher. His research interests include the application of agent technology for achieving agile control in the manufacturing environment.",institutionString:null,institution:null},{id:"605",title:"Prof",name:"Dil",middleName:null,surname:"Hussain",slug:"dil-hussain",fullName:"Dil Hussain",position:null,profilePictureURL:"https://mts.intechopen.com/storage/users/605/images/system/605.jpg",biography:"Dr. Dil Muhammad Akbar Hussain is a professor of Electronics Engineering & Computer Science at the Department of Energy Technology, Aalborg University Denmark.  Professor Akbar has a Master degree in Digital Electronics from Govt. College University, Lahore Pakistan and a P-hD degree in Control Engineering from the School of Engineering and Applied Sciences, University of Sussex United Kingdom.  Aalborg University has Two Satellite Campuses, one in Copenhagen (Aalborg University Copenhagen) and the other in Esbjerg (Aalborg University Esbjerg).\n· He is a member of prestigious IEEE (Institute of Electrical and Electronics Engineers), and IAENG (International Association of Engineers) organizations. \n· He is the chief Editor of the Journal of Software Engineering.\n· He is the member of the Editorial Board of International Journal of Computer Science and Software Technology (IJCSST) and International Journal of Computer Engineering and Information Technology. \n· He is also the Editor of Communication in Computer and Information Science CCIS-20 by Springer.\n· Reviewer For Many Conferences\nHe is the lead person in making collaboration agreements between Aalborg University and many universities of Pakistan, for which the MOU’s (Memorandum of Understanding) have been signed.\nProfessor Akbar is working in Academia since 1990, he started his career as a Lab demonstrator/TA at the University of Sussex.  After finishing his P. hD degree in 1992, he served in the Industry as a Scientific Officer and continued his academic career as a visiting scholar for a number of educational institutions.  In 1996 he joined National University of Science & Technology Pakistan (NUST) as an Associate Professor; NUST is one of the top few universities in Pakistan.  In 1999 he joined an International Company Lineo Inc, Canada as Manager Compiler Group, where he headed the group for developing Compiler Tool Chain and Porting of Operating Systems for the BLACKfin processor.  The processor development was a joint venture by Intel and Analog Devices. In 2002 Lineo Inc., was taken over by another company, so he joined Aalborg University Denmark as an Assistant Professor.\nProfessor Akbar has truly a multi-disciplined career and he continued his legacy and making progress in many areas of his interests both in teaching and research.  He has contributed in stochastic estimation of control area especially, in the Multiple Target Tracking and Interactive Multiple Model (IMM) research, Ball & Beam Control Problem, Robotics, Levitation Control. He has contributed in developing Algorithms for Fingerprint Matching, Computer Vision and Face Recognition.  He has been supervising Pattern Recognition, Formal Languages and Distributed Processing projects for several years.  He has reviewed many books on Management, Computer Science.  Currently, he is an active and permanent reviewer for many international conferences and symposia and the program committee member for many international conferences.\nIn teaching he has taught the core computer science subjects like, Digital Design, Real Time Embedded System Programming, Operating Systems, Software Engineering, Data Structures, Databases, Compiler Construction.  In the Engineering side, Digital Signal Processing, Computer Architecture, Electronics Devices, Digital Filtering and Engineering Management.\nApart from his Academic Interest and activities he loves sport especially, Cricket, Football, Snooker and Squash.  He plays cricket for Esbjerg city in the second division team as an opener wicket keeper batsman.  He is a very good player of squash but has not played squash since his arrival in Denmark.",institutionString:null,institution:null},{id:"611",title:"Prof.",name:"T",middleName:null,surname:"Nagarajan",slug:"t-nagarajan",fullName:"T Nagarajan",position:null,profilePictureURL:"//cdnintech.com/web/frontend/www/assets/author.svg",biography:null,institutionString:null,institution:{name:"Universiti Teknologi Petronas",country:{name:"Malaysia"}}}],filtersByRegion:[{group:"region",caption:"North America",value:1,count:5995},{group:"region",caption:"Middle and South America",value:2,count:5451},{group:"region",caption:"Africa",value:3,count:1911},{group:"region",caption:"Asia",value:4,count:10968},{group:"region",caption:"Australia and Oceania",value:5,count:936},{group:"region",caption:"Europe",value:6,count:16316}],offset:12,limit:12,total:122304},chapterEmbeded:{data:{}},editorApplication:{success:null,errors:{}},ofsBooks:{filterParams:{"amp;sort":"dateEndThirdStepPublish",hasNoEditors:"0"},books:[{type:"book",id:"7102",title:"Pneumonia",subtitle:null,isOpenForSubmission:!0,hash:"9fd70142814192dcec58a176749f1b60",slug:null,bookSignature:"Dr. Nima Rezaei",coverURL:"https://cdn.intechopen.com/books/images_new/7102.jpg",editedByType:null,editors:[{id:"116250",title:"Dr.",name:"Nima",surname:"Rezaei",slug:"nima-rezaei",fullName:"Nima Rezaei"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10193",title:"Renal Replacement Therapy",subtitle:null,isOpenForSubmission:!0,hash:"3c4738671bb3e815744d1e04df7ba879",slug:null,bookSignature:"Prof. Ane C.F. Nunes",coverURL:"https://cdn.intechopen.com/books/images_new/10193.jpg",editedByType:null,editors:[{id:"55270",title:"Prof.",name:"Ane C.F.",surname:"Nunes",slug:"ane-c.f.-nunes",fullName:"Ane C.F. Nunes"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10473",title:"Sarcoidosis - New Perspectives",subtitle:null,isOpenForSubmission:!0,hash:"4bffdfb8619408d0a5608527292b6985",slug:null,bookSignature:"Dr. Seyyed Shamsadin Athari",coverURL:"https://cdn.intechopen.com/books/images_new/10473.jpg",editedByType:null,editors:[{id:"139889",title:"Dr.",name:"Seyyed Shamsadin",surname:"Athari",slug:"seyyed-shamsadin-athari",fullName:"Seyyed Shamsadin Athari"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10568",title:"Hysteresis in Engineering",subtitle:null,isOpenForSubmission:!0,hash:"6482387993b3cebffafe856a916c44ce",slug:null,bookSignature:"Dr. Giuseppe Viola",coverURL:"https://cdn.intechopen.com/books/images_new/10568.jpg",editedByType:null,editors:[{id:"173586",title:"Dr.",name:"Giuseppe",surname:"Viola",slug:"giuseppe-viola",fullName:"Giuseppe Viola"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10652",title:"Visual Object Tracking",subtitle:null,isOpenForSubmission:!0,hash:"d13718b2d986d058d55cf91e69bf21c0",slug:null,bookSignature:"Prof. Antonio J. R. Neves",coverURL:"https://cdn.intechopen.com/books/images_new/10652.jpg",editedByType:null,editors:[{id:"1177",title:"Prof.",name:"Antonio",surname:"Neves",slug:"antonio-neves",fullName:"Antonio Neves"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10661",title:"Cancer Bioinformatics",subtitle:null,isOpenForSubmission:!0,hash:"de4ec5bb46fa24bd45d7cc410bd95779",slug:null,bookSignature:"Dr. Ghedira Kais and Dr. Yosr Hamdi",coverURL:"https://cdn.intechopen.com/books/images_new/10661.jpg",editedByType:null,editors:[{id:"229844",title:"Dr.",name:"Ghedira",surname:"Kais",slug:"ghedira-kais",fullName:"Ghedira Kais"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10662",title:"Pedagogy - Challenges, Recent Advances, New Perspectives, and Applications",subtitle:null,isOpenForSubmission:!0,hash:"72abac6de82d153ad557bff890a93e33",slug:null,bookSignature:"Dr. Hülya Şenol",coverURL:"https://cdn.intechopen.com/books/images_new/10662.jpg",editedByType:null,editors:[{id:"240203",title:"Dr.",name:"Hülya",surname:"Şenol",slug:"hulya-senol",fullName:"Hülya Şenol"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10663",title:"Haptic Technology - Intelligent Approach to Future Man-Machine Interaction",subtitle:null,isOpenForSubmission:!0,hash:"1171e71bef0a5ecd85b992971737ca97",slug:null,bookSignature:"Prof. Ahmad Hoirul Basori, Dr. Sharaf J. Malebary and Dr. Omar M. Barukab",coverURL:"https://cdn.intechopen.com/books/images_new/10663.jpg",editedByType:null,editors:[{id:"13394",title:"Prof.",name:"Ahmad Hoirul",surname:"Basori",slug:"ahmad-hoirul-basori",fullName:"Ahmad Hoirul Basori"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10671",title:"Adolescences",subtitle:null,isOpenForSubmission:!0,hash:"f005179bb7f6cd7c531a00cd8da18eaa",slug:null,bookSignature:"Prof. Massimo Ingrassia and Prof. Loredana Benedetto",coverURL:"https://cdn.intechopen.com/books/images_new/10671.jpg",editedByType:null,editors:[{id:"193901",title:"Prof.",name:"Massimo",surname:"Ingrassia",slug:"massimo-ingrassia",fullName:"Massimo Ingrassia"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10673",title:"The Psychology of Trust",subtitle:null,isOpenForSubmission:!0,hash:"7b45a63e3aadbe8dc8847f5fbbffeb64",slug:null,bookSignature:"Dr. Martha Peaslee Peaslee Levine",coverURL:"https://cdn.intechopen.com/books/images_new/10673.jpg",editedByType:null,editors:[{id:"186919",title:"Dr.",name:"Martha",surname:"Peaslee Levine",slug:"martha-peaslee-levine",fullName:"Martha Peaslee Levine"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10677",title:"Advanced Topics of Topology",subtitle:null,isOpenForSubmission:!0,hash:"bf964c52f9e653fac20a7fcab58070e5",slug:null,bookSignature:"Dr. Francisco Bulnes",coverURL:"https://cdn.intechopen.com/books/images_new/10677.jpg",editedByType:null,editors:[{id:"92918",title:"Dr.",name:"Francisco",surname:"Bulnes",slug:"francisco-bulnes",fullName:"Francisco Bulnes"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10686",title:"Natural Gas - New Perspectives and Future Developments",subtitle:null,isOpenForSubmission:!0,hash:"581763788a6a59e653a9d1d9b5a42d79",slug:null,bookSignature:"Dr. Maryam Takht Ravanchi",coverURL:"https://cdn.intechopen.com/books/images_new/10686.jpg",editedByType:null,editors:[{id:"2416",title:"Dr.",name:"Maryam",surname:"Takht Ravanchi",slug:"maryam-takht-ravanchi",fullName:"Maryam Takht Ravanchi"}],productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}}],filtersByTopic:[{group:"topic",caption:"Agricultural and Biological Sciences",value:5,count:18},{group:"topic",caption:"Biochemistry, Genetics and Molecular Biology",value:6,count:6},{group:"topic",caption:"Business, Management and Economics",value:7,count:5},{group:"topic",caption:"Chemistry",value:8,count:7},{group:"topic",caption:"Computer and Information Science",value:9,count:5},{group:"topic",caption:"Earth and Planetary Sciences",value:10,count:4},{group:"topic",caption:"Engineering",value:11,count:16},{group:"topic",caption:"Environmental Sciences",value:12,count:2},{group:"topic",caption:"Immunology and Microbiology",value:13,count:2},{group:"topic",caption:"Materials Science",value:14,count:5},{group:"topic",caption:"Mathematics",value:15,count:4},{group:"topic",caption:"Medicine",value:16,count:38},{group:"topic",caption:"Nanotechnology and Nanomaterials",value:17,count:1},{group:"topic",caption:"Neuroscience",value:18,count:3},{group:"topic",caption:"Pharmacology, Toxicology and Pharmaceutical Science",value:19,count:4},{group:"topic",caption:"Physics",value:20,count:2},{group:"topic",caption:"Psychology",value:21,count:3},{group:"topic",caption:"Robotics",value:22,count:1},{group:"topic",caption:"Social Sciences",value:23,count:4},{group:"topic",caption:"Technology",value:24,count:1}],offset:12,limit:12,total:131},popularBooks:{featuredBooks:[{type:"book",id:"10363",title:"Abiotic Stress in Plants",subtitle:null,isOpenForSubmission:!1,hash:"e4d0b0a5b0d55843e704d38d55206b91",slug:"abiotic-stress-in-plants",bookSignature:"Shah Fahad, Shah Saud, Yajun Chen, Chao Wu and Depeng Wang",coverURL:"https://cdn.intechopen.com/books/images_new/10363.jpg",editors:[{id:"194771",title:"Dr.",name:"Shah",middleName:null,surname:"Fahad",slug:"shah-fahad",fullName:"Shah Fahad"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10321",title:"Advances in Precision Medicine Oncology",subtitle:null,isOpenForSubmission:!1,hash:"043ad1c1a6bbdcd5604917ccbff003d8",slug:"advances-in-precision-medicine-oncology",bookSignature:"Hilal Arnouk and Bassam Abdul Rasool Hassan",coverURL:"https://cdn.intechopen.com/books/images_new/10321.jpg",editors:[{id:"76431",title:"Dr.",name:"Hilal",middleName:null,surname:"Arnouk",slug:"hilal-arnouk",fullName:"Hilal Arnouk"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9927",title:"Real Perspective of Fourier Transforms and Current Developments in Superconductivity",subtitle:null,isOpenForSubmission:!1,hash:"89f437eae592f8f3730b6c9ec8426e43",slug:"real-perspective-of-fourier-transforms-and-current-developments-in-superconductivity",bookSignature:"Juan Manuel Velazquez Arcos",coverURL:"https://cdn.intechopen.com/books/images_new/9927.jpg",editors:[{id:"114776",title:"Dr.",name:"Juan Manuel",middleName:null,surname:"Velazquez Arcos",slug:"juan-manuel-velazquez-arcos",fullName:"Juan Manuel Velazquez Arcos"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"8950",title:"Birds",subtitle:"Challenges and Opportunities for Business, Conservation and Research",isOpenForSubmission:!1,hash:"404a05af45e47e43871f4a0b1bedc6fd",slug:"birds-challenges-and-opportunities-for-business-conservation-and-research",bookSignature:"Heimo Mikkola",coverURL:"https://cdn.intechopen.com/books/images_new/8950.jpg",editors:[{id:"144330",title:"Dr.",name:"Heimo",middleName:"Juhani",surname:"Mikkola",slug:"heimo-mikkola",fullName:"Heimo Mikkola"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9496",title:"Management of Dyslipidemia",subtitle:null,isOpenForSubmission:!1,hash:"1d1174ff4ed8ad553c944e99add28154",slug:"management-of-dyslipidemia",bookSignature:"Wilbert S. Aronow",coverURL:"https://cdn.intechopen.com/books/images_new/9496.jpg",editors:[{id:"164597",title:"Dr.",name:"Wilbert S.",middleName:null,surname:"Aronow",slug:"wilbert-s.-aronow",fullName:"Wilbert S. Aronow"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10214",title:"Saccharomyces",subtitle:null,isOpenForSubmission:!1,hash:"e313134fdc982e3fdc0cc0bd1b48ef59",slug:"saccharomyces",bookSignature:"Thalita Peixoto Basso and Luiz Carlos Basso",coverURL:"https://cdn.intechopen.com/books/images_new/10214.jpg",editors:[{id:"139174",title:"Ph.D.",name:"Thalita",middleName:null,surname:"Peixoto Basso",slug:"thalita-peixoto-basso",fullName:"Thalita Peixoto Basso"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10071",title:"Nanowires",subtitle:"Recent Progress",isOpenForSubmission:!1,hash:"3baef9684ce58f9f65a1f1788509220d",slug:"nanowires-recent-progress",bookSignature:"Xihong Peng",coverURL:"https://cdn.intechopen.com/books/images_new/10071.jpg",editors:[{id:"24647",title:"Prof.",name:"Xihong",middleName:null,surname:"Peng",slug:"xihong-peng",fullName:"Xihong Peng"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9788",title:"Colorectal Cancer",subtitle:null,isOpenForSubmission:!1,hash:"6faf06dfe50a3febba931e41b794f4e5",slug:"colorectal-cancer",bookSignature:"Alberto Vannelli",coverURL:"https://cdn.intechopen.com/books/images_new/9788.jpg",editors:[{id:"34524",title:"Dr.",name:"Alberto",middleName:null,surname:"Vannelli",slug:"alberto-vannelli",fullName:"Alberto Vannelli"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10237",title:"Innovation in the Food Sector Through the Valorization of Food and Agro-Food By-Products",subtitle:null,isOpenForSubmission:!1,hash:"c3a5a3c7f7999d68f04ae49ff0553f3d",slug:"innovation-in-the-food-sector-through-the-valorization-of-food-and-agro-food-by-products",bookSignature:"Ana Novo de Barros and Irene Gouvinhas",coverURL:"https://cdn.intechopen.com/books/images_new/10237.jpg",editors:[{id:"260510",title:"Prof.",name:"Ana",middleName:null,surname:"Novo de Barros",slug:"ana-novo-de-barros",fullName:"Ana Novo de Barros"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10481",title:"Practical Applications of Laser Ablation",subtitle:null,isOpenForSubmission:!1,hash:"e9f235e98a88813c08a9dba80525b195",slug:"practical-applications-of-laser-ablation",bookSignature:"Dongfang Yang",coverURL:"https://cdn.intechopen.com/books/images_new/10481.jpg",editors:[{id:"177814",title:"Dr.",name:"Dongfang",middleName:null,surname:"Yang",slug:"dongfang-yang",fullName:"Dongfang Yang"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9821",title:"Trauma and Emergency Surgery",subtitle:"The Role of Damage Control Surgery",isOpenForSubmission:!1,hash:"d5f6d0e79ff1167c8db9a24fa69ed232",slug:"trauma-and-emergency-surgery-the-role-of-damage-control-surgery",bookSignature:"Georgios Tsoulfas and Mohammad Meshkini",coverURL:"https://cdn.intechopen.com/books/images_new/9821.jpg",editors:[{id:"57412",title:"Prof.",name:"Georgios",middleName:null,surname:"Tsoulfas",slug:"georgios-tsoulfas",fullName:"Georgios Tsoulfas"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10375",title:"Drilling Technology",subtitle:null,isOpenForSubmission:!1,hash:"cd437b78814b53276b4bafd00f6bedd8",slug:"drilling-technology",bookSignature:"Majid Tolouei-Rad",coverURL:"https://cdn.intechopen.com/books/images_new/10375.jpg",editors:[{id:"110340",title:"Dr.",name:"Majid",middleName:null,surname:"Tolouei-Rad",slug:"majid-tolouei-rad",fullName:"Majid Tolouei-Rad"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}}],offset:12,limit:12,total:5524},hotBookTopics:{hotBooks:[],offset:0,limit:12,total:null},publish:{},publishingProposal:{success:null,errors:{}},books:{featuredBooks:[{type:"book",id:"10363",title:"Abiotic Stress in Plants",subtitle:null,isOpenForSubmission:!1,hash:"e4d0b0a5b0d55843e704d38d55206b91",slug:"abiotic-stress-in-plants",bookSignature:"Shah Fahad, Shah Saud, Yajun Chen, Chao Wu and Depeng Wang",coverURL:"https://cdn.intechopen.com/books/images_new/10363.jpg",editors:[{id:"194771",title:"Dr.",name:"Shah",middleName:null,surname:"Fahad",slug:"shah-fahad",fullName:"Shah Fahad"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10321",title:"Advances in Precision Medicine Oncology",subtitle:null,isOpenForSubmission:!1,hash:"043ad1c1a6bbdcd5604917ccbff003d8",slug:"advances-in-precision-medicine-oncology",bookSignature:"Hilal Arnouk and Bassam Abdul Rasool Hassan",coverURL:"https://cdn.intechopen.com/books/images_new/10321.jpg",editors:[{id:"76431",title:"Dr.",name:"Hilal",middleName:null,surname:"Arnouk",slug:"hilal-arnouk",fullName:"Hilal Arnouk"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9927",title:"Real Perspective of Fourier Transforms and Current Developments in Superconductivity",subtitle:null,isOpenForSubmission:!1,hash:"89f437eae592f8f3730b6c9ec8426e43",slug:"real-perspective-of-fourier-transforms-and-current-developments-in-superconductivity",bookSignature:"Juan Manuel Velazquez Arcos",coverURL:"https://cdn.intechopen.com/books/images_new/9927.jpg",editors:[{id:"114776",title:"Dr.",name:"Juan Manuel",middleName:null,surname:"Velazquez Arcos",slug:"juan-manuel-velazquez-arcos",fullName:"Juan Manuel Velazquez Arcos"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"8950",title:"Birds",subtitle:"Challenges and Opportunities for Business, Conservation and Research",isOpenForSubmission:!1,hash:"404a05af45e47e43871f4a0b1bedc6fd",slug:"birds-challenges-and-opportunities-for-business-conservation-and-research",bookSignature:"Heimo Mikkola",coverURL:"https://cdn.intechopen.com/books/images_new/8950.jpg",editors:[{id:"144330",title:"Dr.",name:"Heimo",middleName:"Juhani",surname:"Mikkola",slug:"heimo-mikkola",fullName:"Heimo Mikkola"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9496",title:"Management of Dyslipidemia",subtitle:null,isOpenForSubmission:!1,hash:"1d1174ff4ed8ad553c944e99add28154",slug:"management-of-dyslipidemia",bookSignature:"Wilbert S. Aronow",coverURL:"https://cdn.intechopen.com/books/images_new/9496.jpg",editors:[{id:"164597",title:"Dr.",name:"Wilbert S.",middleName:null,surname:"Aronow",slug:"wilbert-s.-aronow",fullName:"Wilbert S. Aronow"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10214",title:"Saccharomyces",subtitle:null,isOpenForSubmission:!1,hash:"e313134fdc982e3fdc0cc0bd1b48ef59",slug:"saccharomyces",bookSignature:"Thalita Peixoto Basso and Luiz Carlos Basso",coverURL:"https://cdn.intechopen.com/books/images_new/10214.jpg",editors:[{id:"139174",title:"Ph.D.",name:"Thalita",middleName:null,surname:"Peixoto Basso",slug:"thalita-peixoto-basso",fullName:"Thalita Peixoto Basso"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10071",title:"Nanowires",subtitle:"Recent Progress",isOpenForSubmission:!1,hash:"3baef9684ce58f9f65a1f1788509220d",slug:"nanowires-recent-progress",bookSignature:"Xihong Peng",coverURL:"https://cdn.intechopen.com/books/images_new/10071.jpg",editors:[{id:"24647",title:"Prof.",name:"Xihong",middleName:null,surname:"Peng",slug:"xihong-peng",fullName:"Xihong Peng"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"9788",title:"Colorectal Cancer",subtitle:null,isOpenForSubmission:!1,hash:"6faf06dfe50a3febba931e41b794f4e5",slug:"colorectal-cancer",bookSignature:"Alberto Vannelli",coverURL:"https://cdn.intechopen.com/books/images_new/9788.jpg",editors:[{id:"34524",title:"Dr.",name:"Alberto",middleName:null,surname:"Vannelli",slug:"alberto-vannelli",fullName:"Alberto Vannelli"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10237",title:"Innovation in the Food Sector Through the Valorization of Food and Agro-Food By-Products",subtitle:null,isOpenForSubmission:!1,hash:"c3a5a3c7f7999d68f04ae49ff0553f3d",slug:"innovation-in-the-food-sector-through-the-valorization-of-food-and-agro-food-by-products",bookSignature:"Ana Novo de Barros and Irene Gouvinhas",coverURL:"https://cdn.intechopen.com/books/images_new/10237.jpg",editors:[{id:"260510",title:"Prof.",name:"Ana",middleName:null,surname:"Novo de Barros",slug:"ana-novo-de-barros",fullName:"Ana Novo de Barros"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}},{type:"book",id:"10481",title:"Practical Applications of Laser Ablation",subtitle:null,isOpenForSubmission:!1,hash:"e9f235e98a88813c08a9dba80525b195",slug:"practical-applications-of-laser-ablation",bookSignature:"Dongfang Yang",coverURL:"https://cdn.intechopen.com/books/images_new/10481.jpg",editors:[{id:"177814",title:"Dr.",name:"Dongfang",middleName:null,surname:"Yang",slug:"dongfang-yang",fullName:"Dongfang Yang"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter"}}],latestBooks:[{type:"book",id:"10249",title:"Mycorrhizal Fungi",subtitle:"Utilization in Agriculture and Industry",isOpenForSubmission:!1,hash:"4b82bacf1200d591715f59fad618ec4d",slug:"mycorrhizal-fungi-utilization-in-agriculture-and-industry",bookSignature:"Ramalingam Radhakrishnan",coverURL:"https://cdn.intechopen.com/books/images_new/10249.jpg",editedByType:"Edited by",editors:[{id:"219072",title:"Prof.",name:"Ramalingam",middleName:null,surname:"Radhakrishnan",slug:"ramalingam-radhakrishnan",fullName:"Ramalingam Radhakrishnan"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10508",title:"Innovations in Ultra-Wideband Technologies",subtitle:null,isOpenForSubmission:!1,hash:"1de858f7edccd1bfc9374d96bd867aa1",slug:"innovations-in-ultra-wideband-technologies",bookSignature:"Albert Sabban",coverURL:"https://cdn.intechopen.com/books/images_new/10508.jpg",editedByType:"Edited by",editors:[{id:"16889",title:"Dr.",name:"Albert",middleName:null,surname:"Sabban",slug:"albert-sabban",fullName:"Albert Sabban"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"9753",title:"Terpenes and Terpenoids",subtitle:"Recent Advances",isOpenForSubmission:!1,hash:"575689df13c78bf0e6c1be40804cd010",slug:"terpenes-and-terpenoids-recent-advances",bookSignature:"Shagufta Perveen and Areej Mohammad Al-Taweel",coverURL:"https://cdn.intechopen.com/books/images_new/9753.jpg",editedByType:"Edited by",editors:[{id:"192992",title:"Prof.",name:"Shagufta",middleName:null,surname:"Perveen",slug:"shagufta-perveen",fullName:"Shagufta Perveen"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"8493",title:"Meat and Nutrition",subtitle:null,isOpenForSubmission:!1,hash:"fa7ad96f9b9e63093c9091fb0b93a5f4",slug:"meat-and-nutrition",bookSignature:"Chhabi Lal Ranabhat",coverURL:"https://cdn.intechopen.com/books/images_new/8493.jpg",editedByType:"Edited by",editors:[{id:"230681",title:"Dr.",name:"Chhabi Lal",middleName:null,surname:"Ranabhat",slug:"chhabi-lal-ranabhat",fullName:"Chhabi Lal Ranabhat"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"9791",title:"Multiple Myeloma",subtitle:null,isOpenForSubmission:!1,hash:"91ae15c94c1c8b771c959a4cee4ed8ba",slug:"multiple-myeloma",bookSignature:"Ota Fuchs",coverURL:"https://cdn.intechopen.com/books/images_new/9791.jpg",editedByType:"Edited by",editors:[{id:"36468",title:"Dr.",name:"Ota",middleName:null,surname:"Fuchs",slug:"ota-fuchs",fullName:"Ota Fuchs"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10573",title:"Computational Overview of Fluid Structure Interaction",subtitle:null,isOpenForSubmission:!1,hash:"3950d1f9c82160d23bc594d00ec2ffbb",slug:"computational-overview-of-fluid-structure-interaction",bookSignature:"Khaled Ghaedi, Ahmed Alhusseny, Adel Nasser and Nabeel Al-Zurf",coverURL:"https://cdn.intechopen.com/books/images_new/10573.jpg",editedByType:"Edited by",editors:[{id:"190572",title:"Dr.",name:"Khaled",middleName:null,surname:"Ghaedi",slug:"khaled-ghaedi",fullName:"Khaled Ghaedi"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10575",title:"Magnetic Skyrmions",subtitle:null,isOpenForSubmission:!1,hash:"d93d7485e8a6a30d9e069aed78fdb355",slug:"magnetic-skyrmions",bookSignature:"Dipti Ranjan Sahu",coverURL:"https://cdn.intechopen.com/books/images_new/10575.jpg",editedByType:"Edited by",editors:[{id:"251855",title:"Prof.",name:"Dipti Ranjan",middleName:null,surname:"Sahu",slug:"dipti-ranjan-sahu",fullName:"Dipti Ranjan Sahu"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"10326",title:"Advances in Hepatology",subtitle:null,isOpenForSubmission:!1,hash:"356bcd9352c844e5524bb8e79cf6e7fe",slug:"advances-in-hepatology",bookSignature:"Luis Rodrigo, Ian Martins, Xiaozhong Guo and Xingshun Qi",coverURL:"https://cdn.intechopen.com/books/images_new/10326.jpg",editedByType:"Edited by",editors:[{id:"73208",title:"Prof.",name:"Luis",middleName:null,surname:"Rodrigo",slug:"luis-rodrigo",fullName:"Luis Rodrigo"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"9578",title:"Cardiac Diseases",subtitle:"Novel Aspects of Cardiac Risk, Cardiorenal Pathology and Cardiac Interventions",isOpenForSubmission:!1,hash:"9a5bbee0025f348afb4f26660de011f5",slug:"cardiac-diseases-novel-aspects-of-cardiac-risk-cardiorenal-pathology-and-cardiac-interventions",bookSignature:"David C. Gaze and Aleksandar Kibel",coverURL:"https://cdn.intechopen.com/books/images_new/9578.jpg",editedByType:"Edited by",editors:[{id:"71983",title:"Dr.",name:"David C.",middleName:null,surname:"Gaze",slug:"david-c.-gaze",fullName:"David C. Gaze"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}},{type:"book",id:"9872",title:"Models and Technologies for Smart, Sustainable and Safe Transportation Systems",subtitle:null,isOpenForSubmission:!1,hash:"ef80dab7f0350ea7cb28f40eedea2b35",slug:"models-and-technologies-for-smart-sustainable-and-safe-transportation-systems",bookSignature:"Stefano de Luca, Roberta Di Pace and Chiara Fiori",coverURL:"https://cdn.intechopen.com/books/images_new/9872.jpg",editedByType:"Edited by",editors:[{id:"271061",title:"Prof.",name:"Stefano",middleName:null,surname:"de Luca",slug:"stefano-de-luca",fullName:"Stefano de Luca"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}}]},subject:{topic:{id:"302",title:"Pathology",slug:"veterinary-medicine-and-science-pathology",parent:{id:"25",title:"Veterinary Medicine and Science",slug:"veterinary-medicine-and-science"},numberOfBooks:1,numberOfAuthorsAndEditors:30,numberOfWosCitations:41,numberOfCrossrefCitations:19,numberOfDimensionsCitations:44,videoUrl:null,fallbackUrl:null,description:null},booksByTopicFilter:{topicId:"302",sort:"-publishedDate",limit:12,offset:0},booksByTopicCollection:[{type:"book",id:"5861",title:"Theriogenology",subtitle:null,isOpenForSubmission:!1,hash:"b5aae519c030c5492d65c181d9c0ea57",slug:"theriogenology",bookSignature:"Rita Payan Carreira",coverURL:"https://cdn.intechopen.com/books/images_new/5861.jpg",editedByType:"Edited by",editors:[{id:"38652",title:"Dr.",name:"Rita",middleName:null,surname:"Payan-Carreira",slug:"rita-payan-carreira",fullName:"Rita Payan-Carreira"}],equalEditorOne:null,equalEditorTwo:null,equalEditorThree:null,productType:{id:"1",chapterContentType:"chapter",authoredCaption:"Edited by"}}],booksByTopicTotal:1,mostCitedChapters:[{id:"55491",doi:"10.5772/intechopen.69091",title:"Mitigation of the Heat Stress Impact in Livestock Reproduction",slug:"mitigation-of-the-heat-stress-impact-in-livestock-reproduction",totalDownloads:3726,totalCrossrefCites:8,totalDimensionsCites:17,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Govindan Krishnan, Madiajagan Bagath, Prathap Pragna,\nMallenahally Kusha Vidya, Joy Aleena, Payyanakkal Ravindranathan\nArchana, Veerasamy Sejian and Raghavendra Bhatta",authors:[{id:"89780",title:"Dr.",name:"Veerasamy",middleName:null,surname:"Sejian",slug:"veerasamy-sejian",fullName:"Veerasamy Sejian"},{id:"177210",title:"Dr.",name:"Raghavendra",middleName:null,surname:"Bhatta",slug:"raghavendra-bhatta",fullName:"Raghavendra Bhatta"},{id:"177220",title:"Dr.",name:"M",middleName:null,surname:"Bagath",slug:"m-bagath",fullName:"M Bagath"},{id:"201967",title:"Dr.",name:"Govindan",middleName:null,surname:"Krishnan",slug:"govindan-krishnan",fullName:"Govindan Krishnan"},{id:"201968",title:"Ms.",name:"Archana",middleName:null,surname:"Pr",slug:"archana-pr",fullName:"Archana Pr"},{id:"201969",title:"Ms.",name:"Pragna",middleName:null,surname:"Prathap",slug:"pragna-prathap",fullName:"Pragna Prathap"},{id:"201970",title:"Ms.",name:"Aleena",middleName:null,surname:"Joy",slug:"aleena-joy",fullName:"Aleena Joy"},{id:"201971",title:"Dr.",name:"Vidya",middleName:null,surname:"Mk",slug:"vidya-mk",fullName:"Vidya Mk"}]},{id:"55006",doi:"10.5772/intechopen.68650",title:"Immunocastration as Alternative to Surgical Castration in Pigs",slug:"immunocastration-as-alternative-to-surgical-castration-in-pigs",totalDownloads:1652,totalCrossrefCites:7,totalDimensionsCites:13,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Marjeta Čandek-Potokar, Martin Škrlep and Galia Zamaratskaia",authors:[{id:"23161",title:"Dr.",name:"Marjeta",middleName:null,surname:"Čandek-Potokar",slug:"marjeta-candek-potokar",fullName:"Marjeta Čandek-Potokar"},{id:"198220",title:"Dr.",name:"Martin",middleName:null,surname:"Škrlep",slug:"martin-skrlep",fullName:"Martin Škrlep"},{id:"198221",title:"Prof.",name:"Galia",middleName:null,surname:"Zamaratskaia",slug:"galia-zamaratskaia",fullName:"Galia Zamaratskaia"}]},{id:"56522",doi:"10.5772/intechopen.69549",title:"Role of Melatonin in Reproductive Seasonality in Buffaloes",slug:"role-of-melatonin-in-reproductive-seasonality-in-buffaloes",totalDownloads:1522,totalCrossrefCites:1,totalDimensionsCites:4,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Tamer Awad Ramadan",authors:[{id:"197651",title:"Dr.",name:"Tamer",middleName:"Awad",surname:"Ramadan",slug:"tamer-ramadan",fullName:"Tamer Ramadan"}]}],mostDownloadedChaptersLast30Days:[{id:"55491",title:"Mitigation of the Heat Stress Impact in Livestock Reproduction",slug:"mitigation-of-the-heat-stress-impact-in-livestock-reproduction",totalDownloads:3696,totalCrossrefCites:8,totalDimensionsCites:17,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Govindan Krishnan, Madiajagan Bagath, Prathap Pragna,\nMallenahally Kusha Vidya, Joy Aleena, Payyanakkal Ravindranathan\nArchana, Veerasamy Sejian and Raghavendra Bhatta",authors:[{id:"89780",title:"Dr.",name:"Veerasamy",middleName:null,surname:"Sejian",slug:"veerasamy-sejian",fullName:"Veerasamy Sejian"},{id:"177210",title:"Dr.",name:"Raghavendra",middleName:null,surname:"Bhatta",slug:"raghavendra-bhatta",fullName:"Raghavendra Bhatta"},{id:"177220",title:"Dr.",name:"M",middleName:null,surname:"Bagath",slug:"m-bagath",fullName:"M Bagath"},{id:"201967",title:"Dr.",name:"Govindan",middleName:null,surname:"Krishnan",slug:"govindan-krishnan",fullName:"Govindan Krishnan"},{id:"201968",title:"Ms.",name:"Archana",middleName:null,surname:"Pr",slug:"archana-pr",fullName:"Archana Pr"},{id:"201969",title:"Ms.",name:"Pragna",middleName:null,surname:"Prathap",slug:"pragna-prathap",fullName:"Pragna Prathap"},{id:"201970",title:"Ms.",name:"Aleena",middleName:null,surname:"Joy",slug:"aleena-joy",fullName:"Aleena Joy"},{id:"201971",title:"Dr.",name:"Vidya",middleName:null,surname:"Mk",slug:"vidya-mk",fullName:"Vidya Mk"}]},{id:"55619",title:"Ovary Differentiation and Activity in Teleostei Fish",slug:"ovary-differentiation-and-activity-in-teleostei-fish",totalDownloads:1991,totalCrossrefCites:1,totalDimensionsCites:2,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Talita Sarah Mazzoni and Irani Quagio Grassiotto",authors:[{id:"197554",title:"Dr.",name:"Irani",middleName:null,surname:"Quagio Grassiotto",slug:"irani-quagio-grassiotto",fullName:"Irani Quagio Grassiotto"},{id:"197735",title:"Prof.",name:"Talita Sarah",middleName:null,surname:"Mazzoni",slug:"talita-sarah-mazzoni",fullName:"Talita Sarah Mazzoni"}]},{id:"55006",title:"Immunocastration as Alternative to Surgical Castration in Pigs",slug:"immunocastration-as-alternative-to-surgical-castration-in-pigs",totalDownloads:1633,totalCrossrefCites:7,totalDimensionsCites:13,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Marjeta Čandek-Potokar, Martin Škrlep and Galia Zamaratskaia",authors:[{id:"23161",title:"Dr.",name:"Marjeta",middleName:null,surname:"Čandek-Potokar",slug:"marjeta-candek-potokar",fullName:"Marjeta Čandek-Potokar"},{id:"198220",title:"Dr.",name:"Martin",middleName:null,surname:"Škrlep",slug:"martin-skrlep",fullName:"Martin Škrlep"},{id:"198221",title:"Prof.",name:"Galia",middleName:null,surname:"Zamaratskaia",slug:"galia-zamaratskaia",fullName:"Galia Zamaratskaia"}]},{id:"55324",title:"The Role of Androgens in Ovarian Follicular Development: From Fertility to Ovarian Cancer",slug:"the-role-of-androgens-in-ovarian-follicular-development-from-fertility-to-ovarian-cancer",totalDownloads:1465,totalCrossrefCites:0,totalDimensionsCites:0,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Malgorzata Duda, Kamil Wartalski, Zbigniew Tabarowski and\nGabriela Gorczyca",authors:[{id:"177042",title:"Ph.D.",name:"Malgorzata",middleName:null,surname:"Duda",slug:"malgorzata-duda",fullName:"Malgorzata Duda"},{id:"177918",title:"Dr.",name:"Zbigniew",middleName:null,surname:"Tabarowski",slug:"zbigniew-tabarowski",fullName:"Zbigniew Tabarowski"},{id:"205391",title:"MSc.",name:"Kamil",middleName:null,surname:"Wartalski",slug:"kamil-wartalski",fullName:"Kamil Wartalski"},{id:"205392",title:"MSc.",name:"Gabriela",middleName:null,surname:"Gorczyca",slug:"gabriela-gorczyca",fullName:"Gabriela Gorczyca"}]},{id:"56522",title:"Role of Melatonin in Reproductive Seasonality in Buffaloes",slug:"role-of-melatonin-in-reproductive-seasonality-in-buffaloes",totalDownloads:1501,totalCrossrefCites:1,totalDimensionsCites:4,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Tamer Awad Ramadan",authors:[{id:"197651",title:"Dr.",name:"Tamer",middleName:"Awad",surname:"Ramadan",slug:"tamer-ramadan",fullName:"Tamer Ramadan"}]},{id:"55696",title:"Estrus Cycle Monitoring in Wild Mammals: Challenges and Perspectives",slug:"estrus-cycle-monitoring-in-wild-mammals-challenges-and-perspectives",totalDownloads:1489,totalCrossrefCites:0,totalDimensionsCites:3,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Alexandre R. Silva, Nei Moreira, Alexsandra F. Pereira, Gislayne C.X.\nPeixoto, Keilla M. Maia, Lívia B. Campos and Alana A. Borges",authors:[{id:"90066",title:"Dr.",name:"Alexandre",middleName:"Rodrigues",surname:"Silva",slug:"alexandre-silva",fullName:"Alexandre Silva"},{id:"177090",title:"Dr.",name:"Alexsandra Fernandes",middleName:null,surname:"Pereira",slug:"alexsandra-fernandes-pereira",fullName:"Alexsandra Fernandes Pereira"},{id:"177093",title:"MSc.",name:"Gislayne Christianne Xavier",middleName:null,surname:"Peixoto",slug:"gislayne-christianne-xavier-peixoto",fullName:"Gislayne Christianne Xavier Peixoto"},{id:"198314",title:"Prof.",name:"Nei",middleName:null,surname:"Moreira",slug:"nei-moreira",fullName:"Nei Moreira"},{id:"198315",title:"MSc.",name:"Keilla Moreira",middleName:null,surname:"Maia",slug:"keilla-moreira-maia",fullName:"Keilla Moreira Maia"},{id:"198316",title:"MSc.",name:"Lívia Batista",middleName:null,surname:"Campos",slug:"livia-batista-campos",fullName:"Lívia Batista Campos"},{id:"198317",title:"MSc.",name:"Alana Azevedo",middleName:null,surname:"Borges",slug:"alana-azevedo-borges",fullName:"Alana Azevedo Borges"}]},{id:"54974",title:"Markers for Sperm Freezability and Relevance of Transcriptome Studies in Semen Cryopreservation: A Review",slug:"markers-for-sperm-freezability-and-relevance-of-transcriptome-studies-in-semen-cryopreservation-a-re",totalDownloads:1355,totalCrossrefCites:0,totalDimensionsCites:3,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Leyland Fraser",authors:[{id:"199650",title:"Dr.",name:"Leyland",middleName:null,surname:"Fraser",slug:"leyland-fraser",fullName:"Leyland Fraser"}]},{id:"56161",title:"The Thalassinidean Mud Shrimp Upogebia vasquezi: Life Cycle and Reproductive Traits on the Amazonian Coast, Brazil",slug:"the-thalassinidean-mud-shrimp-upogebia-vasquezi-life-cycle-and-reproductive-traits-on-the-amazonian-",totalDownloads:1352,totalCrossrefCites:1,totalDimensionsCites:1,book:{id:"5861",slug:"theriogenology",title:"Theriogenology",fullTitle:"Theriogenology"},signatures:"Danielly Brito de Oliveira, Fernando Araújo Abrunhosa and Jussara\nMoretto Martinelli-Lemos",authors:[{id:"147527",title:"Dr.",name:"Fernando Araújo",middleName:null,surname:"Abrunhosa",slug:"fernando-araujo-abrunhosa",fullName:"Fernando Araújo Abrunhosa"},{id:"198331",title:"Dr.",name:"Danielly",middleName:null,surname:"Oliveira",slug:"danielly-oliveira",fullName:"Danielly Oliveira"},{id:"204935",title:"Dr.",name:"Jussara",middleName:null,surname:"Moretto Martinelli Lemos",slug:"jussara-moretto-martinelli-lemos",fullName:"Jussara Moretto Martinelli Lemos"}]}],onlineFirstChaptersFilter:{topicId:"302",limit:3,offset:0},onlineFirstChaptersCollection:[],onlineFirstChaptersTotal:0},preDownload:{success:null,errors:{}},aboutIntechopen:{},privacyPolicy:{},peerReviewing:{},howOpenAccessPublishingWithIntechopenWorks:{},sponsorshipBooks:{sponsorshipBooks:[],offset:8,limit:8,total:0},route:{name:"chapter.detail",path:"/chapters/65993",hash:"",query:{},params:{id:"65993"},fullPath:"/chapters/65993",meta:{},from:{name:null,path:"/",hash:"",query:{},params:{},fullPath:"/",meta:{}}}},function(){var e;(e=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(e)}()</script><script src="//cdnintech.com/web/frontend/www/dist/manifest.738d20ca0ff2771c5ad6.js" defer="defer"></script><script src="//cdnintech.com/web/frontend/www/dist/vendor.df6b45c13d4920726136.js" defer="defer"></script><script src="//cdnintech.com/web/frontend/www/dist/app.bc4054f78c29dd68d7ff.js" defer="defer"></script></div></body></html>